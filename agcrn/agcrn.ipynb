{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric_temporal.nn.recurrent import AGCRN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTradeDataset(Dataset):\n",
    "    def __init__(self, num_samples, T, num_nodes, in_channels, num_sectors):\n",
    "        \"\"\"\n",
    "        For demonstration, we create random data:\n",
    "        X shape: [num_samples, T, num_nodes, in_channels]\n",
    "        Y shape: [num_samples, num_nodes, num_sectors]\n",
    "        \"\"\"\n",
    "        self.X = torch.randn(num_samples, T, num_nodes, in_channels)\n",
    "        self.Y = torch.randn(num_samples, num_nodes, num_sectors)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.1194\n",
      "Epoch [2/5], Loss: 1.0829\n",
      "Epoch [3/5], Loss: 1.0574\n",
      "Epoch [4/5], Loss: 1.0366\n",
      "Epoch [5/5], Loss: 1.0182\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Hyperparameters\n",
    "num_samples=50\n",
    "T=10 #no. of time steps\n",
    "num_nodes = 10         # e.g. 10 country pairs\n",
    "num_sectors=5\n",
    "node_features = 2        # sentiment & FBIC\n",
    "in_channels = num_sectors + node_features\n",
    "out_channels = 8       # hidden dimension in AGCRN\n",
    "K = 3                  # polynomial filter size\n",
    "embedding_dims = 4     # dimension of each node's embedding\n",
    "num_epochs = 5\n",
    "batch_size = 4\n",
    "lr = 1e-3\n",
    "\n",
    "dataset = MyTradeDataset(\n",
    "    num_samples=num_samples,\n",
    "    T=T,\n",
    "    num_nodes=num_nodes,\n",
    "    in_channels=in_channels,\n",
    "    num_sectors=num_sectors\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 2) Instantiate AGCRN\n",
    "model = AGCRN(\n",
    "    number_of_nodes=num_nodes,\n",
    "    in_channels=in_channels,\n",
    "    out_channels=out_channels,\n",
    "    K=K,\n",
    "    embedding_dimensions=embedding_dims\n",
    ")\n",
    "\n",
    "# 3) Create the node embedding E separately (following your interface).\n",
    "#    We'll just do a random init. This is learnable, so we wrap it in nn.Parameter.\n",
    "E = nn.Parameter(torch.randn(num_nodes, embedding_dims), requires_grad=True)\n",
    "\n",
    "# 4) A simple linear \"prediction head\" to map from the hidden dimension (out_channels) -> 1\n",
    "prediction_head = nn.Linear(out_channels, num_sectors)\n",
    "\n",
    "# 5) Combine everything in a single optimizer. We must include the node embedding (E) as well.\n",
    "optimizer = optim.Adam(\n",
    "    list(model.parameters()) + list(prediction_head.parameters()) + [E],\n",
    "    lr=lr\n",
    ")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 6) Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for X_batch, Y_batch in dataloader:\n",
    "        # X_batch: [batch_size, num_nodes, in_channels]\n",
    "        # Y_batch: [batch_size, num_nodes, 1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        H = None\n",
    "        # Unroll over T time steps\n",
    "        for t in range(T):\n",
    "            X_t = X_batch[:, t, :, :]  # [batch_size, num_nodes, in_channels]\n",
    "            H = model(X_t, E, H)  # H is the hidden state, E is the node embedding\n",
    "            \n",
    "\n",
    "        # Now map from [out_channels] -> 1 dimension\n",
    "        # We'll do this for each node:\n",
    "        Y_pred = prediction_head(H)\n",
    "\n",
    "        # Compute MSE loss with target\n",
    "        loss = criterion(Y_pred, Y_batch)\n",
    "\n",
    "        # Backprop & update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
