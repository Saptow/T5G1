{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAR model for benchmark performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialising data (adf test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     country_pair sector   adf_stat       p_value  used_lag  nobs\n",
      "0          AREAUS  bec_1  -3.124212  2.481254e-02         5    12\n",
      "1          AREAUS  bec_2  -2.817751  5.578257e-02         7    10\n",
      "2          AREAUS  bec_3   3.498822  1.000000e+00         7    10\n",
      "3          AREAUS  bec_4 -12.485611  3.023461e-23         7    10\n",
      "4          AREAUS  bec_5  -1.953536  3.073098e-01         7    10\n",
      "...           ...    ...        ...           ...       ...   ...\n",
      "2443       VNMUSA  bec_4   9.862133  1.000000e+00         7    10\n",
      "2444       VNMUSA  bec_5   1.455103  9.973506e-01         7    10\n",
      "2445       VNMUSA  bec_6   4.176970  1.000000e+00         7    10\n",
      "2446       VNMUSA  bec_7   1.192659  9.959348e-01         7    10\n",
      "2447       VNMUSA  bec_8  -4.548111  1.608114e-04         7    10\n",
      "\n",
      "[2448 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "training_data=pd.read_csv('../data/final/training_model_data.csv',header=0)\n",
    "test_data=pd.read_csv('../data/final/incompl_test_model_data.csv',header=0)\n",
    "test_data=test_data[training_data.columns]\n",
    "combined=pd.concat([training_data,test_data],axis=0)\n",
    "df_subset=combined[(combined['year']>=2006) & (combined['year']<=2023)]\n",
    "df_subset['country_pair']=df_subset['country_a']+df_subset['country_b']\n",
    "df_subset.head()\n",
    "df_subset=df_subset.drop(columns=['tradeagreementindex','sentiment_index','country_a','country_b'])\n",
    "df_long = df_subset.melt(\n",
    "    id_vars=['year','country_pair'],\n",
    "    value_vars=['bec_1','bec_2','bec_3','bec_4','bec_5','bec_6','bec_7','bec_8'],\n",
    "    var_name='sector',\n",
    "    value_name='value'\n",
    ")\n",
    "df_long=df_long.sort_values(['country_pair','sector','year'])\n",
    "grouped=df_long.groupby(['country_pair','sector'])\n",
    "results_list = []\n",
    "for (pair, sec), group_data in grouped:\n",
    "    ts = group_data.set_index('year')['value'].dropna()\n",
    "\n",
    "\n",
    "    adf_out = adfuller(ts, autolag='AIC')\n",
    "    adf_statistic  = adf_out[0]\n",
    "    p_value        = adf_out[1]\n",
    "    used_lag       = adf_out[2]\n",
    "    nobs           = adf_out[3]\n",
    "    critical_values= adf_out[4]\n",
    "    \n",
    "    results_list.append({\n",
    "        'country_pair': pair,\n",
    "        'sector': sec,\n",
    "        'adf_stat': adf_statistic,\n",
    "        'p_value': p_value,\n",
    "        'used_lag': used_lag,\n",
    "        'nobs': nobs\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_lags=results_df.groupby('country_pair')['used_lag'].median().reset_index()\n",
    "median_lags.to_csv('../data/final/median_adf_lags.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(series, title=''):\n",
    "    \"\"\"Perform ADF test and print results.\"\"\"\n",
    "    print(f'Augmented Dickey-Fuller Test: {title}')\n",
    "    result = adfuller(series.dropna(), autolag='AIC')\n",
    "    labels = ['ADF Statistic', 'p-value', '# Lags Used', '# Observations Used']\n",
    "    out = dict(zip(labels, result[0:4]))\n",
    "    for key, val in out.items():\n",
    "        print(f\"   {key}: {val}\")\n",
    "    for key, val in result[4].items():\n",
    "        print(f\"   Critical Value {key}: {val}\")\n",
    "    print(\"\")\n",
    "\n",
    "# Example: check stationarity for each column\n",
    "for col in df.columns:\n",
    "    adf_test(df[col], title=col)\n",
    "\n",
    "# If non-stationary, consider differencing\n",
    "df_diff = df.diff().dropna()\n",
    "\n",
    "# Re-check with ADF after differencing\n",
    "for col in df_diff.columns:\n",
    "    adf_test(df_diff[col], title=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=pd.read_csv('../data/final/training_model_data.csv',header=0)\n",
    "test_data=pd.read_csv('../data/final/incompl_test_model_data.csv',header=0)\n",
    "test_data=test_data[training_data.columns]\n",
    "combined=pd.concat([training_data,test_data],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def is_stationary(series, significance=0.05):\n",
    "    \"\"\"\n",
    "    Runs Augmented Dickey-Fuller test on a single series.\n",
    "    Returns True if stationary at given significance level, otherwise False.\n",
    "    \"\"\"\n",
    "    # ADF test\n",
    "    result = adfuller(series, autolag='AIC')\n",
    "    p_value = result[1]\n",
    "    return p_value < significance\n",
    "\n",
    "def check_stationarity(df, significance=0.05):\n",
    "    \"\"\"\n",
    "    Checks if ALL columns in df are stationary.\n",
    "    Returns True if all are stationary, else False.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        # Drop NA to avoid errors\n",
    "        series = df[col].dropna()\n",
    "        if len(series) < 10:\n",
    "            # If there's too little data, skip or treat as non-stationary\n",
    "            return False\n",
    "        # If any column is non-stationary, return False immediately\n",
    "        if not is_stationary(series, significance=significance):\n",
    "            return False\n",
    "    # If we get here, all columns are stationary\n",
    "    return True\n",
    "\n",
    "def make_stationary(df_in, max_diffs=2, significance=0.05):\n",
    "    \"\"\"\n",
    "    Iteratively check stationarity for all columns.\n",
    "    If any are non-stationary, difference the entire DataFrame once and re-check.\n",
    "    Continue until everything is stationary or we reach max_diffs.\n",
    "    \n",
    "    Returns:\n",
    "      (df_out, diff_count)\n",
    "        df_out     -> final (differenced) DataFrame\n",
    "        diff_count -> how many times the dataset was differenced\n",
    "    \"\"\"\n",
    "    df_out = df_in.copy()\n",
    "    diff_count = 0\n",
    "    \n",
    "    while diff_count < max_diffs:\n",
    "        if check_stationarity(df_out, significance=significance):\n",
    "            # All columns stationary\n",
    "            break\n",
    "        else:\n",
    "            # Difference all columns once\n",
    "            df_out = df_out.diff().dropna()\n",
    "            diff_count += 1\n",
    "    \n",
    "    # By now, either it's stationary or we hit max_diffs\n",
    "    return df_out, diff_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "def run_var_for_pair(df_pair, date_col='year', significance=0.05, max_diffs=2, max_lags=5, nobs=3):\n",
    "    \"\"\"\n",
    "    1) Splits data into train/test.\n",
    "    2) Automates stationarity checks & differencing.\n",
    "    3) Selects the best VAR order by AIC.\n",
    "    4) Fits VAR and forecasts nobs steps.\n",
    "    5) Inverts differencing (if needed).\n",
    "    6) Returns results + model.\n",
    "    \"\"\"\n",
    "    # 1) Set date index & sort\n",
    "    if date_col in df_pair.columns:\n",
    "        df_pair = df_pair.set_index(date_col)\n",
    "    df_pair = df_pair.sort_index()\n",
    "    \n",
    "    # 2) Train/test split\n",
    "    df_train, df_test = df_pair.iloc[:-nobs], df_pair.iloc[-nobs:]\n",
    "    \n",
    "    # 3) Make training data stationary with auto-differencing\n",
    "    df_stationary, diff_count = make_stationary(df_train, max_diffs=max_diffs, significance=significance)\n",
    "    \n",
    "    # 4) Select best VAR order with AIC\n",
    "    model = VAR(df_stationary)\n",
    "    best_lag = None\n",
    "    best_aic = np.inf\n",
    "    for lag in range(1, max_lags+1):\n",
    "        try:\n",
    "            result = model.fit(lag)\n",
    "            if result.aic < best_aic:\n",
    "                best_aic = result.aic\n",
    "                best_lag = lag\n",
    "        except:\n",
    "            # Some models might fail to converge for certain lags\n",
    "            pass\n",
    "    \n",
    "    if best_lag is None:\n",
    "        raise ValueError(\"No suitable VAR lag found. Check data or reduce max_lags.\")\n",
    "    \n",
    "    # Fit final model\n",
    "    model_fitted = model.fit(best_lag)\n",
    "    \n",
    "    # 5) Forecast nobs steps\n",
    "    forecast_input = df_stationary.values[-best_lag:]\n",
    "    fc = model_fitted.forecast(y=forecast_input, steps=nobs)\n",
    "    df_fc = pd.DataFrame(fc, index=df_test.index, columns=[col + \"_diff\" for col in df_stationary.columns])\n",
    "    \n",
    "    # 6) If we differenced, invert it to original scale\n",
    "    #    Example for a single differencing pass\n",
    "    df_inverted = None\n",
    "    if diff_count > 0:\n",
    "        df_inverted = df_fc.copy()\n",
    "        # We do repeated cumulative sums depending on how many times we've differenced\n",
    "        # Example for 1 difference:\n",
    "        if diff_count == 1:\n",
    "            for col in df_stationary.columns:\n",
    "                df_inverted[col + '_forecast'] = df_train[col].iloc[-1] + df_inverted[col + '_diff'].cumsum()\n",
    "        elif diff_count == 2:\n",
    "            for col in df_stationary.columns:\n",
    "                # First invert the second difference\n",
    "                df_inverted[col + '_1d'] = (df_train[col].iloc[-1] - df_train[col].iloc[-2]) + df_inverted[col + '_diff'].cumsum()\n",
    "                # Then invert the first difference\n",
    "                df_inverted[col + '_forecast'] = df_train[col].iloc[-1] + df_inverted[col + '_1d'].cumsum()\n",
    "        # etc. If you want to be robust to diff_count > 2, just loop.\n",
    "        \n",
    "    # 7) Calculate simple forecast accuracy metrics\n",
    "    def forecast_accuracy(forecast, actual):\n",
    "        mape = np.mean(np.abs(forecast - actual) / np.abs(actual))  \n",
    "        rmse_val = np.sqrt(np.mean((forecast - actual)**2))\n",
    "        return {\"mape\": mape, \"rmse\": rmse_val}\n",
    "    \n",
    "    metrics = {}\n",
    "    # Evaluate either df_fc or df_inverted depending on your scale of interest\n",
    "    df_evaluation = df_inverted if diff_count > 0 else df_fc\n",
    "    \n",
    "    for col in df_stationary.columns:\n",
    "        fc_col = col + ('_forecast' if diff_count > 0 else '_diff')\n",
    "        if fc_col not in df_evaluation.columns:\n",
    "            continue\n",
    "        y_true = df_test[col]\n",
    "        y_pred = df_evaluation[fc_col]\n",
    "        # Filter out any NA\n",
    "        y_true, y_pred = y_true.align(y_pred, join='inner')\n",
    "        if len(y_true) > 0:\n",
    "            metrics[col] = forecast_accuracy(y_pred, y_true)\n",
    "    \n",
    "    # Return final results\n",
    "    return {\n",
    "        'diff_count': diff_count,\n",
    "        'best_lag': best_lag,\n",
    "        'model_fitted': model_fitted,\n",
    "        'df_fc_diff': df_fc,       # forecast in differenced scale\n",
    "        'df_fc_inverted': df_inverted,  # forecast in original scale if diff_count>0\n",
    "        'metrics': metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     country_a country_b         bec_1         bec_2         bec_3  \\\n",
      "3570       ARE       AUS  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "3571       ARE       AUS  1.764716e+08  5.812547e+08  1.131179e+08   \n",
      "3572       ARE       AUS  2.186282e+08  5.242286e+08  1.421974e+08   \n",
      "3573       ARE       AUS  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "3574       ARE       AUS  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "\n",
      "             bec_4         bec_5         bec_6         bec_7         bec_8  \\\n",
      "3570  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  1.060739e+09   \n",
      "3571  6.507964e+08  3.311616e+08  1.274907e+07  2.253624e+07  7.838146e+07   \n",
      "3572  7.929628e+08  3.152631e+08  1.360508e+07  2.231833e+07  7.764083e+07   \n",
      "3573  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  1.814150e+09   \n",
      "3574  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  2.118919e+09   \n",
      "\n",
      "      sentiment_index  tradeagreementindex  year  \n",
      "3570         0.548505                    0  2006  \n",
      "3571         0.628572                    0  2007  \n",
      "3572         0.663694                    0  2008  \n",
      "3573         0.696372                    0  2009  \n",
      "3574         0.713641                    0  2010  \n"
     ]
    }
   ],
   "source": [
    "results_all_pairs = {}\n",
    "grouped = combined.groupby(['country_a', 'country_b'])\n",
    "for (exp, imp), df_pair in grouped:\n",
    "    result = run_var_for_pair(\n",
    "        df_pair,\n",
    "        date_col='date',\n",
    "        significance=0.05,  # or 0.01, your choice\n",
    "        max_diffs=2,        # differ up to twice\n",
    "        max_lags=12,\n",
    "        nobs=4\n",
    "    )\n",
    "    pair_key = f\"{exp}_{imp}\"\n",
    "    results_all_pairs[pair_key] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# # Align true values and forecasts\n",
    "# actual = df.loc[test_data.index, :]  # the actual values in the original scale\n",
    "# preds = final_forecast.loc[test_data.index, :]\n",
    "\n",
    "# mae_export = mean_absolute_error(actual[\"Export\"], preds[\"Export\"])\n",
    "# mae_import = mean_absolute_error(actual[\"Import\"], preds[\"Import\"])\n",
    "\n",
    "# mse_export = mean_squared_error(actual[\"Export\"], preds[\"Export\"])\n",
    "# mse_import = mean_squared_error(actual[\"Import\"], preds[\"Import\"])\n",
    "\n",
    "# print(\"MAE (Export):\", mae_export)\n",
    "# print(\"MAE (Import):\", mae_import)\n",
    "# print(\"MSE (Export):\", mse_export)\n",
    "# print(\"MSE (Import):\", mse_import)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
