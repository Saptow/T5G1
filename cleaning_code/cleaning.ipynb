{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STRI (Services Trade Restrictiveness Index) Dataset\n",
    "The STRI is an innovative tool that offers an overview of regulatory barriers across 22 major sectors and 51 countries. Based on the qualitative information in the database, composite indices quantify the identified restrictions across five standard policy categories, with values between zero and one. The five policy categories are restrictions on foreign entry, restrictions to movement of people, other discriminatory measures, barriers to competition and regulatory transparency. Complete openness to trade and investment gives a score of zero, while being completely closed to foreign services providers yields a score of one. \n",
    "\n",
    "Information on columns:\n",
    "1. REF_AREA: 51 countries\n",
    "2. ECONOMIC_ACTIVITY: 19 activities\n",
    "3. TIME_PERIOD: 2014-2024\n",
    "4. OBS_VALUE: The STRI value, which quantifies trade restrictiveness (0-1 scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read STRI.csv\n",
    "df = pd.read_csv('./data/original/STRI.csv')\n",
    "\n",
    "# Keep only the specified columns\n",
    "df = df[['REF_AREA', 'Economic activity', 'TIME_PERIOD', 'OBS_VALUE']]\n",
    "\n",
    "# Rename economic activity to 'ECONOMIC_ACTIVITY'\n",
    "df = df.rename(columns={'Economic activity': 'ECONOMIC_ACTIVITY'})\n",
    "\n",
    "# Rename REF_AREA to 'COUNTRY'\n",
    "df = df.rename(columns={'REF_AREA': 'COUNTRY'})\n",
    "\n",
    "# Save the new dataframe to 'STRI_cleaned.csv'\n",
    "df.to_csv('./data/cleaned/STRI_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  COUNTRY                                  ECONOMIC_ACTIVITY  TIME_PERIOD  \\\n",
      "0     AUT  Motion picture, video and television programme...         2014   \n",
      "1     AUT  Motion picture, video and television programme...         2015   \n",
      "2     AUT  Motion picture, video and television programme...         2016   \n",
      "3     AUT  Motion picture, video and television programme...         2017   \n",
      "4     AUT  Motion picture, video and television programme...         2018   \n",
      "\n",
      "   OBS_VALUE  \n",
      "0      0.169  \n",
      "1      0.169  \n",
      "2      0.169  \n",
      "3      0.169  \n",
      "4      0.169  \n"
     ]
    }
   ],
   "source": [
    "# Data exploration\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NTM (Non-Tariff Measures) Dataset\n",
    "A trade and market access information system combining data on trade, customs tariffs, and non-tariff measures. TRAINS contains HS-based tariff data for over 170 countries and for several years. The data covers all requirements that can potentially affect international trade for a specific product in a specific country and for a specific trading partner at one point in time. The TRAINS NTM database offers organized information categorized by product, measure type, countries imposing the measure, affected countries and several other variables. \n",
    "\n",
    "Information on columns:\n",
    "1. NTM_CODE: Refer to https://wits.worldbank.org/wits/wits/witshelp/content/data_retrieval/p/intro/C2.Non_Tariff_Measures.htm \n",
    "2. NTM_DESCRIPTION\n",
    "3. COUNTRY_IMPOSING\n",
    "4. IMPLEMENTATION_DATE\n",
    "5. COUNTRY_AFFECTED\n",
    "6. IS_UNILATERAL: One-sided measure or not\n",
    "7. REPEAL_DATE: When that measure will end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read NTM.csv \n",
    "df = pd.read_csv(\"./data/original/NTM.csv\")\n",
    "\n",
    "# Select only the relevant columns\n",
    "relevant_columns = [\n",
    "  \"ntmCode\",\n",
    "  \"ntmDescription\",\n",
    "  \"countryImposingNTMs\",\n",
    "  \"implementationDate\",\n",
    "  \"affectedCountriesNames\",\n",
    "  \"isUnilateral\",\n",
    "  \"repealDate\",\n",
    "]\n",
    "\n",
    "# Create a new dataframe with only the relevant columns\n",
    "cleaned_df = df[relevant_columns].copy()\n",
    "\n",
    "# Rename the columns to be more descriptive\n",
    "cleaned_df = cleaned_df.rename(\n",
    "  columns={\n",
    "    \"ntmCode\": \"NTM_CODE\",\n",
    "    \"ntmDescription\": \"NTM_DESCRIPTION\",\n",
    "    \"countryImposingNTMs\": \"COUNTRY_IMPOSING\",\n",
    "    \"implementationDate\": \"IMPLEMENTATION_DATE\",\n",
    "    \"affectedCountriesNames\": \"COUNTRY_AFFECTED\",\n",
    "    \"isUnilateral\": \"IS_UNILATERAL\",\n",
    "    \"repealDate\": \"REPEAL_DATE\",\n",
    "  }\n",
    ")\n",
    "\n",
    "# Change repeal date of missing values to 9999-12-31T00:00:00\n",
    "cleaned_df[\"REPEAL_DATE\"] = cleaned_df[\"REPEAL_DATE\"].fillna(\"9999-12-31T00:00:00\")\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "cleaned_df.to_csv(\"./data/cleaned/NTM_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NTM_CODE                                    NTM_DESCRIPTION  \\\n",
      "0      B15            Authorization requirement for importers   \n",
      "1      B49  Production or post-production requirements, n....   \n",
      "2       B7  Product-quality, safety or -performance requir...   \n",
      "3      B81          Product registration/approval requirement   \n",
      "4      B82                                Testing requirement   \n",
      "\n",
      "  COUNTRY_IMPOSING  IMPLEMENTATION_DATE                 COUNTRY_AFFECTED  \\\n",
      "0          Algeria  2020-08-01T00:00:00  World [Valid From: 01 Aug 2020]   \n",
      "1          Algeria  2020-08-01T00:00:00  World [Valid From: 01 Aug 2020]   \n",
      "2          Algeria  2020-08-01T00:00:00  World [Valid From: 01 Aug 2020]   \n",
      "3          Algeria  2020-08-01T00:00:00  World [Valid From: 01 Aug 2020]   \n",
      "4          Algeria  2020-08-01T00:00:00  World [Valid From: 01 Aug 2020]   \n",
      "\n",
      "   IS_UNILATERAL          REPEAL_DATE  \n",
      "0           True  9999-12-31T00:00:00  \n",
      "1           True  9999-12-31T00:00:00  \n",
      "2           True  9999-12-31T00:00:00  \n",
      "3           True  9999-12-31T00:00:00  \n",
      "4           True  9999-12-31T00:00:00  \n"
     ]
    }
   ],
   "source": [
    "print(cleaned_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WITS (World Integrated Trade Solution) Dataset\n",
    "It captures trade volumes and values between countries, systematically categorized by sectors and product classifications such as the Harmonized System (HS). This database provides data across different time intervals, including quarterly and yearly trade records, ensuring sufficient temporal granularity for capturing trends and economic fluctuations.\n",
    "\n",
    "Information on columns:\n",
    "1. Year: 2020-2022\n",
    "2. COUNTRY: The trading partner country name\n",
    "3. EXPORT_USD: Value of exports in thousands of US dollars\n",
    "4. IMPORT_USD: Value of imports in thousands of US dollars\n",
    "5. EXPORT_SHARE: Percentage of global export\n",
    "6. IMPORT_SHARE: Percentage of import export\n",
    "7. EXPORT_PRODUCTS: Measure of trade diversity\n",
    "8. IMPORT_PRODUCTS: Measure of trade diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine WITS_2020.csv, WITS_2021.csv, and WITS_2022.csv into a single dataframe\n",
    "df_2020 = pd.read_csv(\"./data/original/WITS_2020.csv\", encoding='latin1')\n",
    "df_2021 = pd.read_csv(\"./data/original/WITS_2021.csv\", encoding=\"latin1\")\n",
    "df_2022 = pd.read_csv(\"./data/original/WITS_2022.csv\", encoding=\"latin1\")\n",
    "\n",
    "# Add a column to each dataframe to indicate the year\n",
    "df_2020[\"Year\"] = 2020\n",
    "df_2021[\"Year\"] = 2021\n",
    "df_2022[\"Year\"] = 2022\n",
    "\n",
    "# Combine the dataframes into a single dataframe\n",
    "combined_df = pd.concat([df_2020, df_2021, df_2022], ignore_index=True)\n",
    "\n",
    "# Save the combined dataframe to a new CSV file\n",
    "# combined_df.to_csv(\"WITS_combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for consistency\n",
    "combined_df = combined_df.rename(columns={\n",
    "    \"Year\": \"YEAR\",\n",
    "    \"Partner Name\": \"COUNTRY\",\n",
    "    \"Export (US$ Thousand)\": \"EXPORT_USD\",\n",
    "    \"Import (US$ Thousand)\": \"IMPORT_USD\",\n",
    "    \"Export Partner Share (%)\": \"EXPORT_SHARE\",\n",
    "    \"Import Partner Share (%)\": \"IMPORT_SHARE\",\n",
    "    \"No Of exported HS6 digit Products\": \"EXPORT_PRODUCTS\",\n",
    "    \"No Of imported HS6 digit Products\": \"IMPORT_PRODUCTS\",\n",
    "})\n",
    "\n",
    "# Change export and import values to * 1000\n",
    "combined_df[\"EXPORT_USD\"] = combined_df[\"EXPORT_USD\"] * 1000\n",
    "combined_df[\"IMPORT_USD\"] = combined_df[\"IMPORT_USD\"] * 1000\n",
    "\n",
    "relevant_columns = [\n",
    "    \"YEAR\",\n",
    "    \"COUNTRY\",\n",
    "    \"EXPORT_USD\",\n",
    "    \"IMPORT_USD\",\n",
    "    \"EXPORT_SHARE\",\n",
    "    \"IMPORT_SHARE\",\n",
    "    \"EXPORT_PRODUCTS\",\n",
    "    \"IMPORT_PRODUCTS\",\n",
    "] \n",
    "\n",
    "# Change missing values in EXPORT_USD, IMPORT_USD, EXPORT_SHARE, and IMPORT_SHARE to 0\n",
    "combined_df[\"EXPORT_USD\"] = combined_df[\"EXPORT_USD\"].fillna(0)\n",
    "combined_df[\"IMPORT_USD\"] = combined_df[\"IMPORT_USD\"].fillna(0)\n",
    "combined_df[\"EXPORT_SHARE\"] = combined_df[\"EXPORT_SHARE\"].fillna(0)\n",
    "combined_df[\"IMPORT_SHARE\"] = combined_df[\"IMPORT_SHARE\"].fillna(0)\n",
    "\n",
    "# Change missing values in EXPORT_PRODUCTS and IMPORT_PRODUCTS to 0\n",
    "combined_df[\"EXPORT_PRODUCTS\"] = combined_df[\"EXPORT_PRODUCTS\"].fillna(0)\n",
    "combined_df[\"IMPORT_PRODUCTS\"] = combined_df[\"IMPORT_PRODUCTS\"].fillna(0)\n",
    "\n",
    "# Create a new dataframe with only the relevant columns\n",
    "cleaned_df = combined_df[relevant_columns]\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "cleaned_df.to_csv(\"./data/cleaned/WITS_combined_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YEAR      COUNTRY    EXPORT_USD    IMPORT_USD  EXPORT_SHARE  IMPORT_SHARE  \\\n",
      "0  2020        Aruba  7.744964e+08  1.558763e+08          0.00          0.00   \n",
      "1  2020  Afghanistan  8.712275e+09  1.821494e+09          0.05          0.01   \n",
      "2  2020       Angola  7.582954e+09  2.390030e+10          0.04          0.14   \n",
      "3  2020      Anguila  1.494505e+08  3.442044e+07          0.00          0.00   \n",
      "4  2020      Albania  5.245674e+09  2.472226e+09          0.03          0.01   \n",
      "\n",
      "   EXPORT_PRODUCTS  IMPORT_PRODUCTS  \n",
      "0           2658.0              901  \n",
      "1           3348.0             1510  \n",
      "2           3810.0             1465  \n",
      "3           1119.0              426  \n",
      "4           3801.0             2090  \n"
     ]
    }
   ],
   "source": [
    "print(cleaned_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCI (Trade Cost Index) Dataset\n",
    "It measures the relative cost of trading internationally versus domestically through an indirect estimation of overall trade frictions, which are then decomposed into specific trade cost components. The index relies on estimates of bilateral trade costs for 43 economies and 31 sectors from 2000 to 2018, tracking changes over time and analyzing trade cost distribution across economies and sectors. \n",
    "\n",
    "Information on columns:\n",
    "1. YEAR\n",
    "2. COUNTRY\n",
    "3. SECTOR_ID\n",
    "4. TCI: Trade Cost Index\n",
    "5. ICI: Import Concentration Index\n",
    "6. ECI: Export Concentration Index\n",
    "7. SECTOR: Sector description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_file_path = \"./data/original/TCI_economy_sector.xlsx\"\n",
    "output_file_path = \"./data/cleaned/TCI_cleaned.csv\"\n",
    "\n",
    "xls = pd.ExcelFile(raw_file_path)\n",
    "trade_cost_df = xls.parse(\"Trade cost index\")\n",
    "sector_description_df = xls.parse(\"Sector description\")\n",
    "\n",
    "# Merge Trade Cost Index with Sector Descriptions\n",
    "trade_cost_df = trade_cost_df.merge(sector_description_df, on=\"SECTOR CODE\", how=\"left\")\n",
    "\n",
    "# Standardize column names to match the provided cleaned dataset\n",
    "trade_cost_df.rename(\n",
    "    columns={\n",
    "        \"ECONOMY\": \"COUNTRY\",\n",
    "        \"SECTOR CODE\": \"SECTOR_ID\",\n",
    "        \"SECTOR DESCRIPTION\": \"SECTOR\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Drop rows with missing TCI values\n",
    "trade_cost_df.dropna(subset=[\"TCI\"], inplace=True)\n",
    "\n",
    "# Convert 'YEAR' column to integer format\n",
    "trade_cost_df[\"YEAR\"] = trade_cost_df[\"YEAR\"].astype(int)\n",
    "\n",
    "# Select only necessary columns to match the provided dataset\n",
    "final_cleaned_trade_cost = trade_cost_df[\n",
    "    [\"YEAR\", \"COUNTRY\", \"SECTOR_ID\", \"TCI\", \"ICI\", \"ECI\", \"SECTOR\"]\n",
    "]\n",
    "\n",
    "# Save the cleaned dataset to CSV\n",
    "final_cleaned_trade_cost.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YEAR COUNTRY SECTOR_ID       TCI       ICI       ECI  \\\n",
      "0  2000     AUS         1  3.772682  3.843992  3.300657   \n",
      "1  2000     AUS         2  2.170142  2.081942  2.417107   \n",
      "2  2000     AUS         3  3.374180  3.391041  3.109401   \n",
      "3  2000     AUS       4&5  2.210107  2.443970  2.021629   \n",
      "4  2000     AUS         6  3.502224  3.626578  3.156503   \n",
      "\n",
      "                                       SECTOR  \n",
      "0  Agriculture, Hunting, Forestry and Fishing  \n",
      "1                        Mining and Quarrying  \n",
      "2                 Food, Beverages and Tobacco  \n",
      "3     Textiles; Leather Products and Footwear  \n",
      "4          Wood and Products of Wood and Cork  \n"
     ]
    }
   ],
   "source": [
    "print(final_cleaned_trade_cost.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPR (Geopolitical Risk Index) Dataset\n",
    "It is an indicator used to measure the level of geopolitical risk worldwide at a specific point in time, along with 44 country-specific indexes. The GPR index is derived from an automated text search of digital archives from 10 major newspapers. It is calculated by measuring the proportion of news articles each month that discuss adverse geopolitical events. The index categorizes these events into the following eight groups: war threats, peace threats, military buildups, nuclear threats, terror threats, beginning of war, escalation of war, and terror acts.\n",
    "\n",
    "Information on columns:\n",
    "\n",
    "Current risk\n",
    "1. MONTH\n",
    "2. COUNTRY\n",
    "3. GPR_SCORE\n",
    "\n",
    "Historical risk\n",
    "1. MONTH\n",
    "2. COUNTRY\n",
    "3. GPR_SCORE\n",
    "\n",
    "Global risk\n",
    "1. MONTH - The time period for the measurement\n",
    "2. GPR - The main Geopolitical Risk Index value\n",
    "3. GPRT - \"Geopolitical Risk Threats\" component\n",
    "4. GPRA - \"Geopolitical Risk Acts\" component\n",
    "5. GPRH - Historical Geopolitical Risk Index\n",
    "6. GPRHT - Historical Geopolitical Risk Threats\n",
    "7. GPRHA - Historical Geopolitical Risk Acts\n",
    "8. SHARE_GPR - Share or proportion of current geopolitical risk\n",
    "9. SHARE_GPRH - Share or proportion of historical geopolitical risk\n",
    "10. SHAREH_CAT_1 through SHAREH_CAT_8 - Shares of the eight event categories mentioned\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Use the pandas import that's already available in the notebook\n",
    "\n",
    "def read_excel_file(path, sheet_name=\"Sheet1\"):\n",
    "  try:\n",
    "    xls = pd.ExcelFile(path)\n",
    "    return xls.parse(sheet_name)\n",
    "  except Exception as e:\n",
    "    print(f\"Error reading file {path}: {e}\")\n",
    "    raise\n",
    "\n",
    "def melt_risk_data(df, prefix):\n",
    "  # Select columns starting with the given prefix\n",
    "  cols = [col for col in df.columns if col.startswith(prefix)]\n",
    "  long_df = df.melt(\n",
    "    id_vars=[\"month\"],\n",
    "    value_vars=cols,\n",
    "    var_name=\"COUNTRY\",\n",
    "    value_name=\"GPR_SCORE\",\n",
    "  )\n",
    "  # Remove the prefix from the country names\n",
    "  long_df[\"COUNTRY\"] = long_df[\"COUNTRY\"].str.replace(prefix, \"\", regex=False)\n",
    "  long_df.dropna(subset=[\"GPR_SCORE\"], inplace=True)\n",
    "  return long_df[[\"month\", \"COUNTRY\", \"GPR_SCORE\"]]\n",
    "\n",
    "# Set paths\n",
    "raw_gpr_path = Path(\"./data/original/data_gpr_export.xlsx\")\n",
    "output_dir = Path(\"./data/cleaned\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "output_gpr_base = output_dir / \"GPR_export\"\n",
    "\n",
    "# Read and preprocess the raw DataFrame\n",
    "raw_gpr_df = read_excel_file(raw_gpr_path)\n",
    "\n",
    "# Rename the first column to \"month\" if necessary and convert it to datetime\n",
    "first_col = raw_gpr_df.columns[0]\n",
    "if first_col != \"month\":\n",
    "  raw_gpr_df.rename(columns={first_col: \"month\"}, inplace=True)\n",
    "raw_gpr_df[\"month\"] = pd.to_datetime(raw_gpr_df[\"month\"], errors=\"coerce\")\n",
    "\n",
    "# Create long format DataFrames for current and historical risk data\n",
    "current_risk_df = melt_risk_data(raw_gpr_df, \"GPRC_\")\n",
    "historical_risk_df = melt_risk_data(raw_gpr_df, \"GPRHC_\")\n",
    "\n",
    "# Define global risk metric columns and extract them if available\n",
    "global_risk_columns = [\n",
    "  \"month\",\n",
    "  \"GPR\",\n",
    "  \"GPRT\",\n",
    "  \"GPRA\",\n",
    "  \"GPRH\",\n",
    "  \"GPRHT\",\n",
    "  \"GPRHA\",\n",
    "  \"SHARE_GPR\",\n",
    "  \"SHARE_GPRH\",\n",
    "  \"SHAREH_CAT_1\",\n",
    "  \"SHAREH_CAT_2\",\n",
    "  \"SHAREH_CAT_3\",\n",
    "  \"SHAREH_CAT_4\",\n",
    "  \"SHAREH_CAT_5\",\n",
    "  \"SHAREH_CAT_6\",\n",
    "  \"SHAREH_CAT_7\",\n",
    "  \"SHAREH_CAT_8\",\n",
    "]\n",
    "global_risk_df = raw_gpr_df[global_risk_columns].dropna(how=\"any\")\n",
    "\n",
    "# Rename month to MONTH\n",
    "current_risk_df.rename(columns={\"month\": \"MONTH\"}, inplace=True)\n",
    "global_risk_df.rename(columns={\"month\": \"MONTH\"}, inplace=True)\n",
    "historical_risk_df.rename(columns={\"month\": \"MONTH\"}, inplace=True)\n",
    "\n",
    "# Save the cleaned datasets as separate CSV files\n",
    "global_risk_df.to_csv(f\"{output_gpr_base}_global_risk.csv\", index=False)\n",
    "current_risk_df.to_csv(f\"{output_gpr_base}_current_risk.csv\", index=False)\n",
    "historical_risk_df.to_csv(f\"{output_gpr_base}_historical_risk.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MONTH COUNTRY  GPR_SCORE\n",
      "1020 1985-01-01     ARG   0.094959\n",
      "1021 1985-02-01     ARG   0.027729\n",
      "1022 1985-03-01     ARG   0.081360\n",
      "1023 1985-04-01     ARG   0.031211\n",
      "1024 1985-05-01     ARG   0.072197\n"
     ]
    }
   ],
   "source": [
    "print(current_risk_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       MONTH COUNTRY  GPR_SCORE\n",
      "0 1900-01-01     ARG   0.025893\n",
      "1 1900-02-01     ARG   0.013941\n",
      "2 1900-03-01     ARG   0.012883\n",
      "3 1900-04-01     ARG   0.000000\n",
      "4 1900-05-01     ARG   0.000000\n"
     ]
    }
   ],
   "source": [
    "print(historical_risk_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MONTH         GPR        GPRT        GPRA        GPRH       GPRHT  \\\n",
      "1020 1985-01-01  102.173378  107.574173   89.647491   87.153206  101.083145   \n",
      "1021 1985-02-01  117.102020  126.442726   96.601669   99.552269  127.213127   \n",
      "1022 1985-03-01  124.778152  127.070854  116.987274  103.822472  131.811447   \n",
      "1023 1985-04-01   87.929001   94.640198   73.757797   74.304153   91.295639   \n",
      "1024 1985-05-01  103.262848  111.159782   92.276726   84.364098  101.910835   \n",
      "\n",
      "          GPRHA  SHARE_GPR  SHARE_GPRH  SHAREH_CAT_1  SHAREH_CAT_2  \\\n",
      "1020  75.144287   3.064572    3.143987      0.318256      0.067509   \n",
      "1021  75.103569   3.512339    3.591274      0.391027      0.061741   \n",
      "1022  78.716949   3.742576    3.745318      0.392367      0.098092   \n",
      "1023  56.713566   2.637328    2.680467      0.283086      0.061925   \n",
      "1024  73.034920   3.097249    3.043372      0.317357      0.073236   \n",
      "\n",
      "      SHAREH_CAT_3  SHAREH_CAT_4  SHAREH_CAT_5  SHAREH_CAT_6  SHAREH_CAT_7  \\\n",
      "1020      0.810107      0.983701      0.096441      0.260392      0.790819   \n",
      "1021      0.936407      1.162791      0.246964      0.339576      0.596831   \n",
      "1022      0.998752      1.239522      0.169431      0.428036      0.793651   \n",
      "1023      0.964260      0.504246      0.185775      0.380396      0.415782   \n",
      "1024      1.082269      0.553340      0.219709      0.309220      0.537066   \n",
      "\n",
      "      SHAREH_CAT_8  \n",
      "1020      0.617224  \n",
      "1021      0.740893  \n",
      "1022      0.561798  \n",
      "1023      0.468861  \n",
      "1024      0.724225  \n"
     ]
    }
   ],
   "source": [
    "print(global_risk_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
