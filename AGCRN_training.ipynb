{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sector Dictionary\n",
    "0. Category 1 (Agri)\n",
    "1. Category 2 (Mining)\n",
    "2. Category 3 (Construction)\n",
    "3. Category 4 (Textile)\n",
    "4. Category 5 (Transport Svcs)\n",
    "5. Category 6 (ICT)\n",
    "6. Category 7 (Health, pharm, sports etc)\n",
    "7. Category 8 (Govt, Millitary, Misc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country_a</th>\n",
       "      <th>country_b</th>\n",
       "      <th>bec_1</th>\n",
       "      <th>bec_2</th>\n",
       "      <th>bec_3</th>\n",
       "      <th>bec_4</th>\n",
       "      <th>bec_5</th>\n",
       "      <th>bec_6</th>\n",
       "      <th>bec_7</th>\n",
       "      <th>bec_8</th>\n",
       "      <th>D</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ARE</td>\n",
       "      <td>AUS</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.060739e+09</td>\n",
       "      <td>0.620151</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ARE</td>\n",
       "      <td>CHE</td>\n",
       "      <td>3.797882e+06</td>\n",
       "      <td>1.355991e+06</td>\n",
       "      <td>6.939408e+06</td>\n",
       "      <td>3.759398e+08</td>\n",
       "      <td>2.690339e+06</td>\n",
       "      <td>9.364289e+05</td>\n",
       "      <td>4.422947e+07</td>\n",
       "      <td>9.824469e+07</td>\n",
       "      <td>0.586050</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ARE</td>\n",
       "      <td>CHN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.953953e+09</td>\n",
       "      <td>0.635445</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ARE</td>\n",
       "      <td>DEU</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.159614e+08</td>\n",
       "      <td>0.566027</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ARE</td>\n",
       "      <td>FRA</td>\n",
       "      <td>4.972880e+07</td>\n",
       "      <td>4.680296e+07</td>\n",
       "      <td>9.306163e+07</td>\n",
       "      <td>7.307789e+07</td>\n",
       "      <td>9.781168e+07</td>\n",
       "      <td>1.751175e+07</td>\n",
       "      <td>1.162716e+08</td>\n",
       "      <td>2.462986e+08</td>\n",
       "      <td>0.620551</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 country_a country_b         bec_1         bec_2         bec_3  \\\n",
       "0           0       ARE       AUS  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1           1       ARE       CHE  3.797882e+06  1.355991e+06  6.939408e+06   \n",
       "2           2       ARE       CHN  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "3           3       ARE       DEU  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "4           4       ARE       FRA  4.972880e+07  4.680296e+07  9.306163e+07   \n",
       "\n",
       "          bec_4         bec_5         bec_6         bec_7         bec_8  \\\n",
       "0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  1.060739e+09   \n",
       "1  3.759398e+08  2.690339e+06  9.364289e+05  4.422947e+07  9.824469e+07   \n",
       "2  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  2.953953e+09   \n",
       "3  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  7.159614e+08   \n",
       "4  7.307789e+07  9.781168e+07  1.751175e+07  1.162716e+08  2.462986e+08   \n",
       "\n",
       "          D  year  \n",
       "0  0.620151  2006  \n",
       "1  0.586050  2006  \n",
       "2  0.635445  2006  \n",
       "3  0.566027  2006  \n",
       "4  0.620551  2006  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp=pd.read_csv('../data/final/final_training_model_data.csv',header=0)\n",
    "# temp.head()\n",
    "# temp.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "# temp=temp[(temp['country_a']!='ARE')& (temp['country_b']!='ARE')]\n",
    "# temp.to_csv('../data/final/without_ARE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_countries=17\n",
    "num_country_pairs=num_countries*(num_countries-1) \n",
    "num_sectors=8 # 8 sectors\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        # Model structure\n",
    "        self.num_nodes = num_country_pairs  \n",
    "        self.input_dim = num_sectors+1    # e.g. sectorial export volume + composite\n",
    "        self.rnn_units = 66\n",
    "        self.output_dim = num_sectors   # e.g., predict only the sectorial export volume\n",
    "        self.horizon = 3      # forecast 3 steps ahead\n",
    "        self.num_layers = 1\n",
    "        self.cheb_k = 2\n",
    "        self.embed_dim = 6\n",
    "        self.default_graph = True  \n",
    "        self.log_dir = './logs/'\n",
    "        self.debug = False\n",
    "        self.model='AGCRN'\n",
    "        self.normaliser = 'max11'\n",
    "        self.device='cpu'\n",
    "        self.batch_size=4 # 4/7 depending on results\n",
    "        self.mode='train'\n",
    "        # Training\n",
    "        self.seed=10\n",
    "        self.loss_func= 'mse'\n",
    "        self.epochs = 50\n",
    "        self.lr_init = 0.0059745480826864684\n",
    "        self.lr_decay = True\n",
    "        self.lr_decay_step = '5,20,40,70'\n",
    "        self.lr_decay_rate = 0.17039700074755165\n",
    "        self.early_stop = True\n",
    "        self.early_stop_patience = 5\n",
    "        self.teacher_forcing = True\n",
    "        self.tf_decay_steps = 20\n",
    "        self.real_value = False\n",
    "        self.grad_norm = True\n",
    "        self.max_grad_norm = 5\n",
    "        self.weight_decay = 0.0001\n",
    "        # Testing\n",
    "        self.mae_thresh=None\n",
    "        self.mape_thresh=0.\n",
    "\n",
    "        #Logging\n",
    "        self.log_step = 20\n",
    "        self.plot=True\n",
    "\n",
    "    def set_args(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Update attributes of Args dynamically based on the kwargs.\n",
    "        If a key doesn't match an existing attribute, a warning is printed.\n",
    "        \"\"\"\n",
    "        for key, value in kwargs.items():\n",
    "            if hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "            else:\n",
    "                print(f\"Warning: '{key}' is not a recognized attribute of the Args class.\")\n",
    "\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp=pd.read_csv('../data/final/without_ARE.csv',header=0) #i will only have 2007 to 2023 now\n",
    "# temp_only_d=temp[['D','country_a','country_b','year']]\n",
    "# temp.drop(columns=['Unnamed: 0','D'],inplace=True)\n",
    "# temp.sort_values(by=['country_a','country_b','year'],inplace=True)\n",
    "# bec_columns = [f'bec_{i}' for i in range(1, 9)]\n",
    "# for col in bec_columns:\n",
    "#     # Create a new column to store the percentage change.\n",
    "#     temp[f'pct_{col}'] = temp.groupby(['country_a', 'country_b'])[col].pct_change() * 100\n",
    "# temp.dropna(inplace=True)\n",
    "# temp.reset_index(drop=True,inplace=True)\n",
    "# temp=temp.merge(temp_only_d, on=['country_a','country_b','year'], how='left')\n",
    "# temp.drop(columns=bec_columns,inplace=True)\n",
    "# temp.rename(columns={'pct_bec_1':'bec_1','pct_bec_2':'bec_2','pct_bec_3':'bec_3','pct_bec_4':'bec_4','pct_bec_5':'bec_5','pct_bec_6':'bec_6','pct_bec_7':'bec_7','pct_bec_8':'bec_8'},inplace=True)\n",
    "# temp.to_csv('../data/final/without_ARE_pct.csv',index=False)\n",
    "# fbic_data=fbic_data.rename(columns={'iso3a':'country_a','iso3b':'country_b'})\n",
    "# training_data=pd.read_csv('../data/final/training_model_data.csv',header=0)\n",
    "# training_data=training_data[['country_a','country_b','bec_1','bec_2','bec_3','bec_4','bec_5','bec_6','bec_7','bec_8','sentiment_index','tradeagreementindex','year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp=pd.read_csv('../data/final/compiled_model_data.csv',header=0)\n",
    "# temp=temp.reset_index(drop=True)\n",
    "# temp=temp[['country_a','country_b','bec_1','bec_2','bec_3','bec_4','bec_5','bec_6','bec_7','bec_8','D','year']]\n",
    "# temp=temp[(temp['year']>=2006) & (temp['year']<=2020)]\n",
    "# temp.to_csv('../data/final/final_training_model_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation to pipeline data into model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_tensor(csv_file):\n",
    "    \"\"\"\n",
    "    Reads a CSV file with columns:\n",
    "      country1, country2, sector1, sector2, ..., sector8, sentiment, year\n",
    "    and returns a tensor of shape (T, N, D), where:\n",
    "      T = number of years,\n",
    "      N = number of unique country pairs,\n",
    "      D = num of sectors + features.\n",
    "    Also returns the sorted list of years and country pair nodes.\n",
    "    \"\"\"\n",
    "    # Read the CSV into a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Ensure the 'year' column is integer (if needed)\n",
    "    df['year'] = df['year'].astype(int)\n",
    "    \n",
    "    # Get a sorted list of unique years\n",
    "    years = sorted(df['year'].unique())\n",
    "    T = len(years)\n",
    "    \n",
    "    # Get all unique country pairs\n",
    "    pairs_df = df[['country_a', 'country_b']].drop_duplicates()\n",
    "    # Create a sorted list of tuples (country1, country2) for consistent node ordering\n",
    "    country_pairs = sorted([tuple(x) for x in pairs_df.values])\n",
    "    N = len(country_pairs)\n",
    "    \n",
    "    # Number of features (8 sectors + 1 sentiment)\n",
    "    D = 9\n",
    "\n",
    "    # Initialize an empty numpy array for the tensor data\n",
    "    tensor_data = np.empty((T, N, D), dtype=float)\n",
    "    \n",
    "    # Loop over each year and each country pair to fill in the tensor\n",
    "    for t, year in enumerate(years):\n",
    "        # Get data for the current year\n",
    "        df_year = df[df['year'] == year]\n",
    "        for n, (c1, c2) in enumerate(country_pairs):\n",
    "            # Filter rows for the current country pair\n",
    "            row = df_year[(df_year['country_a'] == c1) & (df_year['country_b'] == c2)]\n",
    "            if not row.empty:\n",
    "                # Extract the 8 sector columns and the sentiment column.\n",
    "                # Assumes these columns are named exactly as shown.\n",
    "                features = row.iloc[0][['bec_1', 'bec_2', 'bec_3', 'bec_4', \n",
    "                                         'bec_5', 'bec_6', 'bec_7', 'bec_8', 'D']].values\n",
    "                tensor_data[t, n, :] = features.astype(float)\n",
    "            else:\n",
    "                # If a record is missing for a given year/country pair, fill with zeros (or choose another strategy)\n",
    "                tensor_data[t, n, :] = np.zeros(D)\n",
    "                \n",
    "    return tensor_data, years, country_pairs\n",
    "\n",
    "def group_into_windows(tensor_data, window_size):\n",
    "    \"\"\"\n",
    "    Given a tensor of shape (T, N, D), group the data into overlapping windows.\n",
    "    Each window is of length window_size\n",
    "    Returns a numpy array of shape (num_samples, window_size, N, D).\n",
    "    \"\"\"\n",
    "    T, N, D = tensor_data.shape\n",
    "    num_samples = T - window_size + 1  # sliding window with stride 1\n",
    "    windows = []\n",
    "    for i in range(num_samples):\n",
    "        window = tensor_data[i: i + window_size]  # shape: (window_size, N, D)\n",
    "        windows.append(window)\n",
    "    windows = np.stack(windows)  # shape: (num_samples, window_size, N, D)\n",
    "    return windows\n",
    "\n",
    "def split_input_target_direct(windows, input_len, horizon=3):\n",
    "    \"\"\"\n",
    "    Splits each window into input and a single target that is horizon steps forward.\n",
    "    \n",
    "    windows: numpy array of shape (num_samples, window_size, N, D)\n",
    "              where window_size = input_len + horizon.\n",
    "    input_len: number of time steps used as input.\n",
    "    horizon: steps forward to pick the target (here, horizon=3).\n",
    "    \n",
    "    Returns:\n",
    "      x: inputs of shape (num_samples, input_len, N, D)\n",
    "      y: targets of shape (num_samples, N, 8), which are the first 8 features of the target time step.\n",
    "    \"\"\"\n",
    "    # x: first input_len time steps (e.g., years 2006-2009 if input_len=4)\n",
    "    x = windows[:, :input_len]  \n",
    "    # y_full: the time step exactly horizon steps forward (i.e., index input_len + horizon - 1)\n",
    "    # y_full = windows[:, input_len + horizon-1]  \n",
    "    y_full = windows[:, input_len:input_len + horizon]\n",
    "    # y: only the first 8 features from the predicted time step (ignoring sentiment_index and tradeagreementindex)\n",
    "    y = y_full[..., :8]\n",
    "    return x, y\n",
    "\n",
    "def train_val_split(x, y, val_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Splits the data into train and validation sets by ratio.\n",
    "    \"\"\"\n",
    "    num_samples = x.shape[0]\n",
    "    split_index = int(num_samples * (1 - val_ratio))\n",
    "    x_train, y_train = x[:split_index], y[:split_index]\n",
    "    x_val, y_val = x[split_index:], y[split_index:]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AGCRN.lib.dataloader import normalize_dataset\n",
    "\n",
    "#convert csv to tensor\n",
    "training_data_tensor, years, country_pairs = csv_to_tensor('./data/final/without_ARE_pct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for year 2007:\n",
      "[[288.52271933 279.03809661 204.2020891  ... 174.11212633 196.4292726\n",
      "    0.55853787]\n",
      " [ 38.17646947  31.0278394   36.47753454 ...  63.61518823 -17.67302399\n",
      "    0.56009085]\n",
      " [ -0.29719578   3.56841464  14.62732324 ...  20.83388439 -32.08029114\n",
      "    0.59298115]\n",
      " ...\n",
      " [ -0.33857947  18.18635501  26.43173842 ...  16.49221368  18.26733175\n",
      "    0.3671412 ]\n",
      " [ -1.33240313  -4.83563772  47.63716963 ... -16.34540145  10.97735679\n",
      "    0.46350549]\n",
      " [ 27.02208384 -18.73648827  26.17908911 ...  44.25435862  25.63200196\n",
      "    0.57982181]]\n",
      "Features for ('AUS', 'CHE') in 2007:\n",
      "[2.88522719e+02 2.79038097e+02 2.04202089e+02 1.18079757e+03\n",
      " 1.39229930e+02 6.28642389e+02 1.74112126e+02 1.96429273e+02\n",
      " 5.58537867e-01]\n"
     ]
    }
   ],
   "source": [
    "# Inspect data to check\n",
    "print(\"Data for year {}:\".format(years[0]))\n",
    "print(training_data_tensor[0])  # prints the data for all nodes/features for the first year\n",
    "\n",
    "print(\"Features for {} in {}:\".format(country_pairs[0], years[0]))\n",
    "print(training_data_tensor[0, 0, :]) # prints the features for the first country pair in the first year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country Dictionary (ordered by alphabetical order)\n",
    "\n",
    "0. Australia (AUS)\n",
    "1. Switzerland (CHE)\n",
    "2. China (CHN)\n",
    "3. Germany (DEU)\n",
    "4. France (FRA)\n",
    "5. Hong Kong, China (HKG)\n",
    "6. Indonesia (IDN)\n",
    "7. India (IND)\n",
    "8. Japan (JPN)\n",
    "9. Korea, Rep. (KOR)\n",
    "10. Malaysia (MYS)\n",
    "11. Netherlands (NLD)\n",
    "12. Philippines (PHL)\n",
    "13. Singapore (SGP)\n",
    "14. Thailand (THA)\n",
    "15. United States (USA)\n",
    "16. Vietnam (VNM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of country pairs for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AUS', 'CHE'),\n",
       " ('AUS', 'CHN'),\n",
       " ('AUS', 'DEU'),\n",
       " ('AUS', 'FRA'),\n",
       " ('AUS', 'HKG'),\n",
       " ('AUS', 'IDN'),\n",
       " ('AUS', 'IND'),\n",
       " ('AUS', 'JPN'),\n",
       " ('AUS', 'KOR'),\n",
       " ('AUS', 'MYS'),\n",
       " ('AUS', 'NLD'),\n",
       " ('AUS', 'PHL'),\n",
       " ('AUS', 'SGP'),\n",
       " ('AUS', 'THA'),\n",
       " ('AUS', 'USA'),\n",
       " ('AUS', 'VNM'),\n",
       " ('CHE', 'AUS'),\n",
       " ('CHE', 'CHN'),\n",
       " ('CHE', 'DEU'),\n",
       " ('CHE', 'FRA'),\n",
       " ('CHE', 'HKG'),\n",
       " ('CHE', 'IDN'),\n",
       " ('CHE', 'IND'),\n",
       " ('CHE', 'JPN'),\n",
       " ('CHE', 'KOR'),\n",
       " ('CHE', 'MYS'),\n",
       " ('CHE', 'NLD'),\n",
       " ('CHE', 'PHL'),\n",
       " ('CHE', 'SGP'),\n",
       " ('CHE', 'THA'),\n",
       " ('CHE', 'USA'),\n",
       " ('CHE', 'VNM'),\n",
       " ('CHN', 'AUS'),\n",
       " ('CHN', 'CHE'),\n",
       " ('CHN', 'DEU'),\n",
       " ('CHN', 'FRA'),\n",
       " ('CHN', 'HKG'),\n",
       " ('CHN', 'IDN'),\n",
       " ('CHN', 'IND'),\n",
       " ('CHN', 'JPN'),\n",
       " ('CHN', 'KOR'),\n",
       " ('CHN', 'MYS'),\n",
       " ('CHN', 'NLD'),\n",
       " ('CHN', 'PHL'),\n",
       " ('CHN', 'SGP'),\n",
       " ('CHN', 'THA'),\n",
       " ('CHN', 'USA'),\n",
       " ('CHN', 'VNM'),\n",
       " ('DEU', 'AUS'),\n",
       " ('DEU', 'CHE'),\n",
       " ('DEU', 'CHN'),\n",
       " ('DEU', 'FRA'),\n",
       " ('DEU', 'HKG'),\n",
       " ('DEU', 'IDN'),\n",
       " ('DEU', 'IND'),\n",
       " ('DEU', 'JPN'),\n",
       " ('DEU', 'KOR'),\n",
       " ('DEU', 'MYS'),\n",
       " ('DEU', 'NLD'),\n",
       " ('DEU', 'PHL'),\n",
       " ('DEU', 'SGP'),\n",
       " ('DEU', 'THA'),\n",
       " ('DEU', 'USA'),\n",
       " ('DEU', 'VNM'),\n",
       " ('FRA', 'AUS'),\n",
       " ('FRA', 'CHE'),\n",
       " ('FRA', 'CHN'),\n",
       " ('FRA', 'DEU'),\n",
       " ('FRA', 'HKG'),\n",
       " ('FRA', 'IDN'),\n",
       " ('FRA', 'IND'),\n",
       " ('FRA', 'JPN'),\n",
       " ('FRA', 'KOR'),\n",
       " ('FRA', 'MYS'),\n",
       " ('FRA', 'NLD'),\n",
       " ('FRA', 'PHL'),\n",
       " ('FRA', 'SGP'),\n",
       " ('FRA', 'THA'),\n",
       " ('FRA', 'USA'),\n",
       " ('FRA', 'VNM'),\n",
       " ('HKG', 'AUS'),\n",
       " ('HKG', 'CHE'),\n",
       " ('HKG', 'CHN'),\n",
       " ('HKG', 'DEU'),\n",
       " ('HKG', 'FRA'),\n",
       " ('HKG', 'IDN'),\n",
       " ('HKG', 'IND'),\n",
       " ('HKG', 'JPN'),\n",
       " ('HKG', 'KOR'),\n",
       " ('HKG', 'MYS'),\n",
       " ('HKG', 'NLD'),\n",
       " ('HKG', 'PHL'),\n",
       " ('HKG', 'SGP'),\n",
       " ('HKG', 'THA'),\n",
       " ('HKG', 'USA'),\n",
       " ('HKG', 'VNM'),\n",
       " ('IDN', 'AUS'),\n",
       " ('IDN', 'CHE'),\n",
       " ('IDN', 'CHN'),\n",
       " ('IDN', 'DEU'),\n",
       " ('IDN', 'FRA'),\n",
       " ('IDN', 'HKG'),\n",
       " ('IDN', 'IND'),\n",
       " ('IDN', 'JPN'),\n",
       " ('IDN', 'KOR'),\n",
       " ('IDN', 'MYS'),\n",
       " ('IDN', 'NLD'),\n",
       " ('IDN', 'PHL'),\n",
       " ('IDN', 'SGP'),\n",
       " ('IDN', 'THA'),\n",
       " ('IDN', 'USA'),\n",
       " ('IDN', 'VNM'),\n",
       " ('IND', 'AUS'),\n",
       " ('IND', 'CHE'),\n",
       " ('IND', 'CHN'),\n",
       " ('IND', 'DEU'),\n",
       " ('IND', 'FRA'),\n",
       " ('IND', 'HKG'),\n",
       " ('IND', 'IDN'),\n",
       " ('IND', 'JPN'),\n",
       " ('IND', 'KOR'),\n",
       " ('IND', 'MYS'),\n",
       " ('IND', 'NLD'),\n",
       " ('IND', 'PHL'),\n",
       " ('IND', 'SGP'),\n",
       " ('IND', 'THA'),\n",
       " ('IND', 'USA'),\n",
       " ('IND', 'VNM'),\n",
       " ('JPN', 'AUS'),\n",
       " ('JPN', 'CHE'),\n",
       " ('JPN', 'CHN'),\n",
       " ('JPN', 'DEU'),\n",
       " ('JPN', 'FRA'),\n",
       " ('JPN', 'HKG'),\n",
       " ('JPN', 'IDN'),\n",
       " ('JPN', 'IND'),\n",
       " ('JPN', 'KOR'),\n",
       " ('JPN', 'MYS'),\n",
       " ('JPN', 'NLD'),\n",
       " ('JPN', 'PHL'),\n",
       " ('JPN', 'SGP'),\n",
       " ('JPN', 'THA'),\n",
       " ('JPN', 'USA'),\n",
       " ('JPN', 'VNM'),\n",
       " ('KOR', 'AUS'),\n",
       " ('KOR', 'CHE'),\n",
       " ('KOR', 'CHN'),\n",
       " ('KOR', 'DEU'),\n",
       " ('KOR', 'FRA'),\n",
       " ('KOR', 'HKG'),\n",
       " ('KOR', 'IDN'),\n",
       " ('KOR', 'IND'),\n",
       " ('KOR', 'JPN'),\n",
       " ('KOR', 'MYS'),\n",
       " ('KOR', 'NLD'),\n",
       " ('KOR', 'PHL'),\n",
       " ('KOR', 'SGP'),\n",
       " ('KOR', 'THA'),\n",
       " ('KOR', 'USA'),\n",
       " ('KOR', 'VNM'),\n",
       " ('MYS', 'AUS'),\n",
       " ('MYS', 'CHE'),\n",
       " ('MYS', 'CHN'),\n",
       " ('MYS', 'DEU'),\n",
       " ('MYS', 'FRA'),\n",
       " ('MYS', 'HKG'),\n",
       " ('MYS', 'IDN'),\n",
       " ('MYS', 'IND'),\n",
       " ('MYS', 'JPN'),\n",
       " ('MYS', 'KOR'),\n",
       " ('MYS', 'NLD'),\n",
       " ('MYS', 'PHL'),\n",
       " ('MYS', 'SGP'),\n",
       " ('MYS', 'THA'),\n",
       " ('MYS', 'USA'),\n",
       " ('MYS', 'VNM'),\n",
       " ('NLD', 'AUS'),\n",
       " ('NLD', 'CHE'),\n",
       " ('NLD', 'CHN'),\n",
       " ('NLD', 'DEU'),\n",
       " ('NLD', 'FRA'),\n",
       " ('NLD', 'HKG'),\n",
       " ('NLD', 'IDN'),\n",
       " ('NLD', 'IND'),\n",
       " ('NLD', 'JPN'),\n",
       " ('NLD', 'KOR'),\n",
       " ('NLD', 'MYS'),\n",
       " ('NLD', 'PHL'),\n",
       " ('NLD', 'SGP'),\n",
       " ('NLD', 'THA'),\n",
       " ('NLD', 'USA'),\n",
       " ('NLD', 'VNM'),\n",
       " ('PHL', 'AUS'),\n",
       " ('PHL', 'CHE'),\n",
       " ('PHL', 'CHN'),\n",
       " ('PHL', 'DEU'),\n",
       " ('PHL', 'FRA'),\n",
       " ('PHL', 'HKG'),\n",
       " ('PHL', 'IDN'),\n",
       " ('PHL', 'IND'),\n",
       " ('PHL', 'JPN'),\n",
       " ('PHL', 'KOR'),\n",
       " ('PHL', 'MYS'),\n",
       " ('PHL', 'NLD'),\n",
       " ('PHL', 'SGP'),\n",
       " ('PHL', 'THA'),\n",
       " ('PHL', 'USA'),\n",
       " ('PHL', 'VNM'),\n",
       " ('SGP', 'AUS'),\n",
       " ('SGP', 'CHE'),\n",
       " ('SGP', 'CHN'),\n",
       " ('SGP', 'DEU'),\n",
       " ('SGP', 'FRA'),\n",
       " ('SGP', 'HKG'),\n",
       " ('SGP', 'IDN'),\n",
       " ('SGP', 'IND'),\n",
       " ('SGP', 'JPN'),\n",
       " ('SGP', 'KOR'),\n",
       " ('SGP', 'MYS'),\n",
       " ('SGP', 'NLD'),\n",
       " ('SGP', 'PHL'),\n",
       " ('SGP', 'THA'),\n",
       " ('SGP', 'USA'),\n",
       " ('SGP', 'VNM'),\n",
       " ('THA', 'AUS'),\n",
       " ('THA', 'CHE'),\n",
       " ('THA', 'CHN'),\n",
       " ('THA', 'DEU'),\n",
       " ('THA', 'FRA'),\n",
       " ('THA', 'HKG'),\n",
       " ('THA', 'IDN'),\n",
       " ('THA', 'IND'),\n",
       " ('THA', 'JPN'),\n",
       " ('THA', 'KOR'),\n",
       " ('THA', 'MYS'),\n",
       " ('THA', 'NLD'),\n",
       " ('THA', 'PHL'),\n",
       " ('THA', 'SGP'),\n",
       " ('THA', 'USA'),\n",
       " ('THA', 'VNM'),\n",
       " ('USA', 'AUS'),\n",
       " ('USA', 'CHE'),\n",
       " ('USA', 'CHN'),\n",
       " ('USA', 'DEU'),\n",
       " ('USA', 'FRA'),\n",
       " ('USA', 'HKG'),\n",
       " ('USA', 'IDN'),\n",
       " ('USA', 'IND'),\n",
       " ('USA', 'JPN'),\n",
       " ('USA', 'KOR'),\n",
       " ('USA', 'MYS'),\n",
       " ('USA', 'NLD'),\n",
       " ('USA', 'PHL'),\n",
       " ('USA', 'SGP'),\n",
       " ('USA', 'THA'),\n",
       " ('USA', 'VNM'),\n",
       " ('VNM', 'AUS'),\n",
       " ('VNM', 'CHE'),\n",
       " ('VNM', 'CHN'),\n",
       " ('VNM', 'DEU'),\n",
       " ('VNM', 'FRA'),\n",
       " ('VNM', 'HKG'),\n",
       " ('VNM', 'IDN'),\n",
       " ('VNM', 'IND'),\n",
       " ('VNM', 'JPN'),\n",
       " ('VNM', 'KOR'),\n",
       " ('VNM', 'MYS'),\n",
       " ('VNM', 'NLD'),\n",
       " ('VNM', 'PHL'),\n",
       " ('VNM', 'SGP'),\n",
       " ('VNM', 'THA'),\n",
       " ('VNM', 'USA')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "country_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sector Dictionary\n",
    "0. Category 1\n",
    "</br> Description: Agriculture, forestry, fishing, food, beverages, tobacco\n",
    "</br> HS Goods: 972\n",
    "\n",
    "1. Category 2\n",
    "</br>Description: Mining, quarrying, refinery, fuels, chemicals, electricity, water, waste treatment\n",
    "</br>HS Goods: 983\n",
    "\n",
    "2. Category 3\n",
    "</br>Description: Construction, wood, glass, stone, basic metals, housing, electrical appliances, furniture\n",
    "</br>HS Goods: 1313\n",
    "\n",
    "3. Category 4\n",
    "</br>Description: Textile, apparel, shoes, jewelry, leather\n",
    "</br>HS Goods: 895\n",
    "\n",
    "4. Category 5\n",
    "</br>Description: Transport equipment and services, travel, postal services\n",
    "</br>HS Goods: 180\n",
    "\n",
    "5. Category 6\n",
    "</br>Description: ICT, media, computers, business and financial services\n",
    "</br>HS Goods: 441\n",
    "\n",
    "6. Category 7\n",
    "</br>Description: Health, pharmaceuticals, education, cultural, sport\n",
    "</br>HS Goods: 178\n",
    "\n",
    "7. Category 8\n",
    "</br>Description: Government, military and other\n",
    "</br>HS Goods: 139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize the dataset by MinMax11 Normalization\n",
      "Windows shape (num_samples, input_len, N, D): (9, 6, 272, 9)\n",
      "Input shape (num_samples, horizon, N, D): (9, 3, 272, 9)\n",
      "Target shape (num_samples, N, D): (9, 3, 272, 8)\n",
      "Train samples: 7\n",
      "Validation samples: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#do normalisation\n",
    "data_to_normalize = training_data_tensor[:, :, :8]\n",
    "normalized_data, scaler = normalize_dataset(data_to_normalize, normalizer=args.normaliser,column_wise=True)\n",
    "remaining_features = training_data_tensor[:, :, 8:]\n",
    "# Get the shape dimensions\n",
    "T, N, _ = remaining_features.shape\n",
    "\n",
    "# Initialize the scaler with the desired feature range (0, 1)\n",
    "scaler2 = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# Reshape the first column of remaining_features to 2D (T*N, 1)\n",
    "col_data = remaining_features[:, :, 0].reshape(-1, 1)\n",
    "\n",
    "# Fit and transform the column data using the scaler\n",
    "col_scaled = scaler2.fit_transform(col_data)\n",
    "# Concatenate along the last axis\n",
    "normalized_training_data = np.concatenate((normalized_data, col_scaled), axis=-1)\n",
    "\n",
    "# 2. Group data into overlapping windows of 7 time periods (3 input + 3 ahead).\n",
    "windows = group_into_windows(normalized_training_data, window_size=6)\n",
    "print(\"Windows shape (num_samples, input_len, N, D):\", windows.shape)\n",
    "\n",
    "# 3. Split each window into 3 input time periods and a single target (3 steps forward).\n",
    "x, y = split_input_target_direct(windows, input_len=3, horizon=3)\n",
    "print(\"Input shape (num_samples, horizon, N, D):\", x.shape)\n",
    "print(\"Target shape (num_samples, N, D):\", y.shape)\n",
    "\n",
    "# 4. Perform train/validation split.\n",
    "x_train, y_train, x_val, y_val = train_val_split(x, y, val_ratio=0.2)\n",
    "print(\"Train samples:\", x_train.shape[0])\n",
    "print(\"Validation samples:\", x_val.shape[0])\n",
    "\n",
    "x_train_tensor=torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor=torch.tensor(y_train, dtype=torch.float32)\n",
    "train_dataset=TensorDataset(x_train_tensor, y_train_tensor)\n",
    "\n",
    "x_val_tensor=torch.tensor(x_val, dtype=torch.float32)\n",
    "y_val_tensor=torch.tensor(y_val, dtype=torch.float32)\n",
    "val_dataset=TensorDataset(x_val_tensor, y_val_tensor)\n",
    "\n",
    "# Create the dataset and data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from AGCRN.model.BasicTrainer import Trainer\n",
    "from agcrn_model import AGCRNFinal\n",
    "import os\n",
    "\n",
    "def run():\n",
    "    model=AGCRNFinal(args)\n",
    "    model=model.to(args.device)\n",
    "    \n",
    "    for p in model.parameters():\n",
    "        if p.dim() >= 2:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "        else:\n",
    "            # For biases or 1D parameters, just fill with zeros or some small constant\n",
    "            nn.init.zeros_(p)\n",
    "\n",
    "    #load dataset here\n",
    "\n",
    "    #init loss function, optimizer\n",
    "    loss=torch.nn.MSELoss().to(args.device)\n",
    "    optimizer=optim.Adam(model.parameters(),lr=args.lr_init,eps=1.0e-8,weight_decay=0.0,amsgrad=False)\n",
    "\n",
    "    #learning rate decay\n",
    "    lr_scheduler=None\n",
    "    if args.lr_decay:\n",
    "        print('Applying learning rate decay.')\n",
    "        lr_decay_steps = [int(i) for i in list(args.lr_decay_step.split(','))]\n",
    "        lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizer,\n",
    "                                                            milestones=lr_decay_steps,\n",
    "                                                            gamma=args.lr_decay_rate)\n",
    "\n",
    "    #config log path\n",
    "    current_time = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "    current_dir = os.getcwd()\n",
    "    log_dir = os.path.join(current_dir,'logs')\n",
    "    args.log_dir = log_dir\n",
    "\n",
    "    #start training\n",
    "    trainer = Trainer(model, loss, optimizer, train_loader, val_loader, scaler=scaler, #need to get these \n",
    "                    args=args, lr_scheduler=lr_scheduler)\n",
    "    if args.mode == 'train':\n",
    "        trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Tuning\n",
    "\n",
    "We test a few possible hyperparameters based on the paper and do a 80-20 split of the data and get the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Model is lr_init=0.004, embed=10, lr_decay=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: Experiment log path in: c:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\model\\logs\n",
      "2025-04-14 19:29: Experiment log path in: c:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\model\\logs\n",
      "2025-04-14 19:29: Experiment log path in: c:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\model\\logs\n",
      "2025-04-14 19:29: Experiment log path in: c:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\model\\logs\n",
      "2025-04-14 19:29: Experiment log path in: c:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\model\\logs\n",
      "2025-04-14 19:29: Train Epoch 1: 0/2 Loss: 0.366759\n",
      "2025-04-14 19:29: Train Epoch 1: 0/2 Loss: 0.366759\n",
      "2025-04-14 19:29: Train Epoch 1: 0/2 Loss: 0.366759\n",
      "2025-04-14 19:29: Train Epoch 1: 0/2 Loss: 0.366759\n",
      "2025-04-14 19:29: Train Epoch 1: 0/2 Loss: 0.366759\n",
      "2025-04-14 19:29: **********Train Epoch 1: averaged Loss: 0.348856, tf_ratio: 0.950061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying learning rate decay.\n",
      "Create Log File in:  c:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\model\\logs\\run_lr_init_0.0059745480826864684_embed_6_0.17039700074755165.log\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 1: averaged Loss: 0.348856, tf_ratio: 0.950061\n",
      "2025-04-14 19:29: **********Train Epoch 1: averaged Loss: 0.348856, tf_ratio: 0.950061\n",
      "2025-04-14 19:29: **********Train Epoch 1: averaged Loss: 0.348856, tf_ratio: 0.950061\n",
      "2025-04-14 19:29: **********Train Epoch 1: averaged Loss: 0.348856, tf_ratio: 0.950061\n",
      "2025-04-14 19:29: **********Val Epoch 1: average Loss: 0.333246\n",
      "2025-04-14 19:29: **********Val Epoch 1: average Loss: 0.333246\n",
      "2025-04-14 19:29: **********Val Epoch 1: average Loss: 0.333246\n",
      "2025-04-14 19:29: **********Val Epoch 1: average Loss: 0.333246\n",
      "2025-04-14 19:29: **********Val Epoch 1: average Loss: 0.333246\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 2: 0/2 Loss: 0.343841\n",
      "2025-04-14 19:29: Train Epoch 2: 0/2 Loss: 0.343841\n",
      "2025-04-14 19:29: Train Epoch 2: 0/2 Loss: 0.343841\n",
      "2025-04-14 19:29: Train Epoch 2: 0/2 Loss: 0.343841\n",
      "2025-04-14 19:29: Train Epoch 2: 0/2 Loss: 0.343841\n",
      "2025-04-14 19:29: **********Train Epoch 2: averaged Loss: 0.345237, tf_ratio: 0.945098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 2: averaged Loss: 0.345237, tf_ratio: 0.945098\n",
      "2025-04-14 19:29: **********Train Epoch 2: averaged Loss: 0.345237, tf_ratio: 0.945098\n",
      "2025-04-14 19:29: **********Train Epoch 2: averaged Loss: 0.345237, tf_ratio: 0.945098\n",
      "2025-04-14 19:29: **********Train Epoch 2: averaged Loss: 0.345237, tf_ratio: 0.945098\n",
      "2025-04-14 19:29: **********Val Epoch 2: average Loss: 0.323181\n",
      "2025-04-14 19:29: **********Val Epoch 2: average Loss: 0.323181\n",
      "2025-04-14 19:29: **********Val Epoch 2: average Loss: 0.323181\n",
      "2025-04-14 19:29: **********Val Epoch 2: average Loss: 0.323181\n",
      "2025-04-14 19:29: **********Val Epoch 2: average Loss: 0.323181\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 3: 0/2 Loss: 0.349874\n",
      "2025-04-14 19:29: Train Epoch 3: 0/2 Loss: 0.349874\n",
      "2025-04-14 19:29: Train Epoch 3: 0/2 Loss: 0.349874\n",
      "2025-04-14 19:29: Train Epoch 3: 0/2 Loss: 0.349874\n",
      "2025-04-14 19:29: Train Epoch 3: 0/2 Loss: 0.349874\n",
      "2025-04-14 19:29: **********Train Epoch 3: averaged Loss: 0.333762, tf_ratio: 0.939672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 3: averaged Loss: 0.333762, tf_ratio: 0.939672\n",
      "2025-04-14 19:29: **********Train Epoch 3: averaged Loss: 0.333762, tf_ratio: 0.939672\n",
      "2025-04-14 19:29: **********Train Epoch 3: averaged Loss: 0.333762, tf_ratio: 0.939672\n",
      "2025-04-14 19:29: **********Train Epoch 3: averaged Loss: 0.333762, tf_ratio: 0.939672\n",
      "2025-04-14 19:29: **********Val Epoch 3: average Loss: 0.308917\n",
      "2025-04-14 19:29: **********Val Epoch 3: average Loss: 0.308917\n",
      "2025-04-14 19:29: **********Val Epoch 3: average Loss: 0.308917\n",
      "2025-04-14 19:29: **********Val Epoch 3: average Loss: 0.308917\n",
      "2025-04-14 19:29: **********Val Epoch 3: average Loss: 0.308917\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 4: 0/2 Loss: 0.316728\n",
      "2025-04-14 19:29: Train Epoch 4: 0/2 Loss: 0.316728\n",
      "2025-04-14 19:29: Train Epoch 4: 0/2 Loss: 0.316728\n",
      "2025-04-14 19:29: Train Epoch 4: 0/2 Loss: 0.316728\n",
      "2025-04-14 19:29: Train Epoch 4: 0/2 Loss: 0.316728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 4: averaged Loss: 0.326655, tf_ratio: 0.933747\n",
      "2025-04-14 19:29: **********Train Epoch 4: averaged Loss: 0.326655, tf_ratio: 0.933747\n",
      "2025-04-14 19:29: **********Train Epoch 4: averaged Loss: 0.326655, tf_ratio: 0.933747\n",
      "2025-04-14 19:29: **********Train Epoch 4: averaged Loss: 0.326655, tf_ratio: 0.933747\n",
      "2025-04-14 19:29: **********Train Epoch 4: averaged Loss: 0.326655, tf_ratio: 0.933747\n",
      "2025-04-14 19:29: **********Val Epoch 4: average Loss: 0.290541\n",
      "2025-04-14 19:29: **********Val Epoch 4: average Loss: 0.290541\n",
      "2025-04-14 19:29: **********Val Epoch 4: average Loss: 0.290541\n",
      "2025-04-14 19:29: **********Val Epoch 4: average Loss: 0.290541\n",
      "2025-04-14 19:29: **********Val Epoch 4: average Loss: 0.290541\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 5: 0/2 Loss: 0.330303\n",
      "2025-04-14 19:29: Train Epoch 5: 0/2 Loss: 0.330303\n",
      "2025-04-14 19:29: Train Epoch 5: 0/2 Loss: 0.330303\n",
      "2025-04-14 19:29: Train Epoch 5: 0/2 Loss: 0.330303\n",
      "2025-04-14 19:29: Train Epoch 5: 0/2 Loss: 0.330303\n",
      "2025-04-14 19:29: **********Train Epoch 5: averaged Loss: 0.308275, tf_ratio: 0.927286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 5: averaged Loss: 0.308275, tf_ratio: 0.927286\n",
      "2025-04-14 19:29: **********Train Epoch 5: averaged Loss: 0.308275, tf_ratio: 0.927286\n",
      "2025-04-14 19:29: **********Train Epoch 5: averaged Loss: 0.308275, tf_ratio: 0.927286\n",
      "2025-04-14 19:29: **********Train Epoch 5: averaged Loss: 0.308275, tf_ratio: 0.927286\n",
      "2025-04-14 19:29: **********Val Epoch 5: average Loss: 0.275012\n",
      "2025-04-14 19:29: **********Val Epoch 5: average Loss: 0.275012\n",
      "2025-04-14 19:29: **********Val Epoch 5: average Loss: 0.275012\n",
      "2025-04-14 19:29: **********Val Epoch 5: average Loss: 0.275012\n",
      "2025-04-14 19:29: **********Val Epoch 5: average Loss: 0.275012\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 6: 0/2 Loss: 0.324121\n",
      "2025-04-14 19:29: Train Epoch 6: 0/2 Loss: 0.324121\n",
      "2025-04-14 19:29: Train Epoch 6: 0/2 Loss: 0.324121\n",
      "2025-04-14 19:29: Train Epoch 6: 0/2 Loss: 0.324121\n",
      "2025-04-14 19:29: Train Epoch 6: 0/2 Loss: 0.324121\n",
      "2025-04-14 19:29: **********Train Epoch 6: averaged Loss: 0.298335, tf_ratio: 0.920249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 6: averaged Loss: 0.298335, tf_ratio: 0.920249\n",
      "2025-04-14 19:29: **********Train Epoch 6: averaged Loss: 0.298335, tf_ratio: 0.920249\n",
      "2025-04-14 19:29: **********Train Epoch 6: averaged Loss: 0.298335, tf_ratio: 0.920249\n",
      "2025-04-14 19:29: **********Train Epoch 6: averaged Loss: 0.298335, tf_ratio: 0.920249\n",
      "2025-04-14 19:29: **********Val Epoch 6: average Loss: 0.273235\n",
      "2025-04-14 19:29: **********Val Epoch 6: average Loss: 0.273235\n",
      "2025-04-14 19:29: **********Val Epoch 6: average Loss: 0.273235\n",
      "2025-04-14 19:29: **********Val Epoch 6: average Loss: 0.273235\n",
      "2025-04-14 19:29: **********Val Epoch 6: average Loss: 0.273235\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 7: 0/2 Loss: 0.309028\n",
      "2025-04-14 19:29: Train Epoch 7: 0/2 Loss: 0.309028\n",
      "2025-04-14 19:29: Train Epoch 7: 0/2 Loss: 0.309028\n",
      "2025-04-14 19:29: Train Epoch 7: 0/2 Loss: 0.309028\n",
      "2025-04-14 19:29: Train Epoch 7: 0/2 Loss: 0.309028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 7: averaged Loss: 0.298878, tf_ratio: 0.912594\n",
      "2025-04-14 19:29: **********Train Epoch 7: averaged Loss: 0.298878, tf_ratio: 0.912594\n",
      "2025-04-14 19:29: **********Train Epoch 7: averaged Loss: 0.298878, tf_ratio: 0.912594\n",
      "2025-04-14 19:29: **********Train Epoch 7: averaged Loss: 0.298878, tf_ratio: 0.912594\n",
      "2025-04-14 19:29: **********Train Epoch 7: averaged Loss: 0.298878, tf_ratio: 0.912594\n",
      "2025-04-14 19:29: **********Val Epoch 7: average Loss: 0.271465\n",
      "2025-04-14 19:29: **********Val Epoch 7: average Loss: 0.271465\n",
      "2025-04-14 19:29: **********Val Epoch 7: average Loss: 0.271465\n",
      "2025-04-14 19:29: **********Val Epoch 7: average Loss: 0.271465\n",
      "2025-04-14 19:29: **********Val Epoch 7: average Loss: 0.271465\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 8: 0/2 Loss: 0.284128\n",
      "2025-04-14 19:29: Train Epoch 8: 0/2 Loss: 0.284128\n",
      "2025-04-14 19:29: Train Epoch 8: 0/2 Loss: 0.284128\n",
      "2025-04-14 19:29: Train Epoch 8: 0/2 Loss: 0.284128\n",
      "2025-04-14 19:29: Train Epoch 8: 0/2 Loss: 0.284128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 8: averaged Loss: 0.301077, tf_ratio: 0.904282\n",
      "2025-04-14 19:29: **********Train Epoch 8: averaged Loss: 0.301077, tf_ratio: 0.904282\n",
      "2025-04-14 19:29: **********Train Epoch 8: averaged Loss: 0.301077, tf_ratio: 0.904282\n",
      "2025-04-14 19:29: **********Train Epoch 8: averaged Loss: 0.301077, tf_ratio: 0.904282\n",
      "2025-04-14 19:29: **********Train Epoch 8: averaged Loss: 0.301077, tf_ratio: 0.904282\n",
      "2025-04-14 19:29: **********Val Epoch 8: average Loss: 0.269888\n",
      "2025-04-14 19:29: **********Val Epoch 8: average Loss: 0.269888\n",
      "2025-04-14 19:29: **********Val Epoch 8: average Loss: 0.269888\n",
      "2025-04-14 19:29: **********Val Epoch 8: average Loss: 0.269888\n",
      "2025-04-14 19:29: **********Val Epoch 8: average Loss: 0.269888\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 9: 0/2 Loss: 0.325555\n",
      "2025-04-14 19:29: Train Epoch 9: 0/2 Loss: 0.325555\n",
      "2025-04-14 19:29: Train Epoch 9: 0/2 Loss: 0.325555\n",
      "2025-04-14 19:29: Train Epoch 9: 0/2 Loss: 0.325555\n",
      "2025-04-14 19:29: Train Epoch 9: 0/2 Loss: 0.325555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 9: averaged Loss: 0.291860, tf_ratio: 0.895269\n",
      "2025-04-14 19:29: **********Train Epoch 9: averaged Loss: 0.291860, tf_ratio: 0.895269\n",
      "2025-04-14 19:29: **********Train Epoch 9: averaged Loss: 0.291860, tf_ratio: 0.895269\n",
      "2025-04-14 19:29: **********Train Epoch 9: averaged Loss: 0.291860, tf_ratio: 0.895269\n",
      "2025-04-14 19:29: **********Train Epoch 9: averaged Loss: 0.291860, tf_ratio: 0.895269\n",
      "2025-04-14 19:29: **********Val Epoch 9: average Loss: 0.268445\n",
      "2025-04-14 19:29: **********Val Epoch 9: average Loss: 0.268445\n",
      "2025-04-14 19:29: **********Val Epoch 9: average Loss: 0.268445\n",
      "2025-04-14 19:29: **********Val Epoch 9: average Loss: 0.268445\n",
      "2025-04-14 19:29: **********Val Epoch 9: average Loss: 0.268445\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 10: 0/2 Loss: 0.309045\n",
      "2025-04-14 19:29: Train Epoch 10: 0/2 Loss: 0.309045\n",
      "2025-04-14 19:29: Train Epoch 10: 0/2 Loss: 0.309045\n",
      "2025-04-14 19:29: Train Epoch 10: 0/2 Loss: 0.309045\n",
      "2025-04-14 19:29: Train Epoch 10: 0/2 Loss: 0.309045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 10: averaged Loss: 0.292413, tf_ratio: 0.885516\n",
      "2025-04-14 19:29: **********Train Epoch 10: averaged Loss: 0.292413, tf_ratio: 0.885516\n",
      "2025-04-14 19:29: **********Train Epoch 10: averaged Loss: 0.292413, tf_ratio: 0.885516\n",
      "2025-04-14 19:29: **********Train Epoch 10: averaged Loss: 0.292413, tf_ratio: 0.885516\n",
      "2025-04-14 19:29: **********Train Epoch 10: averaged Loss: 0.292413, tf_ratio: 0.885516\n",
      "2025-04-14 19:29: **********Val Epoch 10: average Loss: 0.267089\n",
      "2025-04-14 19:29: **********Val Epoch 10: average Loss: 0.267089\n",
      "2025-04-14 19:29: **********Val Epoch 10: average Loss: 0.267089\n",
      "2025-04-14 19:29: **********Val Epoch 10: average Loss: 0.267089\n",
      "2025-04-14 19:29: **********Val Epoch 10: average Loss: 0.267089\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 11: 0/2 Loss: 0.260400\n",
      "2025-04-14 19:29: Train Epoch 11: 0/2 Loss: 0.260400\n",
      "2025-04-14 19:29: Train Epoch 11: 0/2 Loss: 0.260400\n",
      "2025-04-14 19:29: Train Epoch 11: 0/2 Loss: 0.260400\n",
      "2025-04-14 19:29: Train Epoch 11: 0/2 Loss: 0.260400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 11: averaged Loss: 0.298593, tf_ratio: 0.874981\n",
      "2025-04-14 19:29: **********Train Epoch 11: averaged Loss: 0.298593, tf_ratio: 0.874981\n",
      "2025-04-14 19:29: **********Train Epoch 11: averaged Loss: 0.298593, tf_ratio: 0.874981\n",
      "2025-04-14 19:29: **********Train Epoch 11: averaged Loss: 0.298593, tf_ratio: 0.874981\n",
      "2025-04-14 19:29: **********Train Epoch 11: averaged Loss: 0.298593, tf_ratio: 0.874981\n",
      "2025-04-14 19:29: **********Val Epoch 11: average Loss: 0.265792\n",
      "2025-04-14 19:29: **********Val Epoch 11: average Loss: 0.265792\n",
      "2025-04-14 19:29: **********Val Epoch 11: average Loss: 0.265792\n",
      "2025-04-14 19:29: **********Val Epoch 11: average Loss: 0.265792\n",
      "2025-04-14 19:29: **********Val Epoch 11: average Loss: 0.265792\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 12: 0/2 Loss: 0.279131\n",
      "2025-04-14 19:29: Train Epoch 12: 0/2 Loss: 0.279131\n",
      "2025-04-14 19:29: Train Epoch 12: 0/2 Loss: 0.279131\n",
      "2025-04-14 19:29: Train Epoch 12: 0/2 Loss: 0.279131\n",
      "2025-04-14 19:29: Train Epoch 12: 0/2 Loss: 0.279131\n",
      "2025-04-14 19:29: **********Train Epoch 12: averaged Loss: 0.293299, tf_ratio: 0.863625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 12: averaged Loss: 0.293299, tf_ratio: 0.863625\n",
      "2025-04-14 19:29: **********Train Epoch 12: averaged Loss: 0.293299, tf_ratio: 0.863625\n",
      "2025-04-14 19:29: **********Train Epoch 12: averaged Loss: 0.293299, tf_ratio: 0.863625\n",
      "2025-04-14 19:29: **********Train Epoch 12: averaged Loss: 0.293299, tf_ratio: 0.863625\n",
      "2025-04-14 19:29: **********Val Epoch 12: average Loss: 0.264735\n",
      "2025-04-14 19:29: **********Val Epoch 12: average Loss: 0.264735\n",
      "2025-04-14 19:29: **********Val Epoch 12: average Loss: 0.264735\n",
      "2025-04-14 19:29: **********Val Epoch 12: average Loss: 0.264735\n",
      "2025-04-14 19:29: **********Val Epoch 12: average Loss: 0.264735\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 13: 0/2 Loss: 0.305339\n",
      "2025-04-14 19:29: Train Epoch 13: 0/2 Loss: 0.305339\n",
      "2025-04-14 19:29: Train Epoch 13: 0/2 Loss: 0.305339\n",
      "2025-04-14 19:29: Train Epoch 13: 0/2 Loss: 0.305339\n",
      "2025-04-14 19:29: Train Epoch 13: 0/2 Loss: 0.305339\n",
      "2025-04-14 19:29: **********Train Epoch 13: averaged Loss: 0.287095, tf_ratio: 0.851414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 13: averaged Loss: 0.287095, tf_ratio: 0.851414\n",
      "2025-04-14 19:29: **********Train Epoch 13: averaged Loss: 0.287095, tf_ratio: 0.851414\n",
      "2025-04-14 19:29: **********Train Epoch 13: averaged Loss: 0.287095, tf_ratio: 0.851414\n",
      "2025-04-14 19:29: **********Train Epoch 13: averaged Loss: 0.287095, tf_ratio: 0.851414\n",
      "2025-04-14 19:29: **********Val Epoch 13: average Loss: 0.263707\n",
      "2025-04-14 19:29: **********Val Epoch 13: average Loss: 0.263707\n",
      "2025-04-14 19:29: **********Val Epoch 13: average Loss: 0.263707\n",
      "2025-04-14 19:29: **********Val Epoch 13: average Loss: 0.263707\n",
      "2025-04-14 19:29: **********Val Epoch 13: average Loss: 0.263707\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 14: 0/2 Loss: 0.306344\n",
      "2025-04-14 19:29: Train Epoch 14: 0/2 Loss: 0.306344\n",
      "2025-04-14 19:29: Train Epoch 14: 0/2 Loss: 0.306344\n",
      "2025-04-14 19:29: Train Epoch 14: 0/2 Loss: 0.306344\n",
      "2025-04-14 19:29: Train Epoch 14: 0/2 Loss: 0.306344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 14: averaged Loss: 0.285020, tf_ratio: 0.838313\n",
      "2025-04-14 19:29: **********Train Epoch 14: averaged Loss: 0.285020, tf_ratio: 0.838313\n",
      "2025-04-14 19:29: **********Train Epoch 14: averaged Loss: 0.285020, tf_ratio: 0.838313\n",
      "2025-04-14 19:29: **********Train Epoch 14: averaged Loss: 0.285020, tf_ratio: 0.838313\n",
      "2025-04-14 19:29: **********Train Epoch 14: averaged Loss: 0.285020, tf_ratio: 0.838313\n",
      "2025-04-14 19:29: **********Val Epoch 14: average Loss: 0.262846\n",
      "2025-04-14 19:29: **********Val Epoch 14: average Loss: 0.262846\n",
      "2025-04-14 19:29: **********Val Epoch 14: average Loss: 0.262846\n",
      "2025-04-14 19:29: **********Val Epoch 14: average Loss: 0.262846\n",
      "2025-04-14 19:29: **********Val Epoch 14: average Loss: 0.262846\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 15: 0/2 Loss: 0.292489\n",
      "2025-04-14 19:29: Train Epoch 15: 0/2 Loss: 0.292489\n",
      "2025-04-14 19:29: Train Epoch 15: 0/2 Loss: 0.292489\n",
      "2025-04-14 19:29: Train Epoch 15: 0/2 Loss: 0.292489\n",
      "2025-04-14 19:29: Train Epoch 15: 0/2 Loss: 0.292489\n",
      "2025-04-14 19:29: **********Train Epoch 15: averaged Loss: 0.285584, tf_ratio: 0.824296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 15: averaged Loss: 0.285584, tf_ratio: 0.824296\n",
      "2025-04-14 19:29: **********Train Epoch 15: averaged Loss: 0.285584, tf_ratio: 0.824296\n",
      "2025-04-14 19:29: **********Train Epoch 15: averaged Loss: 0.285584, tf_ratio: 0.824296\n",
      "2025-04-14 19:29: **********Train Epoch 15: averaged Loss: 0.285584, tf_ratio: 0.824296\n",
      "2025-04-14 19:29: **********Val Epoch 15: average Loss: 0.262005\n",
      "2025-04-14 19:29: **********Val Epoch 15: average Loss: 0.262005\n",
      "2025-04-14 19:29: **********Val Epoch 15: average Loss: 0.262005\n",
      "2025-04-14 19:29: **********Val Epoch 15: average Loss: 0.262005\n",
      "2025-04-14 19:29: **********Val Epoch 15: average Loss: 0.262005\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 16: 0/2 Loss: 0.300640\n",
      "2025-04-14 19:29: Train Epoch 16: 0/2 Loss: 0.300640\n",
      "2025-04-14 19:29: Train Epoch 16: 0/2 Loss: 0.300640\n",
      "2025-04-14 19:29: Train Epoch 16: 0/2 Loss: 0.300640\n",
      "2025-04-14 19:29: Train Epoch 16: 0/2 Loss: 0.300640\n",
      "2025-04-14 19:29: **********Train Epoch 16: averaged Loss: 0.282507, tf_ratio: 0.809341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 16: averaged Loss: 0.282507, tf_ratio: 0.809341\n",
      "2025-04-14 19:29: **********Train Epoch 16: averaged Loss: 0.282507, tf_ratio: 0.809341\n",
      "2025-04-14 19:29: **********Train Epoch 16: averaged Loss: 0.282507, tf_ratio: 0.809341\n",
      "2025-04-14 19:29: **********Train Epoch 16: averaged Loss: 0.282507, tf_ratio: 0.809341\n",
      "2025-04-14 19:29: **********Val Epoch 16: average Loss: 0.261213\n",
      "2025-04-14 19:29: **********Val Epoch 16: average Loss: 0.261213\n",
      "2025-04-14 19:29: **********Val Epoch 16: average Loss: 0.261213\n",
      "2025-04-14 19:29: **********Val Epoch 16: average Loss: 0.261213\n",
      "2025-04-14 19:29: **********Val Epoch 16: average Loss: 0.261213\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 17: 0/2 Loss: 0.286255\n",
      "2025-04-14 19:29: Train Epoch 17: 0/2 Loss: 0.286255\n",
      "2025-04-14 19:29: Train Epoch 17: 0/2 Loss: 0.286255\n",
      "2025-04-14 19:29: Train Epoch 17: 0/2 Loss: 0.286255\n",
      "2025-04-14 19:29: Train Epoch 17: 0/2 Loss: 0.286255\n",
      "2025-04-14 19:29: **********Train Epoch 17: averaged Loss: 0.283218, tf_ratio: 0.793431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 17: averaged Loss: 0.283218, tf_ratio: 0.793431\n",
      "2025-04-14 19:29: **********Train Epoch 17: averaged Loss: 0.283218, tf_ratio: 0.793431\n",
      "2025-04-14 19:29: **********Train Epoch 17: averaged Loss: 0.283218, tf_ratio: 0.793431\n",
      "2025-04-14 19:29: **********Train Epoch 17: averaged Loss: 0.283218, tf_ratio: 0.793431\n",
      "2025-04-14 19:29: **********Val Epoch 17: average Loss: 0.260442\n",
      "2025-04-14 19:29: **********Val Epoch 17: average Loss: 0.260442\n",
      "2025-04-14 19:29: **********Val Epoch 17: average Loss: 0.260442\n",
      "2025-04-14 19:29: **********Val Epoch 17: average Loss: 0.260442\n",
      "2025-04-14 19:29: **********Val Epoch 17: average Loss: 0.260442\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 18: 0/2 Loss: 0.288020\n",
      "2025-04-14 19:29: Train Epoch 18: 0/2 Loss: 0.288020\n",
      "2025-04-14 19:29: Train Epoch 18: 0/2 Loss: 0.288020\n",
      "2025-04-14 19:29: Train Epoch 18: 0/2 Loss: 0.288020\n",
      "2025-04-14 19:29: Train Epoch 18: 0/2 Loss: 0.288020\n",
      "2025-04-14 19:29: **********Train Epoch 18: averaged Loss: 0.281335, tf_ratio: 0.776560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 18: averaged Loss: 0.281335, tf_ratio: 0.776560\n",
      "2025-04-14 19:29: **********Train Epoch 18: averaged Loss: 0.281335, tf_ratio: 0.776560\n",
      "2025-04-14 19:29: **********Train Epoch 18: averaged Loss: 0.281335, tf_ratio: 0.776560\n",
      "2025-04-14 19:29: **********Train Epoch 18: averaged Loss: 0.281335, tf_ratio: 0.776560\n",
      "2025-04-14 19:29: **********Val Epoch 18: average Loss: 0.259715\n",
      "2025-04-14 19:29: **********Val Epoch 18: average Loss: 0.259715\n",
      "2025-04-14 19:29: **********Val Epoch 18: average Loss: 0.259715\n",
      "2025-04-14 19:29: **********Val Epoch 18: average Loss: 0.259715\n",
      "2025-04-14 19:29: **********Val Epoch 18: average Loss: 0.259715\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 19: 0/2 Loss: 0.283448\n",
      "2025-04-14 19:29: Train Epoch 19: 0/2 Loss: 0.283448\n",
      "2025-04-14 19:29: Train Epoch 19: 0/2 Loss: 0.283448\n",
      "2025-04-14 19:29: Train Epoch 19: 0/2 Loss: 0.283448\n",
      "2025-04-14 19:29: Train Epoch 19: 0/2 Loss: 0.283448\n",
      "2025-04-14 19:29: **********Train Epoch 19: averaged Loss: 0.280502, tf_ratio: 0.758731\n",
      "2025-04-14 19:29: **********Train Epoch 19: averaged Loss: 0.280502, tf_ratio: 0.758731\n",
      "2025-04-14 19:29: **********Train Epoch 19: averaged Loss: 0.280502, tf_ratio: 0.758731\n",
      "2025-04-14 19:29: **********Train Epoch 19: averaged Loss: 0.280502, tf_ratio: 0.758731\n",
      "2025-04-14 19:29: **********Train Epoch 19: averaged Loss: 0.280502, tf_ratio: 0.758731\n",
      "2025-04-14 19:29: **********Val Epoch 19: average Loss: 0.259000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Val Epoch 19: average Loss: 0.259000\n",
      "2025-04-14 19:29: **********Val Epoch 19: average Loss: 0.259000\n",
      "2025-04-14 19:29: **********Val Epoch 19: average Loss: 0.259000\n",
      "2025-04-14 19:29: **********Val Epoch 19: average Loss: 0.259000\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 20: 0/2 Loss: 0.289808\n",
      "2025-04-14 19:29: Train Epoch 20: 0/2 Loss: 0.289808\n",
      "2025-04-14 19:29: Train Epoch 20: 0/2 Loss: 0.289808\n",
      "2025-04-14 19:29: Train Epoch 20: 0/2 Loss: 0.289808\n",
      "2025-04-14 19:29: Train Epoch 20: 0/2 Loss: 0.289808\n",
      "2025-04-14 19:29: **********Train Epoch 20: averaged Loss: 0.277914, tf_ratio: 0.739955\n",
      "2025-04-14 19:29: **********Train Epoch 20: averaged Loss: 0.277914, tf_ratio: 0.739955\n",
      "2025-04-14 19:29: **********Train Epoch 20: averaged Loss: 0.277914, tf_ratio: 0.739955\n",
      "2025-04-14 19:29: **********Train Epoch 20: averaged Loss: 0.277914, tf_ratio: 0.739955\n",
      "2025-04-14 19:29: **********Train Epoch 20: averaged Loss: 0.277914, tf_ratio: 0.739955\n",
      "2025-04-14 19:29: **********Val Epoch 20: average Loss: 0.258351\n",
      "2025-04-14 19:29: **********Val Epoch 20: average Loss: 0.258351\n",
      "2025-04-14 19:29: **********Val Epoch 20: average Loss: 0.258351\n",
      "2025-04-14 19:29: **********Val Epoch 20: average Loss: 0.258351\n",
      "2025-04-14 19:29: **********Val Epoch 20: average Loss: 0.258351\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: Train Epoch 21: 0/2 Loss: 0.298141\n",
      "2025-04-14 19:29: Train Epoch 21: 0/2 Loss: 0.298141\n",
      "2025-04-14 19:29: Train Epoch 21: 0/2 Loss: 0.298141\n",
      "2025-04-14 19:29: Train Epoch 21: 0/2 Loss: 0.298141\n",
      "2025-04-14 19:29: Train Epoch 21: 0/2 Loss: 0.298141\n",
      "2025-04-14 19:29: **********Train Epoch 21: averaged Loss: 0.275303, tf_ratio: 0.720256\n",
      "2025-04-14 19:29: **********Train Epoch 21: averaged Loss: 0.275303, tf_ratio: 0.720256\n",
      "2025-04-14 19:29: **********Train Epoch 21: averaged Loss: 0.275303, tf_ratio: 0.720256\n",
      "2025-04-14 19:29: **********Train Epoch 21: averaged Loss: 0.275303, tf_ratio: 0.720256\n",
      "2025-04-14 19:29: **********Train Epoch 21: averaged Loss: 0.275303, tf_ratio: 0.720256\n",
      "2025-04-14 19:29: **********Val Epoch 21: average Loss: 0.258236\n",
      "2025-04-14 19:29: **********Val Epoch 21: average Loss: 0.258236\n",
      "2025-04-14 19:29: **********Val Epoch 21: average Loss: 0.258236\n",
      "2025-04-14 19:29: **********Val Epoch 21: average Loss: 0.258236\n",
      "2025-04-14 19:29: **********Val Epoch 21: average Loss: 0.258236\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 22: 0/2 Loss: 0.260236\n",
      "2025-04-14 19:29: Train Epoch 22: 0/2 Loss: 0.260236\n",
      "2025-04-14 19:29: Train Epoch 22: 0/2 Loss: 0.260236\n",
      "2025-04-14 19:29: Train Epoch 22: 0/2 Loss: 0.260236\n",
      "2025-04-14 19:29: Train Epoch 22: 0/2 Loss: 0.260236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 22: averaged Loss: 0.281382, tf_ratio: 0.699671\n",
      "2025-04-14 19:29: **********Train Epoch 22: averaged Loss: 0.281382, tf_ratio: 0.699671\n",
      "2025-04-14 19:29: **********Train Epoch 22: averaged Loss: 0.281382, tf_ratio: 0.699671\n",
      "2025-04-14 19:29: **********Train Epoch 22: averaged Loss: 0.281382, tf_ratio: 0.699671\n",
      "2025-04-14 19:29: **********Train Epoch 22: averaged Loss: 0.281382, tf_ratio: 0.699671\n",
      "2025-04-14 19:29: **********Val Epoch 22: average Loss: 0.258106\n",
      "2025-04-14 19:29: **********Val Epoch 22: average Loss: 0.258106\n",
      "2025-04-14 19:29: **********Val Epoch 22: average Loss: 0.258106\n",
      "2025-04-14 19:29: **********Val Epoch 22: average Loss: 0.258106\n",
      "2025-04-14 19:29: **********Val Epoch 22: average Loss: 0.258106\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 23: 0/2 Loss: 0.255316\n",
      "2025-04-14 19:29: Train Epoch 23: 0/2 Loss: 0.255316\n",
      "2025-04-14 19:29: Train Epoch 23: 0/2 Loss: 0.255316\n",
      "2025-04-14 19:29: Train Epoch 23: 0/2 Loss: 0.255316\n",
      "2025-04-14 19:29: Train Epoch 23: 0/2 Loss: 0.255316\n",
      "2025-04-14 19:29: **********Train Epoch 23: averaged Loss: 0.281965, tf_ratio: 0.678248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 23: averaged Loss: 0.281965, tf_ratio: 0.678248\n",
      "2025-04-14 19:29: **********Train Epoch 23: averaged Loss: 0.281965, tf_ratio: 0.678248\n",
      "2025-04-14 19:29: **********Train Epoch 23: averaged Loss: 0.281965, tf_ratio: 0.678248\n",
      "2025-04-14 19:29: **********Train Epoch 23: averaged Loss: 0.281965, tf_ratio: 0.678248\n",
      "2025-04-14 19:29: **********Val Epoch 23: average Loss: 0.257970\n",
      "2025-04-14 19:29: **********Val Epoch 23: average Loss: 0.257970\n",
      "2025-04-14 19:29: **********Val Epoch 23: average Loss: 0.257970\n",
      "2025-04-14 19:29: **********Val Epoch 23: average Loss: 0.257970\n",
      "2025-04-14 19:29: **********Val Epoch 23: average Loss: 0.257970\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 24: 0/2 Loss: 0.242361\n",
      "2025-04-14 19:29: Train Epoch 24: 0/2 Loss: 0.242361\n",
      "2025-04-14 19:29: Train Epoch 24: 0/2 Loss: 0.242361\n",
      "2025-04-14 19:29: Train Epoch 24: 0/2 Loss: 0.242361\n",
      "2025-04-14 19:29: Train Epoch 24: 0/2 Loss: 0.242361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 24: averaged Loss: 0.283893, tf_ratio: 0.656048\n",
      "2025-04-14 19:29: **********Train Epoch 24: averaged Loss: 0.283893, tf_ratio: 0.656048\n",
      "2025-04-14 19:29: **********Train Epoch 24: averaged Loss: 0.283893, tf_ratio: 0.656048\n",
      "2025-04-14 19:29: **********Train Epoch 24: averaged Loss: 0.283893, tf_ratio: 0.656048\n",
      "2025-04-14 19:29: **********Train Epoch 24: averaged Loss: 0.283893, tf_ratio: 0.656048\n",
      "2025-04-14 19:29: **********Val Epoch 24: average Loss: 0.257838\n",
      "2025-04-14 19:29: **********Val Epoch 24: average Loss: 0.257838\n",
      "2025-04-14 19:29: **********Val Epoch 24: average Loss: 0.257838\n",
      "2025-04-14 19:29: **********Val Epoch 24: average Loss: 0.257838\n",
      "2025-04-14 19:29: **********Val Epoch 24: average Loss: 0.257838\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 25: 0/2 Loss: 0.253899\n",
      "2025-04-14 19:29: Train Epoch 25: 0/2 Loss: 0.253899\n",
      "2025-04-14 19:29: Train Epoch 25: 0/2 Loss: 0.253899\n",
      "2025-04-14 19:29: Train Epoch 25: 0/2 Loss: 0.253899\n",
      "2025-04-14 19:29: Train Epoch 25: 0/2 Loss: 0.253899\n",
      "2025-04-14 19:29: **********Train Epoch 25: averaged Loss: 0.281712, tf_ratio: 0.633145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 25: averaged Loss: 0.281712, tf_ratio: 0.633145\n",
      "2025-04-14 19:29: **********Train Epoch 25: averaged Loss: 0.281712, tf_ratio: 0.633145\n",
      "2025-04-14 19:29: **********Train Epoch 25: averaged Loss: 0.281712, tf_ratio: 0.633145\n",
      "2025-04-14 19:29: **********Train Epoch 25: averaged Loss: 0.281712, tf_ratio: 0.633145\n",
      "2025-04-14 19:29: **********Val Epoch 25: average Loss: 0.257726\n",
      "2025-04-14 19:29: **********Val Epoch 25: average Loss: 0.257726\n",
      "2025-04-14 19:29: **********Val Epoch 25: average Loss: 0.257726\n",
      "2025-04-14 19:29: **********Val Epoch 25: average Loss: 0.257726\n",
      "2025-04-14 19:29: **********Val Epoch 25: average Loss: 0.257726\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 26: 0/2 Loss: 0.266464\n",
      "2025-04-14 19:29: Train Epoch 26: 0/2 Loss: 0.266464\n",
      "2025-04-14 19:29: Train Epoch 26: 0/2 Loss: 0.266464\n",
      "2025-04-14 19:29: Train Epoch 26: 0/2 Loss: 0.266464\n",
      "2025-04-14 19:29: Train Epoch 26: 0/2 Loss: 0.266464\n",
      "2025-04-14 19:29: **********Train Epoch 26: averaged Loss: 0.279364, tf_ratio: 0.609624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 26: averaged Loss: 0.279364, tf_ratio: 0.609624\n",
      "2025-04-14 19:29: **********Train Epoch 26: averaged Loss: 0.279364, tf_ratio: 0.609624\n",
      "2025-04-14 19:29: **********Train Epoch 26: averaged Loss: 0.279364, tf_ratio: 0.609624\n",
      "2025-04-14 19:29: **********Train Epoch 26: averaged Loss: 0.279364, tf_ratio: 0.609624\n",
      "2025-04-14 19:29: **********Val Epoch 26: average Loss: 0.257612\n",
      "2025-04-14 19:29: **********Val Epoch 26: average Loss: 0.257612\n",
      "2025-04-14 19:29: **********Val Epoch 26: average Loss: 0.257612\n",
      "2025-04-14 19:29: **********Val Epoch 26: average Loss: 0.257612\n",
      "2025-04-14 19:29: **********Val Epoch 26: average Loss: 0.257612\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 27: 0/2 Loss: 0.253522\n",
      "2025-04-14 19:29: Train Epoch 27: 0/2 Loss: 0.253522\n",
      "2025-04-14 19:29: Train Epoch 27: 0/2 Loss: 0.253522\n",
      "2025-04-14 19:29: Train Epoch 27: 0/2 Loss: 0.253522\n",
      "2025-04-14 19:29: Train Epoch 27: 0/2 Loss: 0.253522\n",
      "2025-04-14 19:29: **********Train Epoch 27: averaged Loss: 0.281294, tf_ratio: 0.585582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 27: averaged Loss: 0.281294, tf_ratio: 0.585582\n",
      "2025-04-14 19:29: **********Train Epoch 27: averaged Loss: 0.281294, tf_ratio: 0.585582\n",
      "2025-04-14 19:29: **********Train Epoch 27: averaged Loss: 0.281294, tf_ratio: 0.585582\n",
      "2025-04-14 19:29: **********Train Epoch 27: averaged Loss: 0.281294, tf_ratio: 0.585582\n",
      "2025-04-14 19:29: **********Val Epoch 27: average Loss: 0.257486\n",
      "2025-04-14 19:29: **********Val Epoch 27: average Loss: 0.257486\n",
      "2025-04-14 19:29: **********Val Epoch 27: average Loss: 0.257486\n",
      "2025-04-14 19:29: **********Val Epoch 27: average Loss: 0.257486\n",
      "2025-04-14 19:29: **********Val Epoch 27: average Loss: 0.257486\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 28: 0/2 Loss: 0.254209\n",
      "2025-04-14 19:29: Train Epoch 28: 0/2 Loss: 0.254209\n",
      "2025-04-14 19:29: Train Epoch 28: 0/2 Loss: 0.254209\n",
      "2025-04-14 19:29: Train Epoch 28: 0/2 Loss: 0.254209\n",
      "2025-04-14 19:29: Train Epoch 28: 0/2 Loss: 0.254209\n",
      "2025-04-14 19:29: **********Train Epoch 28: averaged Loss: 0.280950, tf_ratio: 0.561126\n",
      "2025-04-14 19:29: **********Train Epoch 28: averaged Loss: 0.280950, tf_ratio: 0.561126\n",
      "2025-04-14 19:29: **********Train Epoch 28: averaged Loss: 0.280950, tf_ratio: 0.561126\n",
      "2025-04-14 19:29: **********Train Epoch 28: averaged Loss: 0.280950, tf_ratio: 0.561126\n",
      "2025-04-14 19:29: **********Train Epoch 28: averaged Loss: 0.280950, tf_ratio: 0.561126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Val Epoch 28: average Loss: 0.257351\n",
      "2025-04-14 19:29: **********Val Epoch 28: average Loss: 0.257351\n",
      "2025-04-14 19:29: **********Val Epoch 28: average Loss: 0.257351\n",
      "2025-04-14 19:29: **********Val Epoch 28: average Loss: 0.257351\n",
      "2025-04-14 19:29: **********Val Epoch 28: average Loss: 0.257351\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 29: 0/2 Loss: 0.291842\n",
      "2025-04-14 19:29: Train Epoch 29: 0/2 Loss: 0.291842\n",
      "2025-04-14 19:29: Train Epoch 29: 0/2 Loss: 0.291842\n",
      "2025-04-14 19:29: Train Epoch 29: 0/2 Loss: 0.291842\n",
      "2025-04-14 19:29: Train Epoch 29: 0/2 Loss: 0.291842\n",
      "2025-04-14 19:29: **********Train Epoch 29: averaged Loss: 0.274443, tf_ratio: 0.536369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 29: averaged Loss: 0.274443, tf_ratio: 0.536369\n",
      "2025-04-14 19:29: **********Train Epoch 29: averaged Loss: 0.274443, tf_ratio: 0.536369\n",
      "2025-04-14 19:29: **********Train Epoch 29: averaged Loss: 0.274443, tf_ratio: 0.536369\n",
      "2025-04-14 19:29: **********Train Epoch 29: averaged Loss: 0.274443, tf_ratio: 0.536369\n",
      "2025-04-14 19:29: **********Val Epoch 29: average Loss: 0.257238\n",
      "2025-04-14 19:29: **********Val Epoch 29: average Loss: 0.257238\n",
      "2025-04-14 19:29: **********Val Epoch 29: average Loss: 0.257238\n",
      "2025-04-14 19:29: **********Val Epoch 29: average Loss: 0.257238\n",
      "2025-04-14 19:29: **********Val Epoch 29: average Loss: 0.257238\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 30: 0/2 Loss: 0.299613\n",
      "2025-04-14 19:29: Train Epoch 30: 0/2 Loss: 0.299613\n",
      "2025-04-14 19:29: Train Epoch 30: 0/2 Loss: 0.299613\n",
      "2025-04-14 19:29: Train Epoch 30: 0/2 Loss: 0.299613\n",
      "2025-04-14 19:29: Train Epoch 30: 0/2 Loss: 0.299613\n",
      "2025-04-14 19:29: **********Train Epoch 30: averaged Loss: 0.272913, tf_ratio: 0.511431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 30: averaged Loss: 0.272913, tf_ratio: 0.511431\n",
      "2025-04-14 19:29: **********Train Epoch 30: averaged Loss: 0.272913, tf_ratio: 0.511431\n",
      "2025-04-14 19:29: **********Train Epoch 30: averaged Loss: 0.272913, tf_ratio: 0.511431\n",
      "2025-04-14 19:29: **********Train Epoch 30: averaged Loss: 0.272913, tf_ratio: 0.511431\n",
      "2025-04-14 19:29: **********Val Epoch 30: average Loss: 0.257111\n",
      "2025-04-14 19:29: **********Val Epoch 30: average Loss: 0.257111\n",
      "2025-04-14 19:29: **********Val Epoch 30: average Loss: 0.257111\n",
      "2025-04-14 19:29: **********Val Epoch 30: average Loss: 0.257111\n",
      "2025-04-14 19:29: **********Val Epoch 30: average Loss: 0.257111\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 31: 0/2 Loss: 0.256684\n",
      "2025-04-14 19:29: Train Epoch 31: 0/2 Loss: 0.256684\n",
      "2025-04-14 19:29: Train Epoch 31: 0/2 Loss: 0.256684\n",
      "2025-04-14 19:29: Train Epoch 31: 0/2 Loss: 0.256684\n",
      "2025-04-14 19:29: Train Epoch 31: 0/2 Loss: 0.256684\n",
      "2025-04-14 19:29: **********Train Epoch 31: averaged Loss: 0.279856, tf_ratio: 0.486436\n",
      "2025-04-14 19:29: **********Train Epoch 31: averaged Loss: 0.279856, tf_ratio: 0.486436\n",
      "2025-04-14 19:29: **********Train Epoch 31: averaged Loss: 0.279856, tf_ratio: 0.486436\n",
      "2025-04-14 19:29: **********Train Epoch 31: averaged Loss: 0.279856, tf_ratio: 0.486436\n",
      "2025-04-14 19:29: **********Train Epoch 31: averaged Loss: 0.279856, tf_ratio: 0.486436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Val Epoch 31: average Loss: 0.256970\n",
      "2025-04-14 19:29: **********Val Epoch 31: average Loss: 0.256970\n",
      "2025-04-14 19:29: **********Val Epoch 31: average Loss: 0.256970\n",
      "2025-04-14 19:29: **********Val Epoch 31: average Loss: 0.256970\n",
      "2025-04-14 19:29: **********Val Epoch 31: average Loss: 0.256970\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 32: 0/2 Loss: 0.256461\n",
      "2025-04-14 19:29: Train Epoch 32: 0/2 Loss: 0.256461\n",
      "2025-04-14 19:29: Train Epoch 32: 0/2 Loss: 0.256461\n",
      "2025-04-14 19:29: Train Epoch 32: 0/2 Loss: 0.256461\n",
      "2025-04-14 19:29: Train Epoch 32: 0/2 Loss: 0.256461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 32: averaged Loss: 0.279658, tf_ratio: 0.461509\n",
      "2025-04-14 19:29: **********Train Epoch 32: averaged Loss: 0.279658, tf_ratio: 0.461509\n",
      "2025-04-14 19:29: **********Train Epoch 32: averaged Loss: 0.279658, tf_ratio: 0.461509\n",
      "2025-04-14 19:29: **********Train Epoch 32: averaged Loss: 0.279658, tf_ratio: 0.461509\n",
      "2025-04-14 19:29: **********Train Epoch 32: averaged Loss: 0.279658, tf_ratio: 0.461509\n",
      "2025-04-14 19:29: **********Val Epoch 32: average Loss: 0.256838\n",
      "2025-04-14 19:29: **********Val Epoch 32: average Loss: 0.256838\n",
      "2025-04-14 19:29: **********Val Epoch 32: average Loss: 0.256838\n",
      "2025-04-14 19:29: **********Val Epoch 32: average Loss: 0.256838\n",
      "2025-04-14 19:29: **********Val Epoch 32: average Loss: 0.256838\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 33: 0/2 Loss: 0.291746\n",
      "2025-04-14 19:29: Train Epoch 33: 0/2 Loss: 0.291746\n",
      "2025-04-14 19:29: Train Epoch 33: 0/2 Loss: 0.291746\n",
      "2025-04-14 19:29: Train Epoch 33: 0/2 Loss: 0.291746\n",
      "2025-04-14 19:29: Train Epoch 33: 0/2 Loss: 0.291746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Train Epoch 33: averaged Loss: 0.273559, tf_ratio: 0.436773\n",
      "2025-04-14 19:29: **********Train Epoch 33: averaged Loss: 0.273559, tf_ratio: 0.436773\n",
      "2025-04-14 19:29: **********Train Epoch 33: averaged Loss: 0.273559, tf_ratio: 0.436773\n",
      "2025-04-14 19:29: **********Train Epoch 33: averaged Loss: 0.273559, tf_ratio: 0.436773\n",
      "2025-04-14 19:29: **********Train Epoch 33: averaged Loss: 0.273559, tf_ratio: 0.436773\n",
      "2025-04-14 19:29: **********Val Epoch 33: average Loss: 0.256719\n",
      "2025-04-14 19:29: **********Val Epoch 33: average Loss: 0.256719\n",
      "2025-04-14 19:29: **********Val Epoch 33: average Loss: 0.256719\n",
      "2025-04-14 19:29: **********Val Epoch 33: average Loss: 0.256719\n",
      "2025-04-14 19:29: **********Val Epoch 33: average Loss: 0.256719\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 34: 0/2 Loss: 0.257891\n",
      "2025-04-14 19:29: Train Epoch 34: 0/2 Loss: 0.257891\n",
      "2025-04-14 19:29: Train Epoch 34: 0/2 Loss: 0.257891\n",
      "2025-04-14 19:29: Train Epoch 34: 0/2 Loss: 0.257891\n",
      "2025-04-14 19:29: Train Epoch 34: 0/2 Loss: 0.257891\n",
      "2025-04-14 19:29: **********Train Epoch 34: averaged Loss: 0.278959, tf_ratio: 0.412348\n",
      "2025-04-14 19:29: **********Train Epoch 34: averaged Loss: 0.278959, tf_ratio: 0.412348\n",
      "2025-04-14 19:29: **********Train Epoch 34: averaged Loss: 0.278959, tf_ratio: 0.412348\n",
      "2025-04-14 19:29: **********Train Epoch 34: averaged Loss: 0.278959, tf_ratio: 0.412348\n",
      "2025-04-14 19:29: **********Train Epoch 34: averaged Loss: 0.278959, tf_ratio: 0.412348\n",
      "2025-04-14 19:29: **********Val Epoch 34: average Loss: 0.256599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Val Epoch 34: average Loss: 0.256599\n",
      "2025-04-14 19:29: **********Val Epoch 34: average Loss: 0.256599\n",
      "2025-04-14 19:29: **********Val Epoch 34: average Loss: 0.256599\n",
      "2025-04-14 19:29: **********Val Epoch 34: average Loss: 0.256599\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 35: 0/2 Loss: 0.286452\n",
      "2025-04-14 19:29: Train Epoch 35: 0/2 Loss: 0.286452\n",
      "2025-04-14 19:29: Train Epoch 35: 0/2 Loss: 0.286452\n",
      "2025-04-14 19:29: Train Epoch 35: 0/2 Loss: 0.286452\n",
      "2025-04-14 19:29: Train Epoch 35: 0/2 Loss: 0.286452\n",
      "2025-04-14 19:29: **********Train Epoch 35: averaged Loss: 0.273984, tf_ratio: 0.388347\n",
      "2025-04-14 19:29: **********Train Epoch 35: averaged Loss: 0.273984, tf_ratio: 0.388347\n",
      "2025-04-14 19:29: **********Train Epoch 35: averaged Loss: 0.273984, tf_ratio: 0.388347\n",
      "2025-04-14 19:29: **********Train Epoch 35: averaged Loss: 0.273984, tf_ratio: 0.388347\n",
      "2025-04-14 19:29: **********Train Epoch 35: averaged Loss: 0.273984, tf_ratio: 0.388347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Val Epoch 35: average Loss: 0.256485\n",
      "2025-04-14 19:29: **********Val Epoch 35: average Loss: 0.256485\n",
      "2025-04-14 19:29: **********Val Epoch 35: average Loss: 0.256485\n",
      "2025-04-14 19:29: **********Val Epoch 35: average Loss: 0.256485\n",
      "2025-04-14 19:29: **********Val Epoch 35: average Loss: 0.256485\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 36: 0/2 Loss: 0.264970\n",
      "2025-04-14 19:29: Train Epoch 36: 0/2 Loss: 0.264970\n",
      "2025-04-14 19:29: Train Epoch 36: 0/2 Loss: 0.264970\n",
      "2025-04-14 19:29: Train Epoch 36: 0/2 Loss: 0.264970\n",
      "2025-04-14 19:29: Train Epoch 36: 0/2 Loss: 0.264970\n",
      "2025-04-14 19:29: **********Train Epoch 36: averaged Loss: 0.277334, tf_ratio: 0.364875\n",
      "2025-04-14 19:29: **********Train Epoch 36: averaged Loss: 0.277334, tf_ratio: 0.364875\n",
      "2025-04-14 19:29: **********Train Epoch 36: averaged Loss: 0.277334, tf_ratio: 0.364875\n",
      "2025-04-14 19:29: **********Train Epoch 36: averaged Loss: 0.277334, tf_ratio: 0.364875\n",
      "2025-04-14 19:29: **********Train Epoch 36: averaged Loss: 0.277334, tf_ratio: 0.364875\n",
      "2025-04-14 19:29: **********Val Epoch 36: average Loss: 0.256368\n",
      "2025-04-14 19:29: **********Val Epoch 36: average Loss: 0.256368\n",
      "2025-04-14 19:29: **********Val Epoch 36: average Loss: 0.256368\n",
      "2025-04-14 19:29: **********Val Epoch 36: average Loss: 0.256368\n",
      "2025-04-14 19:29: **********Val Epoch 36: average Loss: 0.256368\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 37: 0/2 Loss: 0.273086\n",
      "2025-04-14 19:29: Train Epoch 37: 0/2 Loss: 0.273086\n",
      "2025-04-14 19:29: Train Epoch 37: 0/2 Loss: 0.273086\n",
      "2025-04-14 19:29: Train Epoch 37: 0/2 Loss: 0.273086\n",
      "2025-04-14 19:29: Train Epoch 37: 0/2 Loss: 0.273086\n",
      "2025-04-14 19:29: **********Train Epoch 37: averaged Loss: 0.275787, tf_ratio: 0.342028\n",
      "2025-04-14 19:29: **********Train Epoch 37: averaged Loss: 0.275787, tf_ratio: 0.342028\n",
      "2025-04-14 19:29: **********Train Epoch 37: averaged Loss: 0.275787, tf_ratio: 0.342028\n",
      "2025-04-14 19:29: **********Train Epoch 37: averaged Loss: 0.275787, tf_ratio: 0.342028\n",
      "2025-04-14 19:29: **********Train Epoch 37: averaged Loss: 0.275787, tf_ratio: 0.342028\n",
      "2025-04-14 19:29: **********Val Epoch 37: average Loss: 0.256234\n",
      "2025-04-14 19:29: **********Val Epoch 37: average Loss: 0.256234\n",
      "2025-04-14 19:29: **********Val Epoch 37: average Loss: 0.256234\n",
      "2025-04-14 19:29: **********Val Epoch 37: average Loss: 0.256234\n",
      "2025-04-14 19:29: **********Val Epoch 37: average Loss: 0.256234\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: Train Epoch 38: 0/2 Loss: 0.257667\n",
      "2025-04-14 19:29: Train Epoch 38: 0/2 Loss: 0.257667\n",
      "2025-04-14 19:29: Train Epoch 38: 0/2 Loss: 0.257667\n",
      "2025-04-14 19:29: Train Epoch 38: 0/2 Loss: 0.257667\n",
      "2025-04-14 19:29: Train Epoch 38: 0/2 Loss: 0.257667\n",
      "2025-04-14 19:29: **********Train Epoch 38: averaged Loss: 0.278120, tf_ratio: 0.319892\n",
      "2025-04-14 19:29: **********Train Epoch 38: averaged Loss: 0.278120, tf_ratio: 0.319892\n",
      "2025-04-14 19:29: **********Train Epoch 38: averaged Loss: 0.278120, tf_ratio: 0.319892\n",
      "2025-04-14 19:29: **********Train Epoch 38: averaged Loss: 0.278120, tf_ratio: 0.319892\n",
      "2025-04-14 19:29: **********Train Epoch 38: averaged Loss: 0.278120, tf_ratio: 0.319892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Val Epoch 38: average Loss: 0.256125\n",
      "2025-04-14 19:29: **********Val Epoch 38: average Loss: 0.256125\n",
      "2025-04-14 19:29: **********Val Epoch 38: average Loss: 0.256125\n",
      "2025-04-14 19:29: **********Val Epoch 38: average Loss: 0.256125\n",
      "2025-04-14 19:29: **********Val Epoch 38: average Loss: 0.256125\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 39: 0/2 Loss: 0.252050\n",
      "2025-04-14 19:29: Train Epoch 39: 0/2 Loss: 0.252050\n",
      "2025-04-14 19:29: Train Epoch 39: 0/2 Loss: 0.252050\n",
      "2025-04-14 19:29: Train Epoch 39: 0/2 Loss: 0.252050\n",
      "2025-04-14 19:29: Train Epoch 39: 0/2 Loss: 0.252050\n",
      "2025-04-14 19:29: **********Train Epoch 39: averaged Loss: 0.278843, tf_ratio: 0.298538\n",
      "2025-04-14 19:29: **********Train Epoch 39: averaged Loss: 0.278843, tf_ratio: 0.298538\n",
      "2025-04-14 19:29: **********Train Epoch 39: averaged Loss: 0.278843, tf_ratio: 0.298538\n",
      "2025-04-14 19:29: **********Train Epoch 39: averaged Loss: 0.278843, tf_ratio: 0.298538\n",
      "2025-04-14 19:29: **********Train Epoch 39: averaged Loss: 0.278843, tf_ratio: 0.298538\n",
      "2025-04-14 19:29: **********Val Epoch 39: average Loss: 0.256016\n",
      "2025-04-14 19:29: **********Val Epoch 39: average Loss: 0.256016\n",
      "2025-04-14 19:29: **********Val Epoch 39: average Loss: 0.256016\n",
      "2025-04-14 19:29: **********Val Epoch 39: average Loss: 0.256016\n",
      "2025-04-14 19:29: **********Val Epoch 39: average Loss: 0.256016\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: Train Epoch 40: 0/2 Loss: 0.289362\n",
      "2025-04-14 19:29: Train Epoch 40: 0/2 Loss: 0.289362\n",
      "2025-04-14 19:29: Train Epoch 40: 0/2 Loss: 0.289362\n",
      "2025-04-14 19:29: Train Epoch 40: 0/2 Loss: 0.289362\n",
      "2025-04-14 19:29: Train Epoch 40: 0/2 Loss: 0.289362\n",
      "2025-04-14 19:29: **********Train Epoch 40: averaged Loss: 0.272395, tf_ratio: 0.278027\n",
      "2025-04-14 19:29: **********Train Epoch 40: averaged Loss: 0.272395, tf_ratio: 0.278027\n",
      "2025-04-14 19:29: **********Train Epoch 40: averaged Loss: 0.272395, tf_ratio: 0.278027\n",
      "2025-04-14 19:29: **********Train Epoch 40: averaged Loss: 0.272395, tf_ratio: 0.278027\n",
      "2025-04-14 19:29: **********Train Epoch 40: averaged Loss: 0.272395, tf_ratio: 0.278027\n",
      "2025-04-14 19:29: **********Val Epoch 40: average Loss: 0.255911\n",
      "2025-04-14 19:29: **********Val Epoch 40: average Loss: 0.255911\n",
      "2025-04-14 19:29: **********Val Epoch 40: average Loss: 0.255911\n",
      "2025-04-14 19:29: **********Val Epoch 40: average Loss: 0.255911\n",
      "2025-04-14 19:29: **********Val Epoch 40: average Loss: 0.255911\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: Train Epoch 41: 0/2 Loss: 0.269692\n",
      "2025-04-14 19:29: Train Epoch 41: 0/2 Loss: 0.269692\n",
      "2025-04-14 19:29: Train Epoch 41: 0/2 Loss: 0.269692\n",
      "2025-04-14 19:29: Train Epoch 41: 0/2 Loss: 0.269692\n",
      "2025-04-14 19:29: Train Epoch 41: 0/2 Loss: 0.269692\n",
      "2025-04-14 19:29: **********Train Epoch 41: averaged Loss: 0.275494, tf_ratio: 0.258406\n",
      "2025-04-14 19:29: **********Train Epoch 41: averaged Loss: 0.275494, tf_ratio: 0.258406\n",
      "2025-04-14 19:29: **********Train Epoch 41: averaged Loss: 0.275494, tf_ratio: 0.258406\n",
      "2025-04-14 19:29: **********Train Epoch 41: averaged Loss: 0.275494, tf_ratio: 0.258406\n",
      "2025-04-14 19:29: **********Train Epoch 41: averaged Loss: 0.275494, tf_ratio: 0.258406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Val Epoch 41: average Loss: 0.255893\n",
      "2025-04-14 19:29: **********Val Epoch 41: average Loss: 0.255893\n",
      "2025-04-14 19:29: **********Val Epoch 41: average Loss: 0.255893\n",
      "2025-04-14 19:29: **********Val Epoch 41: average Loss: 0.255893\n",
      "2025-04-14 19:29: **********Val Epoch 41: average Loss: 0.255893\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 42: 0/2 Loss: 0.285106\n",
      "2025-04-14 19:29: Train Epoch 42: 0/2 Loss: 0.285106\n",
      "2025-04-14 19:29: Train Epoch 42: 0/2 Loss: 0.285106\n",
      "2025-04-14 19:29: Train Epoch 42: 0/2 Loss: 0.285106\n",
      "2025-04-14 19:29: Train Epoch 42: 0/2 Loss: 0.285106\n",
      "2025-04-14 19:29: **********Train Epoch 42: averaged Loss: 0.272894, tf_ratio: 0.239710\n",
      "2025-04-14 19:29: **********Train Epoch 42: averaged Loss: 0.272894, tf_ratio: 0.239710\n",
      "2025-04-14 19:29: **********Train Epoch 42: averaged Loss: 0.272894, tf_ratio: 0.239710\n",
      "2025-04-14 19:29: **********Train Epoch 42: averaged Loss: 0.272894, tf_ratio: 0.239710\n",
      "2025-04-14 19:29: **********Train Epoch 42: averaged Loss: 0.272894, tf_ratio: 0.239710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n",
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Val Epoch 42: average Loss: 0.255870\n",
      "2025-04-14 19:29: **********Val Epoch 42: average Loss: 0.255870\n",
      "2025-04-14 19:29: **********Val Epoch 42: average Loss: 0.255870\n",
      "2025-04-14 19:29: **********Val Epoch 42: average Loss: 0.255870\n",
      "2025-04-14 19:29: **********Val Epoch 42: average Loss: 0.255870\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 43: 0/2 Loss: 0.238527\n",
      "2025-04-14 19:29: Train Epoch 43: 0/2 Loss: 0.238527\n",
      "2025-04-14 19:29: Train Epoch 43: 0/2 Loss: 0.238527\n",
      "2025-04-14 19:29: Train Epoch 43: 0/2 Loss: 0.238527\n",
      "2025-04-14 19:29: Train Epoch 43: 0/2 Loss: 0.238527\n",
      "2025-04-14 19:29: **********Train Epoch 43: averaged Loss: 0.280620, tf_ratio: 0.221962\n",
      "2025-04-14 19:29: **********Train Epoch 43: averaged Loss: 0.280620, tf_ratio: 0.221962\n",
      "2025-04-14 19:29: **********Train Epoch 43: averaged Loss: 0.280620, tf_ratio: 0.221962\n",
      "2025-04-14 19:29: **********Train Epoch 43: averaged Loss: 0.280620, tf_ratio: 0.221962\n",
      "2025-04-14 19:29: **********Train Epoch 43: averaged Loss: 0.280620, tf_ratio: 0.221962\n",
      "2025-04-14 19:29: **********Val Epoch 43: average Loss: 0.255848\n",
      "2025-04-14 19:29: **********Val Epoch 43: average Loss: 0.255848\n",
      "2025-04-14 19:29: **********Val Epoch 43: average Loss: 0.255848\n",
      "2025-04-14 19:29: **********Val Epoch 43: average Loss: 0.255848\n",
      "2025-04-14 19:29: **********Val Epoch 43: average Loss: 0.255848\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: Train Epoch 44: 0/2 Loss: 0.272056\n",
      "2025-04-14 19:29: Train Epoch 44: 0/2 Loss: 0.272056\n",
      "2025-04-14 19:29: Train Epoch 44: 0/2 Loss: 0.272056\n",
      "2025-04-14 19:29: Train Epoch 44: 0/2 Loss: 0.272056\n",
      "2025-04-14 19:29: Train Epoch 44: 0/2 Loss: 0.272056\n",
      "2025-04-14 19:29: **********Train Epoch 44: averaged Loss: 0.274995, tf_ratio: 0.205174\n",
      "2025-04-14 19:29: **********Train Epoch 44: averaged Loss: 0.274995, tf_ratio: 0.205174\n",
      "2025-04-14 19:29: **********Train Epoch 44: averaged Loss: 0.274995, tf_ratio: 0.205174\n",
      "2025-04-14 19:29: **********Train Epoch 44: averaged Loss: 0.274995, tf_ratio: 0.205174\n",
      "2025-04-14 19:29: **********Train Epoch 44: averaged Loss: 0.274995, tf_ratio: 0.205174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Val Epoch 44: average Loss: 0.255830\n",
      "2025-04-14 19:29: **********Val Epoch 44: average Loss: 0.255830\n",
      "2025-04-14 19:29: **********Val Epoch 44: average Loss: 0.255830\n",
      "2025-04-14 19:29: **********Val Epoch 44: average Loss: 0.255830\n",
      "2025-04-14 19:29: **********Val Epoch 44: average Loss: 0.255830\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 45: 0/2 Loss: 0.303162\n",
      "2025-04-14 19:29: Train Epoch 45: 0/2 Loss: 0.303162\n",
      "2025-04-14 19:29: Train Epoch 45: 0/2 Loss: 0.303162\n",
      "2025-04-14 19:29: Train Epoch 45: 0/2 Loss: 0.303162\n",
      "2025-04-14 19:29: Train Epoch 45: 0/2 Loss: 0.303162\n",
      "2025-04-14 19:29: **********Train Epoch 45: averaged Loss: 0.269771, tf_ratio: 0.189346\n",
      "2025-04-14 19:29: **********Train Epoch 45: averaged Loss: 0.269771, tf_ratio: 0.189346\n",
      "2025-04-14 19:29: **********Train Epoch 45: averaged Loss: 0.269771, tf_ratio: 0.189346\n",
      "2025-04-14 19:29: **********Train Epoch 45: averaged Loss: 0.269771, tf_ratio: 0.189346\n",
      "2025-04-14 19:29: **********Train Epoch 45: averaged Loss: 0.269771, tf_ratio: 0.189346\n",
      "2025-04-14 19:29: **********Val Epoch 45: average Loss: 0.255816\n",
      "2025-04-14 19:29: **********Val Epoch 45: average Loss: 0.255816\n",
      "2025-04-14 19:29: **********Val Epoch 45: average Loss: 0.255816\n",
      "2025-04-14 19:29: **********Val Epoch 45: average Loss: 0.255816\n",
      "2025-04-14 19:29: **********Val Epoch 45: average Loss: 0.255816\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: Train Epoch 46: 0/2 Loss: 0.251078\n",
      "2025-04-14 19:29: Train Epoch 46: 0/2 Loss: 0.251078\n",
      "2025-04-14 19:29: Train Epoch 46: 0/2 Loss: 0.251078\n",
      "2025-04-14 19:29: Train Epoch 46: 0/2 Loss: 0.251078\n",
      "2025-04-14 19:29: Train Epoch 46: 0/2 Loss: 0.251078\n",
      "2025-04-14 19:29: **********Train Epoch 46: averaged Loss: 0.278418, tf_ratio: 0.174471\n",
      "2025-04-14 19:29: **********Train Epoch 46: averaged Loss: 0.278418, tf_ratio: 0.174471\n",
      "2025-04-14 19:29: **********Train Epoch 46: averaged Loss: 0.278418, tf_ratio: 0.174471\n",
      "2025-04-14 19:29: **********Train Epoch 46: averaged Loss: 0.278418, tf_ratio: 0.174471\n",
      "2025-04-14 19:29: **********Train Epoch 46: averaged Loss: 0.278418, tf_ratio: 0.174471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Val Epoch 46: average Loss: 0.255798\n",
      "2025-04-14 19:29: **********Val Epoch 46: average Loss: 0.255798\n",
      "2025-04-14 19:29: **********Val Epoch 46: average Loss: 0.255798\n",
      "2025-04-14 19:29: **********Val Epoch 46: average Loss: 0.255798\n",
      "2025-04-14 19:29: **********Val Epoch 46: average Loss: 0.255798\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 47: 0/2 Loss: 0.254508\n",
      "2025-04-14 19:29: Train Epoch 47: 0/2 Loss: 0.254508\n",
      "2025-04-14 19:29: Train Epoch 47: 0/2 Loss: 0.254508\n",
      "2025-04-14 19:29: Train Epoch 47: 0/2 Loss: 0.254508\n",
      "2025-04-14 19:29: Train Epoch 47: 0/2 Loss: 0.254508\n",
      "2025-04-14 19:29: **********Train Epoch 47: averaged Loss: 0.277811, tf_ratio: 0.160533\n",
      "2025-04-14 19:29: **********Train Epoch 47: averaged Loss: 0.277811, tf_ratio: 0.160533\n",
      "2025-04-14 19:29: **********Train Epoch 47: averaged Loss: 0.277811, tf_ratio: 0.160533\n",
      "2025-04-14 19:29: **********Train Epoch 47: averaged Loss: 0.277811, tf_ratio: 0.160533\n",
      "2025-04-14 19:29: **********Train Epoch 47: averaged Loss: 0.277811, tf_ratio: 0.160533\n",
      "2025-04-14 19:29: **********Val Epoch 47: average Loss: 0.255779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Val Epoch 47: average Loss: 0.255779\n",
      "2025-04-14 19:29: **********Val Epoch 47: average Loss: 0.255779\n",
      "2025-04-14 19:29: **********Val Epoch 47: average Loss: 0.255779\n",
      "2025-04-14 19:29: **********Val Epoch 47: average Loss: 0.255779\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 48: 0/2 Loss: 0.251015\n",
      "2025-04-14 19:29: Train Epoch 48: 0/2 Loss: 0.251015\n",
      "2025-04-14 19:29: Train Epoch 48: 0/2 Loss: 0.251015\n",
      "2025-04-14 19:29: Train Epoch 48: 0/2 Loss: 0.251015\n",
      "2025-04-14 19:29: Train Epoch 48: 0/2 Loss: 0.251015\n",
      "2025-04-14 19:29: **********Train Epoch 48: averaged Loss: 0.278355, tf_ratio: 0.147510\n",
      "2025-04-14 19:29: **********Train Epoch 48: averaged Loss: 0.278355, tf_ratio: 0.147510\n",
      "2025-04-14 19:29: **********Train Epoch 48: averaged Loss: 0.278355, tf_ratio: 0.147510\n",
      "2025-04-14 19:29: **********Train Epoch 48: averaged Loss: 0.278355, tf_ratio: 0.147510\n",
      "2025-04-14 19:29: **********Train Epoch 48: averaged Loss: 0.278355, tf_ratio: 0.147510\n",
      "2025-04-14 19:29: **********Val Epoch 48: average Loss: 0.255762\n",
      "2025-04-14 19:29: **********Val Epoch 48: average Loss: 0.255762\n",
      "2025-04-14 19:29: **********Val Epoch 48: average Loss: 0.255762\n",
      "2025-04-14 19:29: **********Val Epoch 48: average Loss: 0.255762\n",
      "2025-04-14 19:29: **********Val Epoch 48: average Loss: 0.255762\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: Train Epoch 49: 0/2 Loss: 0.238303\n",
      "2025-04-14 19:29: Train Epoch 49: 0/2 Loss: 0.238303\n",
      "2025-04-14 19:29: Train Epoch 49: 0/2 Loss: 0.238303\n",
      "2025-04-14 19:29: Train Epoch 49: 0/2 Loss: 0.238303\n",
      "2025-04-14 19:29: Train Epoch 49: 0/2 Loss: 0.238303\n",
      "2025-04-14 19:29: **********Train Epoch 49: averaged Loss: 0.280439, tf_ratio: 0.135373\n",
      "2025-04-14 19:29: **********Train Epoch 49: averaged Loss: 0.280439, tf_ratio: 0.135373\n",
      "2025-04-14 19:29: **********Train Epoch 49: averaged Loss: 0.280439, tf_ratio: 0.135373\n",
      "2025-04-14 19:29: **********Train Epoch 49: averaged Loss: 0.280439, tf_ratio: 0.135373\n",
      "2025-04-14 19:29: **********Train Epoch 49: averaged Loss: 0.280439, tf_ratio: 0.135373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n",
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Val Epoch 49: average Loss: 0.255744\n",
      "2025-04-14 19:29: **********Val Epoch 49: average Loss: 0.255744\n",
      "2025-04-14 19:29: **********Val Epoch 49: average Loss: 0.255744\n",
      "2025-04-14 19:29: **********Val Epoch 49: average Loss: 0.255744\n",
      "2025-04-14 19:29: **********Val Epoch 49: average Loss: 0.255744\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Train Epoch 50: 0/2 Loss: 0.250962\n",
      "2025-04-14 19:29: Train Epoch 50: 0/2 Loss: 0.250962\n",
      "2025-04-14 19:29: Train Epoch 50: 0/2 Loss: 0.250962\n",
      "2025-04-14 19:29: Train Epoch 50: 0/2 Loss: 0.250962\n",
      "2025-04-14 19:29: Train Epoch 50: 0/2 Loss: 0.250962\n",
      "2025-04-14 19:29: **********Train Epoch 50: averaged Loss: 0.278291, tf_ratio: 0.124089\n",
      "2025-04-14 19:29: **********Train Epoch 50: averaged Loss: 0.278291, tf_ratio: 0.124089\n",
      "2025-04-14 19:29: **********Train Epoch 50: averaged Loss: 0.278291, tf_ratio: 0.124089\n",
      "2025-04-14 19:29: **********Train Epoch 50: averaged Loss: 0.278291, tf_ratio: 0.124089\n",
      "2025-04-14 19:29: **********Train Epoch 50: averaged Loss: 0.278291, tf_ratio: 0.124089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([4, 3, 272, 8])\n",
      "label shape: torch.Size([4, 3, 272, 8])\n",
      "output shape: torch.Size([3, 3, 272, 8])\n",
      "label shape: torch.Size([3, 3, 272, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:29: **********Val Epoch 50: average Loss: 0.255729\n",
      "2025-04-14 19:29: **********Val Epoch 50: average Loss: 0.255729\n",
      "2025-04-14 19:29: **********Val Epoch 50: average Loss: 0.255729\n",
      "2025-04-14 19:29: **********Val Epoch 50: average Loss: 0.255729\n",
      "2025-04-14 19:29: **********Val Epoch 50: average Loss: 0.255729\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Current best model saved!\n",
      "2025-04-14 19:29: Total training time: 0.1935min, best loss: 0.255729\n",
      "2025-04-14 19:29: Total training time: 0.1935min, best loss: 0.255729\n",
      "2025-04-14 19:29: Total training time: 0.1935min, best loss: 0.255729\n",
      "2025-04-14 19:29: Total training time: 0.1935min, best loss: 0.255729\n",
      "2025-04-14 19:29: Total training time: 0.1935min, best loss: 0.255729\n",
      "2025-04-14 19:29: Saving current best model to c:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\model\\logs/lr_init_0.0059745480826864684_embed_dim_6_lr_decay_0.17039700074755165\\best_model.pth\n",
      "2025-04-14 19:29: Saving current best model to c:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\model\\logs/lr_init_0.0059745480826864684_embed_dim_6_lr_decay_0.17039700074755165\\best_model.pth\n",
      "2025-04-14 19:29: Saving current best model to c:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\model\\logs/lr_init_0.0059745480826864684_embed_dim_6_lr_decay_0.17039700074755165\\best_model.pth\n",
      "2025-04-14 19:29: Saving current best model to c:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\model\\logs/lr_init_0.0059745480826864684_embed_dim_6_lr_decay_0.17039700074755165\\best_model.pth\n",
      "2025-04-14 19:29: Saving current best model to c:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\model\\logs/lr_init_0.0059745480826864684_embed_dim_6_lr_decay_0.17039700074755165\\best_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([2, 3, 272, 8])\n",
      "label shape: torch.Size([2, 3, 272, 8])\n",
      "last_output shape: torch.Size([2, 272, 8])\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation to pipeline data into model (for 2021 to 2023 % change volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country_a</th>\n",
       "      <th>country_b</th>\n",
       "      <th>bec_1</th>\n",
       "      <th>bec_2</th>\n",
       "      <th>bec_3</th>\n",
       "      <th>bec_4</th>\n",
       "      <th>bec_5</th>\n",
       "      <th>bec_6</th>\n",
       "      <th>bec_7</th>\n",
       "      <th>bec_8</th>\n",
       "      <th>D</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ARE</td>\n",
       "      <td>AUS</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.060739e+09</td>\n",
       "      <td>0.620151</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ARE</td>\n",
       "      <td>CHE</td>\n",
       "      <td>3.797882e+06</td>\n",
       "      <td>1.355991e+06</td>\n",
       "      <td>6.939408e+06</td>\n",
       "      <td>3.759398e+08</td>\n",
       "      <td>2.690339e+06</td>\n",
       "      <td>9.364289e+05</td>\n",
       "      <td>4.422947e+07</td>\n",
       "      <td>9.824469e+07</td>\n",
       "      <td>0.586050</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ARE</td>\n",
       "      <td>CHN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.953953e+09</td>\n",
       "      <td>0.635445</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ARE</td>\n",
       "      <td>DEU</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.159614e+08</td>\n",
       "      <td>0.566027</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ARE</td>\n",
       "      <td>FRA</td>\n",
       "      <td>4.972880e+07</td>\n",
       "      <td>4.680296e+07</td>\n",
       "      <td>9.306163e+07</td>\n",
       "      <td>7.307789e+07</td>\n",
       "      <td>9.781168e+07</td>\n",
       "      <td>1.751175e+07</td>\n",
       "      <td>1.162716e+08</td>\n",
       "      <td>2.462986e+08</td>\n",
       "      <td>0.620551</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 country_a country_b         bec_1         bec_2         bec_3  \\\n",
       "0           0       ARE       AUS  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1           1       ARE       CHE  3.797882e+06  1.355991e+06  6.939408e+06   \n",
       "2           2       ARE       CHN  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "3           3       ARE       DEU  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "4           4       ARE       FRA  4.972880e+07  4.680296e+07  9.306163e+07   \n",
       "\n",
       "          bec_4         bec_5         bec_6         bec_7         bec_8  \\\n",
       "0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  1.060739e+09   \n",
       "1  3.759398e+08  2.690339e+06  9.364289e+05  4.422947e+07  9.824469e+07   \n",
       "2  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  2.953953e+09   \n",
       "3  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  7.159614e+08   \n",
       "4  7.307789e+07  9.781168e+07  1.751175e+07  1.162716e+08  2.462986e+08   \n",
       "\n",
       "          D  year  \n",
       "0  0.620151  2006  \n",
       "1  0.586050  2006  \n",
       "2  0.635445  2006  \n",
       "3  0.566027  2006  \n",
       "4  0.620551  2006  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp=pd.read_csv('../data/final/final_modeL_data.csv',header=0)\n",
    "# temp.head()\n",
    "# temp.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "# temp=temp[(temp['country_a']!='ARE')& (temp['country_b']!='ARE')]\n",
    "# temp=temp[(temp['year']>=2020) & (temp['year']<=2023)]\n",
    "# temp_only_d=temp[['D','country_a','country_b','year']]\n",
    "# temp.drop(columns=['D'],inplace=True)\n",
    "# temp.sort_values(by=['country_a','country_b','year'],inplace=True)\n",
    "# bec_columns = [f'bec_{i}' for i in range(1, 9)]\n",
    "# for col in bec_columns:\n",
    "#     # Create a new column to store the percentage change.\n",
    "#     temp[f'pct_{col}'] = temp.groupby(['country_a', 'country_b'])[col].pct_change() * 100\n",
    "# temp.dropna(inplace=True)\n",
    "# temp.reset_index(drop=True,inplace=True)\n",
    "# temp=temp.merge(temp_only_d, on=['country_a','country_b','year'], how='left')\n",
    "# temp.drop(columns=bec_columns,inplace=True)\n",
    "# temp.rename(columns={'pct_bec_1':'bec_1','pct_bec_2':'bec_2','pct_bec_3':'bec_3','pct_bec_4':'bec_4','pct_bec_5':'bec_5','pct_bec_6':'bec_6','pct_bec_7':'bec_7','pct_bec_8':'bec_8'},inplace=True)\n",
    "# temp.to_csv('../data/final/without_ARE_pct_2021_2023.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_actual=Args()\n",
    "args_actual.set_args(embed_dim=10, lr_init=0.005489139587271934,lr_decay_rate=0.18605505546333992, rnn_units=64, num_layers=2, weight_decay=3.0450041080579258e-05) #based on best model by Optuna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelining the data into the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_tensor_run(csv_file\n",
    "                    #   ,sentiment_dict,year_nlp=2023\n",
    "                      ):\n",
    "    \"\"\"\n",
    "    Reads a CSV file with columns:\n",
    "      country1, country2, sector1, sector2, ..., sector8, sentiment, year\n",
    "    and returns a tensor of shape (T, N, D), where:\n",
    "      T = number of years,\n",
    "      N = number of unique country pairs,\n",
    "      D = num of sectors + features.\n",
    "    Also returns the sorted list of years and country pair nodes.\n",
    "    \"\"\"\n",
    "    def change_sentiment_index(df1,dict,year):\n",
    "        \"\"\"\n",
    "        Change the sentiment index of the dataframe based on NLP model. (For now, it replaces based on year)\n",
    "        \"\"\"\n",
    "        for country_pair, sentiment in dict.items():\n",
    "            # Extract the country pair from the tuple\n",
    "            country_a, country_b = country_pair.split('-')\n",
    "            # Update the sentiment index for the specific year and country pair\n",
    "            df1.loc[(df1['year'] == year) & (df1['country_a'] == country_a) & (df1['country_b'] == country_b), 'sentiment_index'] = sentiment\n",
    "            df1.loc[(df1['year'] == year) & (df1['country_a'] == country_b) & (df1['country_b'] == country_a), 'sentiment_index'] = sentiment\n",
    "        return df1\n",
    "    # Read the CSV into a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # df=change_sentiment_index(df,sentiment_dict,year_nlp)\n",
    "\n",
    "    # # Transform tradeagreementindex and sentiment_index into D\n",
    "    # df['D']=1+(-1)*0.5*df['tradeagreementindex']+(-1)*0.5*df['sentiment_index']\n",
    "    # df=df.drop(columns=['sentiment_index','tradeagreementindex'],axis=1)   \n",
    "\n",
    "    T= len(df['year'].unique())\n",
    "    years= sorted(df['year'].unique())\n",
    "    # Get all unique country pairs\n",
    "    pairs_df = df[['country_a', 'country_b']].drop_duplicates()\n",
    "    # Create a sorted list of tuples (country1, country2) for consistent node ordering\n",
    "    country_pairs = sorted([tuple(x) for x in pairs_df.values])\n",
    "    N = len(country_pairs)\n",
    "    \n",
    "    # Number of features (8 sectors + 1 sentiment)\n",
    "    D = 9\n",
    "\n",
    "    # Initialize an empty numpy array for the tensor data\n",
    "    tensor_data = np.empty((T, N, D), dtype=float)\n",
    "    \n",
    "    # Loop over each year and each country pair to fill in the tensor\n",
    "    for t, year in enumerate(years):\n",
    "        # Get data for the current year\n",
    "        df_year = df[df['year'] == year]\n",
    "        for n, (c1, c2) in enumerate(country_pairs):\n",
    "            # Filter rows for the current country pair\n",
    "            row = df_year[(df_year['country_a'] == c1) & (df_year['country_b'] == c2)]\n",
    "            if not row.empty:\n",
    "                # Extract the 8 sector columns and the sentiment column.\n",
    "                # Assumes these columns are named exactly as shown.\n",
    "                features = row.iloc[0][['bec_1', 'bec_2', 'bec_3', 'bec_4', \n",
    "                                         'bec_5', 'bec_6', 'bec_7', 'bec_8', 'D']].values\n",
    "                tensor_data[t, n, :] = features.astype(float)\n",
    "            else:\n",
    "                # If a record is missing for a given year/country pair, fill with zeros (or choose another strategy)\n",
    "                tensor_data[t, n, :] = np.zeros(D)\n",
    "                \n",
    "    return tensor_data, years, country_pairs\n",
    "\n",
    "def group_into_windows(tensor_data, window_size):\n",
    "    \"\"\"\n",
    "    Given a tensor of shape (T, N, D), group the data into overlapping windows.\n",
    "    Each window is of length window_size\n",
    "    Returns a numpy array of shape (num_samples, window_size, N, D).\n",
    "    \"\"\"\n",
    "    T, N, D = tensor_data.shape\n",
    "    num_samples = T - window_size + 1  # sliding window with stride 1\n",
    "    windows = []\n",
    "    for i in range(num_samples):\n",
    "        window = tensor_data[i: i + window_size]  # shape: (window_size, N, D)\n",
    "        windows.append(window)\n",
    "    windows = np.stack(windows)  # shape: (num_samples, window_size, N, D)\n",
    "    return windows\n",
    "\n",
    "def split_input_target_direct(windows, input_len, horizon=3):\n",
    "    \"\"\"\n",
    "    Splits each window into input and a single target that is horizon steps forward.\n",
    "    \n",
    "    windows: numpy array of shape (num_samples, window_size, N, D)\n",
    "              where window_size = input_len + horizon.\n",
    "    input_len: number of time steps used as input.\n",
    "    horizon: steps forward to pick the target (here, horizon=3).\n",
    "    \n",
    "    Returns:\n",
    "      x: inputs of shape (num_samples, input_len, N, D)\n",
    "      y: targets of shape (num_samples, N, 8), which are the first 8 features of the target time step.\n",
    "    \"\"\"\n",
    "    # x: first input_len time steps (e.g., years 2006-2009 if input_len=4)\n",
    "    x = windows[:, :input_len]  \n",
    "    # y_full: the time step exactly horizon steps forward (i.e., index input_len + horizon - 1)\n",
    "    # y_full = windows[:, input_len + horizon-1]  \n",
    "    y_full = windows[:, input_len:input_len + horizon]\n",
    "    # y: only the first 8 features from the predicted time step (ignoring sentiment_index and tradeagreementindex)\n",
    "    y = y_full[..., :8]\n",
    "    return x, y\n",
    "\n",
    "def train_val_split(x, y, val_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Splits the data into train and validation sets by ratio.\n",
    "    \"\"\"\n",
    "    num_samples = x.shape[0]\n",
    "    split_index = int(num_samples * (1 - val_ratio))\n",
    "    x_train, y_train = x[:split_index], y[:split_index]\n",
    "    x_val, y_val = x[split_index:], y[split_index:]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AGCRN.lib.dataloader import normalize_dataset\n",
    "\n",
    "test_data_tensor, years, country_pairs_model = csv_to_tensor_run('./data/final/without_ARE_pct_2021_2023.csv'\n",
    "                                                                #  ,sentiment_dict=sentiment_dict,year_nlp=year_nlp\n",
    "                                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect country_pairs to ensure it is the same as initial_nums to perform data transformation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AUS', 'CHE'),\n",
       " ('AUS', 'CHN'),\n",
       " ('AUS', 'DEU'),\n",
       " ('AUS', 'FRA'),\n",
       " ('AUS', 'HKG'),\n",
       " ('AUS', 'IDN'),\n",
       " ('AUS', 'IND'),\n",
       " ('AUS', 'JPN'),\n",
       " ('AUS', 'KOR'),\n",
       " ('AUS', 'MYS'),\n",
       " ('AUS', 'NLD'),\n",
       " ('AUS', 'PHL'),\n",
       " ('AUS', 'SGP'),\n",
       " ('AUS', 'THA'),\n",
       " ('AUS', 'USA'),\n",
       " ('AUS', 'VNM'),\n",
       " ('CHE', 'AUS'),\n",
       " ('CHE', 'CHN'),\n",
       " ('CHE', 'DEU'),\n",
       " ('CHE', 'FRA'),\n",
       " ('CHE', 'HKG'),\n",
       " ('CHE', 'IDN'),\n",
       " ('CHE', 'IND'),\n",
       " ('CHE', 'JPN'),\n",
       " ('CHE', 'KOR'),\n",
       " ('CHE', 'MYS'),\n",
       " ('CHE', 'NLD'),\n",
       " ('CHE', 'PHL'),\n",
       " ('CHE', 'SGP'),\n",
       " ('CHE', 'THA'),\n",
       " ('CHE', 'USA'),\n",
       " ('CHE', 'VNM'),\n",
       " ('CHN', 'AUS'),\n",
       " ('CHN', 'CHE'),\n",
       " ('CHN', 'DEU'),\n",
       " ('CHN', 'FRA'),\n",
       " ('CHN', 'HKG'),\n",
       " ('CHN', 'IDN'),\n",
       " ('CHN', 'IND'),\n",
       " ('CHN', 'JPN'),\n",
       " ('CHN', 'KOR'),\n",
       " ('CHN', 'MYS'),\n",
       " ('CHN', 'NLD'),\n",
       " ('CHN', 'PHL'),\n",
       " ('CHN', 'SGP'),\n",
       " ('CHN', 'THA'),\n",
       " ('CHN', 'USA'),\n",
       " ('CHN', 'VNM'),\n",
       " ('DEU', 'AUS'),\n",
       " ('DEU', 'CHE'),\n",
       " ('DEU', 'CHN'),\n",
       " ('DEU', 'FRA'),\n",
       " ('DEU', 'HKG'),\n",
       " ('DEU', 'IDN'),\n",
       " ('DEU', 'IND'),\n",
       " ('DEU', 'JPN'),\n",
       " ('DEU', 'KOR'),\n",
       " ('DEU', 'MYS'),\n",
       " ('DEU', 'NLD'),\n",
       " ('DEU', 'PHL'),\n",
       " ('DEU', 'SGP'),\n",
       " ('DEU', 'THA'),\n",
       " ('DEU', 'USA'),\n",
       " ('DEU', 'VNM'),\n",
       " ('FRA', 'AUS'),\n",
       " ('FRA', 'CHE'),\n",
       " ('FRA', 'CHN'),\n",
       " ('FRA', 'DEU'),\n",
       " ('FRA', 'HKG'),\n",
       " ('FRA', 'IDN'),\n",
       " ('FRA', 'IND'),\n",
       " ('FRA', 'JPN'),\n",
       " ('FRA', 'KOR'),\n",
       " ('FRA', 'MYS'),\n",
       " ('FRA', 'NLD'),\n",
       " ('FRA', 'PHL'),\n",
       " ('FRA', 'SGP'),\n",
       " ('FRA', 'THA'),\n",
       " ('FRA', 'USA'),\n",
       " ('FRA', 'VNM'),\n",
       " ('HKG', 'AUS'),\n",
       " ('HKG', 'CHE'),\n",
       " ('HKG', 'CHN'),\n",
       " ('HKG', 'DEU'),\n",
       " ('HKG', 'FRA'),\n",
       " ('HKG', 'IDN'),\n",
       " ('HKG', 'IND'),\n",
       " ('HKG', 'JPN'),\n",
       " ('HKG', 'KOR'),\n",
       " ('HKG', 'MYS'),\n",
       " ('HKG', 'NLD'),\n",
       " ('HKG', 'PHL'),\n",
       " ('HKG', 'SGP'),\n",
       " ('HKG', 'THA'),\n",
       " ('HKG', 'USA'),\n",
       " ('HKG', 'VNM'),\n",
       " ('IDN', 'AUS'),\n",
       " ('IDN', 'CHE'),\n",
       " ('IDN', 'CHN'),\n",
       " ('IDN', 'DEU'),\n",
       " ('IDN', 'FRA'),\n",
       " ('IDN', 'HKG'),\n",
       " ('IDN', 'IND'),\n",
       " ('IDN', 'JPN'),\n",
       " ('IDN', 'KOR'),\n",
       " ('IDN', 'MYS'),\n",
       " ('IDN', 'NLD'),\n",
       " ('IDN', 'PHL'),\n",
       " ('IDN', 'SGP'),\n",
       " ('IDN', 'THA'),\n",
       " ('IDN', 'USA'),\n",
       " ('IDN', 'VNM'),\n",
       " ('IND', 'AUS'),\n",
       " ('IND', 'CHE'),\n",
       " ('IND', 'CHN'),\n",
       " ('IND', 'DEU'),\n",
       " ('IND', 'FRA'),\n",
       " ('IND', 'HKG'),\n",
       " ('IND', 'IDN'),\n",
       " ('IND', 'JPN'),\n",
       " ('IND', 'KOR'),\n",
       " ('IND', 'MYS'),\n",
       " ('IND', 'NLD'),\n",
       " ('IND', 'PHL'),\n",
       " ('IND', 'SGP'),\n",
       " ('IND', 'THA'),\n",
       " ('IND', 'USA'),\n",
       " ('IND', 'VNM'),\n",
       " ('JPN', 'AUS'),\n",
       " ('JPN', 'CHE'),\n",
       " ('JPN', 'CHN'),\n",
       " ('JPN', 'DEU'),\n",
       " ('JPN', 'FRA'),\n",
       " ('JPN', 'HKG'),\n",
       " ('JPN', 'IDN'),\n",
       " ('JPN', 'IND'),\n",
       " ('JPN', 'KOR'),\n",
       " ('JPN', 'MYS'),\n",
       " ('JPN', 'NLD'),\n",
       " ('JPN', 'PHL'),\n",
       " ('JPN', 'SGP'),\n",
       " ('JPN', 'THA'),\n",
       " ('JPN', 'USA'),\n",
       " ('JPN', 'VNM'),\n",
       " ('KOR', 'AUS'),\n",
       " ('KOR', 'CHE'),\n",
       " ('KOR', 'CHN'),\n",
       " ('KOR', 'DEU'),\n",
       " ('KOR', 'FRA'),\n",
       " ('KOR', 'HKG'),\n",
       " ('KOR', 'IDN'),\n",
       " ('KOR', 'IND'),\n",
       " ('KOR', 'JPN'),\n",
       " ('KOR', 'MYS'),\n",
       " ('KOR', 'NLD'),\n",
       " ('KOR', 'PHL'),\n",
       " ('KOR', 'SGP'),\n",
       " ('KOR', 'THA'),\n",
       " ('KOR', 'USA'),\n",
       " ('KOR', 'VNM'),\n",
       " ('MYS', 'AUS'),\n",
       " ('MYS', 'CHE'),\n",
       " ('MYS', 'CHN'),\n",
       " ('MYS', 'DEU'),\n",
       " ('MYS', 'FRA'),\n",
       " ('MYS', 'HKG'),\n",
       " ('MYS', 'IDN'),\n",
       " ('MYS', 'IND'),\n",
       " ('MYS', 'JPN'),\n",
       " ('MYS', 'KOR'),\n",
       " ('MYS', 'NLD'),\n",
       " ('MYS', 'PHL'),\n",
       " ('MYS', 'SGP'),\n",
       " ('MYS', 'THA'),\n",
       " ('MYS', 'USA'),\n",
       " ('MYS', 'VNM'),\n",
       " ('NLD', 'AUS'),\n",
       " ('NLD', 'CHE'),\n",
       " ('NLD', 'CHN'),\n",
       " ('NLD', 'DEU'),\n",
       " ('NLD', 'FRA'),\n",
       " ('NLD', 'HKG'),\n",
       " ('NLD', 'IDN'),\n",
       " ('NLD', 'IND'),\n",
       " ('NLD', 'JPN'),\n",
       " ('NLD', 'KOR'),\n",
       " ('NLD', 'MYS'),\n",
       " ('NLD', 'PHL'),\n",
       " ('NLD', 'SGP'),\n",
       " ('NLD', 'THA'),\n",
       " ('NLD', 'USA'),\n",
       " ('NLD', 'VNM'),\n",
       " ('PHL', 'AUS'),\n",
       " ('PHL', 'CHE'),\n",
       " ('PHL', 'CHN'),\n",
       " ('PHL', 'DEU'),\n",
       " ('PHL', 'FRA'),\n",
       " ('PHL', 'HKG'),\n",
       " ('PHL', 'IDN'),\n",
       " ('PHL', 'IND'),\n",
       " ('PHL', 'JPN'),\n",
       " ('PHL', 'KOR'),\n",
       " ('PHL', 'MYS'),\n",
       " ('PHL', 'NLD'),\n",
       " ('PHL', 'SGP'),\n",
       " ('PHL', 'THA'),\n",
       " ('PHL', 'USA'),\n",
       " ('PHL', 'VNM'),\n",
       " ('SGP', 'AUS'),\n",
       " ('SGP', 'CHE'),\n",
       " ('SGP', 'CHN'),\n",
       " ('SGP', 'DEU'),\n",
       " ('SGP', 'FRA'),\n",
       " ('SGP', 'HKG'),\n",
       " ('SGP', 'IDN'),\n",
       " ('SGP', 'IND'),\n",
       " ('SGP', 'JPN'),\n",
       " ('SGP', 'KOR'),\n",
       " ('SGP', 'MYS'),\n",
       " ('SGP', 'NLD'),\n",
       " ('SGP', 'PHL'),\n",
       " ('SGP', 'THA'),\n",
       " ('SGP', 'USA'),\n",
       " ('SGP', 'VNM'),\n",
       " ('THA', 'AUS'),\n",
       " ('THA', 'CHE'),\n",
       " ('THA', 'CHN'),\n",
       " ('THA', 'DEU'),\n",
       " ('THA', 'FRA'),\n",
       " ('THA', 'HKG'),\n",
       " ('THA', 'IDN'),\n",
       " ('THA', 'IND'),\n",
       " ('THA', 'JPN'),\n",
       " ('THA', 'KOR'),\n",
       " ('THA', 'MYS'),\n",
       " ('THA', 'NLD'),\n",
       " ('THA', 'PHL'),\n",
       " ('THA', 'SGP'),\n",
       " ('THA', 'USA'),\n",
       " ('THA', 'VNM'),\n",
       " ('USA', 'AUS'),\n",
       " ('USA', 'CHE'),\n",
       " ('USA', 'CHN'),\n",
       " ('USA', 'DEU'),\n",
       " ('USA', 'FRA'),\n",
       " ('USA', 'HKG'),\n",
       " ('USA', 'IDN'),\n",
       " ('USA', 'IND'),\n",
       " ('USA', 'JPN'),\n",
       " ('USA', 'KOR'),\n",
       " ('USA', 'MYS'),\n",
       " ('USA', 'NLD'),\n",
       " ('USA', 'PHL'),\n",
       " ('USA', 'SGP'),\n",
       " ('USA', 'THA'),\n",
       " ('USA', 'VNM'),\n",
       " ('VNM', 'AUS'),\n",
       " ('VNM', 'CHE'),\n",
       " ('VNM', 'CHN'),\n",
       " ('VNM', 'DEU'),\n",
       " ('VNM', 'FRA'),\n",
       " ('VNM', 'HKG'),\n",
       " ('VNM', 'IDN'),\n",
       " ('VNM', 'IND'),\n",
       " ('VNM', 'JPN'),\n",
       " ('VNM', 'KOR'),\n",
       " ('VNM', 'MYS'),\n",
       " ('VNM', 'NLD'),\n",
       " ('VNM', 'PHL'),\n",
       " ('VNM', 'SGP'),\n",
       " ('VNM', 'THA'),\n",
       " ('VNM', 'USA')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_pairs_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for year 2021:\n",
      "[[-23.76676415   5.44830872   8.48811764 ... -16.42896358   0.16023751\n",
      "    0.80989102]\n",
      " [ -4.32133521  28.1916725   27.40833829 ...   4.54033474 -27.55138592\n",
      "    0.86075767]\n",
      " [ 30.04506149  -6.13320462   7.47301508 ... -19.3816128   10.17375255\n",
      "    0.83792047]\n",
      " ...\n",
      " [  4.71237695  53.61440096  27.75656542 ...   2.92823602  29.68103916\n",
      "    0.63215932]\n",
      " [-11.86357687  46.59080175  10.18924034 ...   4.79350723  45.04526876\n",
      "    0.64640775]\n",
      " [ 14.98410578  23.31365631  36.93566773 ...  11.27367646  10.96054528\n",
      "    0.85279134]]\n",
      "Features for ('AUS', 'CHE') in 2021:\n",
      "[-23.76676415   5.44830872   8.48811764 -36.85539035 -14.90805586\n",
      " -14.90717037 -16.42896358   0.16023751   0.80989102]\n"
     ]
    }
   ],
   "source": [
    "# Inspect data to check\n",
    "print(\"Data for year {}:\".format(years[0]))\n",
    "print(test_data_tensor[0])  # prints the data for all nodes/features for the first year\n",
    "\n",
    "\n",
    "print(\"Features for {} in {}:\".format(country_pairs[0], years[0]))\n",
    "print(test_data_tensor[0, 0, :]) # prints the features for the first country pair in the first year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize the dataset by MinMax11 Normalization\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#do normalisation\n",
    "data_to_normalize = test_data_tensor[:, :, :8]\n",
    "normalized_data, scaler = normalize_dataset(data_to_normalize, normalizer=args.normaliser,column_wise=True)\n",
    "remaining_features = test_data_tensor[:, :, 8:]\n",
    "\n",
    "# Get the shape dimensions\n",
    "T, N, _ = remaining_features.shape\n",
    "\n",
    "# Initialize the scaler with the desired feature range (-1, 1)\n",
    "scaler2 = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# Reshape the first column of remaining_features to 2D (T*N, 1)\n",
    "col_data = remaining_features[:, :, 0].reshape(-1, 1)\n",
    "\n",
    "# Fit and transform the column data using the scaler\n",
    "col_scaled = scaler2.fit_transform(col_data)\n",
    "\n",
    "# Reshape back to the original shape (T, N, 1)\n",
    "col_scaled = col_scaled.reshape(T, N, 1)\n",
    "# Concatenate along the last axis\n",
    "normalized_test_data = np.concatenate((normalized_data, col_scaled), axis=-1)\n",
    "test_x_tensor=torch.tensor(normalized_test_data, dtype=torch.float32)\n",
    "test_x_tensor = test_x_tensor.unsqueeze(0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single pass of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agcrn_model import AGCRNFinal\n",
    "\n",
    "#load model and previously saved states\n",
    "model=AGCRNFinal(args_actual)\n",
    "model=model.to(args_actual.device)\n",
    "model.load_state_dict(torch.load('./logs/best_model_69.pth',map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_x_tensor = test_x_tensor.to(args_actual.device)\n",
    "    predictions = model(test_x_tensor,None,0)\n",
    "    predictions = predictions.cpu().numpy()\n",
    "\n",
    "#convert back to original scale\n",
    "predictions = scaler.inverse_transform(predictions[0, :, :, :8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert % change predictions into absolute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_nums=pd.read_csv('./data/final/without_ARE_2021_2023.csv',header=0)\n",
    "\n",
    "# we only need 2023 data to compute forecasted 2024, 2025 and 2026 values\n",
    "initial_nums=initial_nums[initial_nums['year']==2023]\n",
    "initial_nums.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for ordering of country pairs before appending back to dataframe (should have no outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe indices by country pairs\n",
    "for country_pair in country_pairs:\n",
    "    country_a, country_b = country_pair\n",
    "    \n",
    "    # Extract the subset of dataframe where country_a and country_b match\n",
    "    subset = initial_nums[(initial_nums['country_a'] == country_a) & (initial_nums['country_b'] == country_b)]\n",
    "    \n",
    "    #check for any country pair/year missing \n",
    "    if subset.empty:\n",
    "       print(f'country_pair: ({country_a}, {country_b}) is missing')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applying percentage change to absolute values to get forecasted 24,25,26 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bec_cols=[f'bec_{i}' for i in range(1, 9)]\n",
    "future_years = [2024, 2025, 2026]\n",
    "predicted=[]\n",
    "\n",
    "for pair_idx, row in initial_nums.iterrows():\n",
    "    # convert base values to numpy array and float\n",
    "    base_values = row[bec_cols].values.astype(float)\n",
    "    \n",
    "    # copy just for saving the initial values\n",
    "    current_values = base_values.copy()\n",
    "    \n",
    "    # Apply the percentage changes for each future year\n",
    "    for year_offset, future_year in enumerate(future_years):\n",
    "        # extract the 8 % changes for country pair in forecast_year\n",
    "        pct_change = predictions[year_offset, pair_idx, :]\n",
    "        # convert to factor change\n",
    "        factor = 1 + pct_change / 100.0\n",
    "        \n",
    "        # update current values\n",
    "        current_values = current_values * factor\n",
    "        \n",
    "        # build dictionary to build final dataframe\n",
    "        row_dict = {\n",
    "            'country_a': row['country_a'],\n",
    "            'country_b': row['country_b'],\n",
    "            'year': future_year\n",
    "        }\n",
    "        # add each bec column\n",
    "        for col_idx, col in enumerate(bec_cols):\n",
    "            row_dict[col] = current_values[col_idx]\n",
    "        \n",
    "        # Add the row to our list\n",
    "        predicted.append(row_dict)\n",
    "\n",
    "# Create a new df containing the predicted absolute trade volumes for 2024, 2025, 2026\n",
    "predictions_df = pd.DataFrame(predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline data to frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put exports and imports in the same row and transform column names\n",
    "temp=pd.merge(predictions_df,predictions_df,how='outer',left_on=['country_a','country_b','year'],right_on=['country_b','country_a','year'],suffixes=('_export_A_to_b', '_import_A_from_B'))\n",
    "temp.drop(columns=['country_a_import_A_from_B','country_b_import_A_from_B'],inplace=True)\n",
    "temp.rename(columns={'country_a_export_A_to_b':'country_a','country_b_export_A_to_b':'country_b'},inplace=True)\n",
    "temp['country_pair'] = temp.apply(\n",
    "    lambda x: '_'.join(sorted([x['country_a'], x['country_b']])), \n",
    "    axis=1\n",
    ")\n",
    "temp = temp.drop_duplicates(subset=['country_pair', 'year'], keep='first')\n",
    "temp = temp.drop('country_pair', axis=1)\n",
    "\n",
    "#add additional columns for frontend\n",
    "bec_export_cols=[f'bec_{i}_export_A_to_b' for i in range(1, 9)]\n",
    "bec_import_cols=[f'bec_{i}_import_A_from_B' for i in range(1, 9)]\n",
    "temp['total_export_A_to_B']=temp[bec_export_cols].sum(axis=1)\n",
    "temp['total_import_A_from_B']=temp[bec_import_cols].sum(axis=1)\n",
    "temp['trade_volume']=temp['total_export_A_to_B']+temp['total_import_A_from_B']\n",
    "temp['scenario']='forecast'\n",
    "\n",
    "#reorder columns for frontend\n",
    "temp=temp[['country_a','country_b','year','total_export_A_to_B','total_import_A_from_B','trade_volume']+bec_export_cols+bec_import_cols+['scenario']]\n",
    "\n",
    "# # #filter only 2026 data and add scenario column for frontend\n",
    "# temp=temp[temp['year']==2026] #comment out if need 2024 to 2026 data as well\n",
    "\n",
    "temp['scenario']='postshock'\n",
    "\n",
    "baseline=pd.read_csv('./data/final/2026_baseline_forecast.csv',header=0)\n",
    "final=pd.concat([baseline,temp],axis=0,ignore_index=True)\n",
    "final.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: \n",
    "temp is the final dataframe that contains the same columns as sample_2026.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country_a', 'country_b', 'year', 'total_export_A_to_B',\n",
       "       'total_import_A_from_B', 'trade_volume', 'bec_1_export_A_to_b',\n",
       "       'bec_2_export_A_to_b', 'bec_3_export_A_to_b', 'bec_4_export_A_to_b',\n",
       "       'bec_5_export_A_to_b', 'bec_6_export_A_to_b', 'bec_7_export_A_to_b',\n",
       "       'bec_8_export_A_to_b', 'bec_1_import_A_from_B', 'bec_2_import_A_from_B',\n",
       "       'bec_3_import_A_from_B', 'bec_4_import_A_from_B',\n",
       "       'bec_5_import_A_from_B', 'bec_6_import_A_from_B',\n",
       "       'bec_7_import_A_from_B', 'bec_8_import_A_from_B', 'scenario'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check temp columns\n",
    "final.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
