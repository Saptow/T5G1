{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trying out a pytorch geometric temporal implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.display import clear_output\n",
    "pt_version = torch.__version__\n",
    "print(pt_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-geometric-temporal in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (0.54.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: decorator==4.4.2 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch-geometric-temporal) (4.4.2)\n",
      "Requirement already satisfied: torch in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch-geometric-temporal) (2.6.0)\n",
      "Requirement already satisfied: cython in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch-geometric-temporal) (3.0.12)\n",
      "Requirement already satisfied: pandas<=1.3.5 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch-geometric-temporal) (1.3.5)\n",
      "Requirement already satisfied: torch_sparse in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch-geometric-temporal) (0.6.18+pt23cpu)\n",
      "Requirement already satisfied: torch_scatter in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch-geometric-temporal) (2.1.2+pt23cpu)\n",
      "Requirement already satisfied: torch_geometric in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch-geometric-temporal) (2.6.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch-geometric-temporal) (1.26.4)\n",
      "Requirement already satisfied: six in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch-geometric-temporal) (1.17.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch-geometric-temporal) (3.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from pandas<=1.3.5->torch-geometric-temporal) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from pandas<=1.3.5->torch-geometric-temporal) (2025.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch->torch-geometric-temporal) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch->torch-geometric-temporal) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch->torch-geometric-temporal) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch->torch-geometric-temporal) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch->torch-geometric-temporal) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch->torch-geometric-temporal) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from sympy==1.13.1->torch->torch-geometric-temporal) (1.3.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch_geometric->torch-geometric-temporal) (3.11.14)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch_geometric->torch-geometric-temporal) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch_geometric->torch-geometric-temporal) (3.2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch_geometric->torch-geometric-temporal) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch_geometric->torch-geometric-temporal) (4.67.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from torch_sparse->torch-geometric-temporal) (1.15.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from aiohttp->torch_geometric->torch-geometric-temporal) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from aiohttp->torch_geometric->torch-geometric-temporal) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from aiohttp->torch_geometric->torch-geometric-temporal) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from aiohttp->torch_geometric->torch-geometric-temporal) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from aiohttp->torch_geometric->torch-geometric-temporal) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from aiohttp->torch_geometric->torch-geometric-temporal) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from aiohttp->torch_geometric->torch-geometric-temporal) (1.18.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from jinja2->torch->torch-geometric-temporal) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from requests->torch_geometric->torch-geometric-temporal) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from requests->torch_geometric->torch-geometric-temporal) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from requests->torch_geometric->torch-geometric-temporal) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from requests->torch_geometric->torch-geometric-temporal) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\rob-l\\documents\\nus\\y3s2\\dse3101\\t5g1\\venv\\lib\\site-packages (from tqdm->torch_geometric->torch-geometric-temporal) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "%pip install torch-geometric-temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated synthetic export data with 96 records\n",
      "   timestamp source_country target_country  export_volume\n",
      "0 2020-01-31      Country_0      Country_1      23.323699\n",
      "1 2020-01-31      Country_0      Country_2      27.390971\n",
      "2 2020-01-31      Country_1      Country_0      29.573955\n",
      "3 2020-01-31      Country_1      Country_2      44.807302\n",
      "4 2020-01-31      Country_2      Country_0      37.974495\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn import MSELoss\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Create synthetic export data\n",
    "def generate_synthetic_export_data(num_countries=3, num_timestamps=16, sparsity=0):\n",
    "    \"\"\"\n",
    "    Generate synthetic export data between countries\n",
    "    \n",
    "    Args:\n",
    "        num_countries: Number of countries in the dataset\n",
    "        num_timestamps: Number of time points\n",
    "        sparsity: Fraction of country pairs that have trade relationships\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns [timestamp, source_country, target_country, export_volume]\n",
    "    \"\"\"\n",
    "    countries = [f\"Country_{i}\" for i in range(num_countries)]\n",
    "    timestamps = pd.date_range(start='2020-01-01', periods=num_timestamps, freq='M')\n",
    "    \n",
    "    # Create all possible country pairs\n",
    "    country_pairs = []\n",
    "    for src in countries:\n",
    "        for tgt in countries:\n",
    "            if src != tgt and random.random() > sparsity:  # Add sparsity\n",
    "                country_pairs.append((src, tgt))\n",
    "    \n",
    "    data = []\n",
    "    for ts in timestamps:\n",
    "        for src, tgt in country_pairs:\n",
    "            # Create some temporal patterns and country-specific effects\n",
    "            src_idx = int(src.split('_')[1])\n",
    "            tgt_idx = int(tgt.split('_')[1])\n",
    "            \n",
    "            # Base volume depends on source and target country sizes\n",
    "            base_volume = (src_idx + 1) * 10 + (tgt_idx + 1) * 5\n",
    "            \n",
    "            # Add seasonal pattern\n",
    "            month = ts.month\n",
    "            seasonal_factor = 1.0 + 0.2 * np.sin(2 * np.pi * month / 12)\n",
    "            \n",
    "            # Add trend\n",
    "            trend_factor = 1.0 + 0.01 * (ts.year - 2020) * 12 + 0.01 * ts.month\n",
    "            \n",
    "            # Add some randomness\n",
    "            noise = np.random.normal(1, 0.1)\n",
    "            \n",
    "            export_volume = base_volume * seasonal_factor * trend_factor * noise\n",
    "            \n",
    "            data.append({\n",
    "                'timestamp': ts,\n",
    "                'source_country': src,\n",
    "                'target_country': tgt,\n",
    "                'export_volume': export_volume\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate example data\n",
    "data = generate_synthetic_export_data(num_countries=3, num_timestamps=16)\n",
    "print(f\"Generated synthetic export data with {len(data)} records\")\n",
    "print(data.head())\n",
    "\n",
    "# Create a dataset class for MTGNN\n",
    "class ExportDataset(Dataset):\n",
    "    def __init__(self, data, num_countries, seq_length, predict_length):\n",
    "        \"\"\"\n",
    "        data: DataFrame with columns [timestamp, source_country, target_country, export_volume]\n",
    "        num_countries: Total number of countries\n",
    "        seq_length: Historical sequence length to use for prediction\n",
    "        predict_length: Number of future time steps to predict\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.num_countries = num_countries\n",
    "        self.seq_length = seq_length\n",
    "        self.predict_length = predict_length\n",
    "        \n",
    "        # Get unique timestamps\n",
    "        self.timestamps = sorted(data['timestamp'].unique())\n",
    "        \n",
    "        # Create a mapping of country names to indices\n",
    "        countries = sorted(set(data['source_country'].unique()) | set(data['target_country'].unique()))\n",
    "        self.country_to_idx = {country: idx for idx, country in enumerate(countries)}\n",
    "        self.idx_to_country = {idx: country for country, idx in self.country_to_idx.items()}\n",
    "        \n",
    "        # Create adjacency matrices for each timestamp\n",
    "        self.adj_matrices = {}\n",
    "        self.node_features = {}  # Total exports per country at each timestamp\n",
    "        for ts in self.timestamps:\n",
    "            adj = np.zeros((num_countries, num_countries))\n",
    "            ts_data = data[data['timestamp'] == ts]\n",
    "            \n",
    "            for _, row in ts_data.iterrows():\n",
    "                src_idx = self.country_to_idx[row['source_country']]\n",
    "                tgt_idx = self.country_to_idx[row['target_country']]\n",
    "                adj[src_idx, tgt_idx] = row['export_volume']\n",
    "                \n",
    "            self.adj_matrices[ts] = adj\n",
    "            \n",
    "            # Calculate total exports per country\n",
    "            self.node_features[ts] = np.sum(adj, axis=1)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.timestamps) - self.seq_length - self.predict_length + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get sequence of timestamps\n",
    "        input_timestamps = self.timestamps[idx:idx+self.seq_length]\n",
    "        target_timestamps = self.timestamps[idx+self.seq_length:idx+self.seq_length+self.predict_length]\n",
    "        \n",
    "        # Create input tensor of shape (in_channels, num_nodes, seq_length)\n",
    "        X = np.zeros((1, self.num_countries, self.seq_length))\n",
    "        for i, ts in enumerate(input_timestamps):\n",
    "            X[0, :, i] = self.node_features[ts]  # Total exports from each country\n",
    "        \n",
    "        # Create target tensor\n",
    "        y = np.zeros((1, self.num_countries, self.predict_length))\n",
    "        for i, ts in enumerate(target_timestamps):\n",
    "            y[0, :, i] = self.node_features[ts]\n",
    "        \n",
    "        # Create adjacency matrix - average over the input sequence\n",
    "        A = np.mean([self.adj_matrices[ts] for ts in input_timestamps], axis=0)\n",
    "        \n",
    "        # Row-normalize the adjacency matrix\n",
    "        row_sums = A.sum(axis=1, keepdims=True)\n",
    "        # Avoid division by zero\n",
    "        row_sums[row_sums == 0] = 1\n",
    "        A_normalized = A / row_sums\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        return torch.FloatTensor(X), torch.FloatTensor(y), torch.FloatTensor(A_normalized)\n",
    "\n",
    "# Set up parameters\n",
    "num_countries = len(set(data['source_country'].unique()) | set(data['target_country'].unique()))\n",
    "seq_length = 12  # Use 12 months of history\n",
    "predict_length = 1  # Predict next 3 months\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = ExportDataset(data, num_countries, seq_length, predict_length)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{numpy.datetime64('2020-01-31T00:00:00.000000000'): array([[ 0.        , 23.32369885, 27.3909709 ],\n",
       "        [29.57395491,  0.        , 44.8073016 ],\n",
       "        [37.9744946 , 43.39949536,  0.        ]]),\n",
       " numpy.datetime64('2020-02-29T00:00:00.000000000'): array([[ 0.        , 27.71297426, 32.21264328],\n",
       "        [28.51221574,  0.        , 44.15584848],\n",
       "        [39.94246953, 45.63746952,  0.        ]]),\n",
       " numpy.datetime64('2020-03-31T00:00:00.000000000'): array([[ 0.        , 25.31813074, 24.98796404],\n",
       "        [25.5700039 ,  0.        , 40.82754415],\n",
       "        [38.87849257, 50.99363881,  0.        ]]),\n",
       " numpy.datetime64('2020-04-30T00:00:00.000000000'): array([[ 0.        , 22.18684489, 26.19533522],\n",
       "        [34.97404921,  0.        , 41.74049481],\n",
       "        [42.99304188, 41.85180063,  0.        ]]),\n",
       " numpy.datetime64('2020-05-31T00:00:00.000000000'): array([[ 0.        , 21.84247591, 29.19528898],\n",
       "        [25.55150605,  0.        , 41.94375924],\n",
       "        [37.9969181 , 44.85237488,  0.        ]]),\n",
       " numpy.datetime64('2020-06-30T00:00:00.000000000'): array([[ 0.        , 19.92438198, 31.40853719],\n",
       "        [26.46423235,  0.        , 33.17589245],\n",
       "        [40.15164162, 37.22362292,  0.        ]]),\n",
       " numpy.datetime64('2020-07-31T00:00:00.000000000'): array([[ 0.        , 19.66227128, 19.35709418],\n",
       "        [20.87739209,  0.        , 34.3685208 ],\n",
       "        [36.19400161, 39.18011062,  0.        ]]),\n",
       " numpy.datetime64('2020-08-31T00:00:00.000000000'): array([[ 0.        , 17.65223665, 21.6512951 ],\n",
       "        [19.02288975,  0.        , 29.00312979],\n",
       "        [29.8132206 , 39.49332111,  0.        ]]),\n",
       " numpy.datetime64('2020-09-30T00:00:00.000000000'): array([[ 0.        , 18.0392703 , 17.95657246],\n",
       "        [22.50650305,  0.        , 29.34472888],\n",
       "        [28.45403406, 37.0135269 ,  0.        ]]),\n",
       " numpy.datetime64('2020-10-31T00:00:00.000000000'): array([[ 0.        , 20.06482359, 24.85429887],\n",
       "        [20.82874312,  0.        , 30.84733179],\n",
       "        [32.88606904, 39.92790977,  0.        ]]),\n",
       " numpy.datetime64('2020-11-30T00:00:00.000000000'): array([[ 0.        , 19.02260987, 24.51131671],\n",
       "        [22.2119284 ,  0.        , 30.78246354],\n",
       "        [37.80599654, 45.37953515,  0.        ]]),\n",
       " numpy.datetime64('2020-12-31T00:00:00.000000000'): array([[ 0.        , 22.23869733, 30.80989211],\n",
       "        [29.01258087,  0.        , 36.67113056],\n",
       "        [40.61667077, 51.69040382,  0.        ]]),\n",
       " numpy.datetime64('2021-01-31T00:00:00.000000000'): array([[ 0.        , 24.77093647, 35.93713016],\n",
       "        [22.93414209,  0.        , 47.08068685],\n",
       "        [43.88369827, 48.23333545,  0.        ]]),\n",
       " numpy.datetime64('2021-02-28T00:00:00.000000000'): array([[ 0.        , 26.99452744, 26.79064085],\n",
       "        [32.7018423 ,  0.        , 48.48255819],\n",
       "        [53.7290352 , 50.72550181,  0.        ]]),\n",
       " numpy.datetime64('2021-03-31T00:00:00.000000000'): array([[ 0.        , 25.36855766, 32.7689382 ],\n",
       "        [37.65813731,  0.        , 49.88786786],\n",
       "        [45.74125822, 58.03323623,  0.        ]]),\n",
       " numpy.datetime64('2021-04-30T00:00:00.000000000'): array([[ 0.        , 27.48258702, 37.31856309],\n",
       "        [31.6343558 ,  0.        , 46.0714018 ],\n",
       "        [45.76443177, 46.46982102,  0.        ]])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.adj_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 3, 12]) torch.Size([3, 1, 3, 1]) torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "device='cpu'\n",
    "for X, y, A in train_loader:\n",
    "    X, y, A = X.to(device), y.to(device), A.to(device)\n",
    "    print(X.shape, y.shape, A[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([2, 1, 3, 13]) y: torch.Size([2, 1, 3, 1]) A: torch.Size([2, 3, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 77\u001b[0m\n\u001b[0;32m     74\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 77\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader, criterion, device)\n\u001b[0;32m     80\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[38], line 46\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX:\u001b[39m\u001b[38;5;124m'\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my:\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA:\u001b[39m\u001b[38;5;124m'\u001b[39m, A\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 46\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_tilde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y)\n\u001b[0;32m     49\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch_geometric_temporal\\nn\\attention\\mtgnn.py:675\u001b[0m, in \u001b[0;36mMTGNN.forward\u001b[1;34m(self, X_in, A_tilde, idx, FE)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mtgnn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mtgnn_layers:\n\u001b[1;32m--> 675\u001b[0m         X, X_skip \u001b[38;5;241m=\u001b[39m \u001b[43mmtgnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_skip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_tilde\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_in\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mtgnn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mtgnn_layers:\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch_geometric_temporal\\nn\\attention\\mtgnn.py:446\u001b[0m, in \u001b[0;36mMTGNNLayer.forward\u001b[1;34m(self, X, X_skip, A_tilde, idx, training)\u001b[0m\n\u001b[0;32m    444\u001b[0m X_skip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip_conv(X) \u001b[38;5;241m+\u001b[39m X_skip\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gcn_true:\n\u001b[1;32m--> 446\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mixprop_conv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_tilde\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mixprop_conv2(\n\u001b[0;32m    447\u001b[0m         X, A_tilde\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    448\u001b[0m     )\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    450\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_residual_conv(X)\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch_geometric_temporal\\nn\\attention\\mtgnn.py:91\u001b[0m, in \u001b[0;36mMixProp.forward\u001b[1;34m(self, X, A)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: torch\u001b[38;5;241m.\u001b[39mFloatTensor, A: torch\u001b[38;5;241m.\u001b[39mFloatTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[0;32m     81\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    Making a forward pass of mix-hop propagation.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m        * **H_0** (PyTorch Float Tensor) - Hidden representation for all nodes, with shape (batch_size, c_out, num_nodes, seq_len).\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m     A \u001b[38;5;241m=\u001b[39m \u001b[43mA\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m     d \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     93\u001b[0m     H \u001b[38;5;241m=\u001b[39m X\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "# Initialize the MTGNN model\n",
    "from torch_geometric_temporal.nn.attention.mtgnn import MTGNN  \n",
    "\n",
    "model = MTGNN(\n",
    "    gcn_true=True,             # Use graph convolution\n",
    "    build_adj=False,           # We're providing our own adjacency matrix (shape [batch, num_nodes, num_nodes])\n",
    "    gcn_depth=2,               # Depth of graph convolution\n",
    "    num_nodes=3,               # 3 nodes (countries)\n",
    "    kernel_set=[2],         # Kernel set remains as is\n",
    "    kernel_size=1,             # Base kernel size\n",
    "    dropout=0.3,               # Dropout rate\n",
    "    subgraph_size=3,           # Full graph (3 nodes)\n",
    "    node_dim=40,               # Node embedding dimension\n",
    "    dilation_exponential=2,    # Dilation factor\n",
    "    conv_channels=2,          # Convolution channels\n",
    "    residual_channels=2,      # Residual channels\n",
    "    skip_channels=4,          # Skip channels\n",
    "    end_channels=8,          # End convolution channels\n",
    "    seq_length=12,             # Input sequence length (from X shape)\n",
    "    in_dim=1,                  # Input dimension (export volume channel) ()\n",
    "    out_dim=num_countries,     # Output dimension (predicted export volume) (should be for each sector and country, so is sector*country)\n",
    "    layers=1,                  # Number of MTGNN layers\n",
    "    propalpha=0.05,            # Propagation weight\n",
    "    tanhalpha=3,               # Tanh alpha\n",
    "    layer_norm_affline=True    # Use affine transformation in layer norm\n",
    ")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Initialize optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5, verbose=True)\n",
    "criterion = MSELoss()\n",
    "\n",
    "# Training function\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X, y, A in train_loader:\n",
    "        X, y, A = X.to(device), y.to(device), A.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        print('X:', X.shape, 'y:', y.shape, 'A:', A.shape)\n",
    "        output = model(X, A_tilde=A)\n",
    "        \n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * X.size(0)\n",
    "    \n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y, A in test_loader:\n",
    "            X, y, A = X.to(device), y.to(device), A.to(device)\n",
    "            \n",
    "            output = model(X, A_tilde=A)\n",
    "            loss = criterion(output, y)\n",
    "            \n",
    "            total_loss += loss.item() * X.size(0)\n",
    "    \n",
    "    return total_loss / len(test_loader.dataset)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_future_exports(model, dataset, idx, device):\n",
    "    \"\"\"\n",
    "    Make predictions for a specific sample in the dataset\n",
    "    \n",
    "    Args:\n",
    "        model: Trained MTGNN model\n",
    "        dataset: ExportDataset instance\n",
    "        idx: Index of the sample to predict\n",
    "        device: Device to run inference on\n",
    "    \n",
    "    Returns:\n",
    "        actual: Ground truth values\n",
    "        predicted: Predicted values\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    X, y, A = dataset[idx]\n",
    "    X, y, A = X.unsqueeze(0).to(device), y.to(device), A.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(X, A_tilde=A)\n",
    "        \n",
    "    # Convert tensors to numpy arrays\n",
    "    predicted = output.cpu().squeeze().numpy()\n",
    "    actual = y.cpu().squeeze().numpy()\n",
    "    \n",
    "    return actual, predicted\n",
    "\n",
    "# Make a prediction for a sample in the test dataset\n",
    "sample_idx = 0  # First sample in the test dataset\n",
    "test_sample = test_dataset[sample_idx]\n",
    "\n",
    "# Get actual data sample\n",
    "actual, predicted = predict_future_exports(model, test_dataset, sample_idx, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple implementation of MTGNN\n",
    "\n",
    "3 sectors, 3 countries, seq_length of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn import MSELoss\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# define static variables\n",
    "num_countries=3\n",
    "num_sectors=3\n",
    "seq_length=12\n",
    "\n",
    "#form pre-defined adjacency matrix\n",
    "matrix=[[np.random.rand(0,1) for _ in range(3)] for _ in range(3)]\n",
    "adj_matrix=torch.tensor(matrix,dtype=torch.float)\n",
    "\n",
    "export_volumes = np.random.rand(num_countries, num_sectors, seq_length)\n",
    "\n",
    "# Convert to a DataFrame for better visualization\n",
    "countries = [f\"Country_{i+1}\" for i in range(num_countries)]\n",
    "sectors = [f\"Sector_{i+1}\" for i in range(num_sectors)]\n",
    "timestamps = [f\"Timestamp_{i+1}\" for i in range(seq_length)]\n",
    "\n",
    "# Create a multi-index DataFrame\n",
    "index = pd.MultiIndex.from_product([countries, sectors], names=[\"Country\", \"Sector\"])\n",
    "export_data = pd.DataFrame(export_volumes.reshape(-1, seq_length), index=index, columns=timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Timestamp_1  Timestamp_2  Timestamp_3  Timestamp_4  \\\n",
      "Country   Sector                                                         \n",
      "Country_1 Sector_1     0.374540     0.950714     0.731994     0.598658   \n",
      "          Sector_2     0.832443     0.212339     0.181825     0.183405   \n",
      "          Sector_3     0.456070     0.785176     0.199674     0.514234   \n",
      "Country_2 Sector_1     0.304614     0.097672     0.684233     0.440152   \n",
      "          Sector_2     0.546710     0.184854     0.969585     0.775133   \n",
      "\n",
      "                    Timestamp_5  Timestamp_6  Timestamp_7  Timestamp_8  \\\n",
      "Country   Sector                                                         \n",
      "Country_1 Sector_1     0.156019     0.155995     0.058084     0.866176   \n",
      "          Sector_2     0.304242     0.524756     0.431945     0.291229   \n",
      "          Sector_3     0.592415     0.046450     0.607545     0.170524   \n",
      "Country_2 Sector_1     0.122038     0.495177     0.034389     0.909320   \n",
      "          Sector_2     0.939499     0.894827     0.597900     0.921874   \n",
      "\n",
      "                    Timestamp_9  Timestamp_10  Timestamp_11  Timestamp_12  \n",
      "Country   Sector                                                           \n",
      "Country_1 Sector_1     0.601115      0.708073      0.020584      0.969910  \n",
      "          Sector_2     0.611853      0.139494      0.292145      0.366362  \n",
      "          Sector_3     0.065052      0.948886      0.965632      0.808397  \n",
      "Country_2 Sector_1     0.258780      0.662522      0.311711      0.520068  \n",
      "          Sector_2     0.088493      0.195983      0.045227      0.325330  \n"
     ]
    }
   ],
   "source": [
    "print(export_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 12])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Select one country (e.g., Country_1) for prediction\n",
    "selected_country = \"Country_1\"\n",
    "input_data = export_data.loc[selected_country].values  # Shape: (num_sectors, seq_length)\n",
    "\n",
    "# Convert to PyTorch tensor and reshape to match MTGNN input requirements\n",
    "# Shape required: (batch_size, in_dim, num_nodes, seq_length)\n",
    "# Since we are predicting for one country, num_nodes = 1 (as we are not considering node interactions between countries)\n",
    "# Correct adjustment\n",
    "# Adjust input dimensions to include all countries but focus on the selected one\n",
    "# Since you are predicting for one country, you might need to adjust how you handle num_nodes\n",
    "input_data_all_countries = export_volumes[:, :, :]  # Shape: (num_countries, num_sectors, seq_length)\n",
    "input_data_all_countries = input_data_all_countries.transpose(1, 0, 2)  # Shape: (num_sectors, num_countries, seq_length)\n",
    "input_tensor = torch.tensor(input_data_all_countries, dtype=torch.float32).unsqueeze(0)  # Shape: (batch_size, in_dim, num_nodes, seq_length)\n",
    "\n",
    "print(input_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ExportDataset(Dataset):\n",
    "    def __init__(self, export_volumes):\n",
    "        self.export_volumes = export_volumes\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.export_volumes.shape[2] - seq_length + 1  # Number of possible time windows\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx\n",
    "        end = start + seq_length\n",
    "        input_data = self.export_volumes[:, :, start:end].transpose(1, 0, 2)\n",
    "        return torch.tensor(input_data, dtype=torch.float32)\n",
    "\n",
    "dataset = ExportDataset(export_volumes)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "batch_size = 4  # Desired batch size\n",
    "input_tensor_batch = torch.tensor(input_data_all_countries, dtype=torch.float32).unsqueeze(0).repeat(batch_size, 1, 1, 1)  # Shape: (batch_size, in_dim, num_nodes, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 12])\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MTGNN model\n",
    "from torch_geometric_temporal.nn.attention.mtgnn import MTGNN\n",
    "\n",
    "model = MTGNN(\n",
    "    gcn_true=True,             # Use graph convolution\n",
    "    build_adj=True,           # We're providing our own adjacency matrix (shape [batch, num_nodes, num_nodes])\n",
    "    gcn_depth=1,               # Depth of graph convolution\n",
    "    num_nodes=3,               # 3 nodes (countries)\n",
    "    kernel_set=[2],         # Kernel set remains as is\n",
    "    kernel_size=1,             # Base kernel size\n",
    "    dropout=0.3,               # Dropout rate\n",
    "    subgraph_size=3,           # Full graph (3 nodes)\n",
    "    node_dim=4,               # Node embedding dimension\n",
    "    dilation_exponential=1,    # Dilation factor\n",
    "    conv_channels=16,         # Convolution channels (adjusted to match the paper)\n",
    "    residual_channels=16,     # Residual channels (adjusted to match the paper)\n",
    "    skip_channels=32,         # Skip channels (adjusted to match the paper)\n",
    "    end_channels=64,          # End convolution channels (adjusted to match the first output layer in the paper)\n",
    "    seq_length=12,             # Input sequence length (from X shape)\n",
    "    in_dim=num_sectors,       # Input dimension (number of sectors)\n",
    "    out_dim=num_sectors,               # Output dimension (adjusted to match the final output layer in the paper)\n",
    "    layers=1,                  # Number of MTGNN layers (adjusted to match the number of convolution modules)\n",
    "    propalpha=0.05,            # Propagation weight\n",
    "    tanhalpha=3,               # Tanh alpha\n",
    "    layer_norm_affline=True    # Use affine transformation in layer norm\n",
    ")\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Initialize optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5, verbose=True)\n",
    "criterion = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (3 x 11). Kernel size: (1 x 12). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43madj_matrix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch_geometric_temporal\\nn\\attention\\mtgnn.py:675\u001b[0m, in \u001b[0;36mMTGNN.forward\u001b[1;34m(self, X_in, A_tilde, idx, FE)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mtgnn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mtgnn_layers:\n\u001b[1;32m--> 675\u001b[0m         X, X_skip \u001b[38;5;241m=\u001b[39m \u001b[43mmtgnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_skip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_tilde\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_in\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mtgnn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mtgnn_layers:\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch_geometric_temporal\\nn\\attention\\mtgnn.py:444\u001b[0m, in \u001b[0;36mMTGNNLayer.forward\u001b[1;34m(self, X, X_skip, A_tilde, idx, training)\u001b[0m\n\u001b[0;32m    442\u001b[0m X \u001b[38;5;241m=\u001b[39m X_filter \u001b[38;5;241m*\u001b[39m X_gate\n\u001b[0;32m    443\u001b[0m X \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dropout, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m--> 444\u001b[0m X_skip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_skip_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m X_skip\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gcn_true:\n\u001b[0;32m    446\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mixprop_conv1(X, A_tilde) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mixprop_conv2(\n\u001b[0;32m    447\u001b[0m         X, A_tilde\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    448\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rob-l\\Documents\\NUS\\Y3S2\\DSE3101\\T5G1\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (3 x 11). Kernel size: (1 x 12). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "output=model(input_tensor,adj_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
