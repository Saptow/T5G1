{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from IPython.display import clear_output\n",
    "pt_version = torch.__version__\n",
    "print(pt_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 5, 10, 12])\n",
      "Adjacency shape: torch.Size([10, 10])\n",
      "Output shape: torch.Size([4, 1, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric_temporal.nn.attention.mtgnn import MTGNN\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "    # ---------------------------------------------\n",
    "    # 1. Configuration & Hyperparameters\n",
    "    # ---------------------------------------------\n",
    "    num_nodes = 10         # e.g., 10 countries\n",
    "    seq_length = 12        # 12 time steps of historical data\n",
    "    in_dim = 5             # e.g., 5 features per country (5 sectors of imports)\n",
    "    out_dim = 1            # e.g., 1 feature to predict (export volume) \n",
    "                           # or set = # of sectors if you predict multiple export sectors\n",
    "    batch_size = 4\n",
    "\n",
    "    # Since we want to supply our own adjacency (based on trade relationships),\n",
    "    # we set build_adj=False so the model won't learn a new adjacency.\n",
    "    model = MTGNN(\n",
    "        gcn_true=True,\n",
    "        build_adj=False,       # <--- use your adjacency, do not learn a new one\n",
    "        gcn_depth=2,\n",
    "        num_nodes=num_nodes,\n",
    "        kernel_set=[2],        # minimal kernel set for demonstration\n",
    "        kernel_size=2,\n",
    "        dropout=0.3,\n",
    "        subgraph_size=5,\n",
    "        node_dim=16,\n",
    "        dilation_exponential=1,\n",
    "        conv_channels=16,\n",
    "        residual_channels=16,\n",
    "        skip_channels=32,\n",
    "        end_channels=64,\n",
    "        seq_length=seq_length,\n",
    "        in_dim=in_dim,\n",
    "        out_dim=out_dim,\n",
    "        layers=1,\n",
    "        propalpha=0.05,\n",
    "        tanhalpha=3.0,\n",
    "        layer_norm_affline=True,\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # 2. Define Trade-Based Adjacency Matrix\n",
    "    # ---------------------------------------------\n",
    "    # Suppose you already have an N x N matrix of trade scores.\n",
    "    # Here we create a dummy adjacency for illustration:\n",
    "    A_tilde = torch.rand(num_nodes, num_nodes)\n",
    "\n",
    "    # Potentially, you might want to symmetrize or row-normalize it:\n",
    "    # For example, row-normalize so each row sums to 1:\n",
    "    A_tilde = A_tilde / A_tilde.sum(dim=1, keepdim=True).clamp(min=1e-9)\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # 3. Create Dummy Input Data\n",
    "    # ---------------------------------------------\n",
    "    # Shape is (batch_size, in_dim, num_nodes, seq_length).\n",
    "    # This means 'batch_size' examples, each example has 'in_dim' features for each node,\n",
    "    # and we have 'seq_length' time steps.\n",
    "    x_in = torch.randn(batch_size, in_dim, num_nodes, seq_length)\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # 4. Forward Pass\n",
    "    # ---------------------------------------------\n",
    "    # Pass your adjacency as A_tilde. Model won't try to rebuild adjacency if build_adj=False.\n",
    "    output = model(x_in, A_tilde=A_tilde)\n",
    "\n",
    "    print(\"Input shape:\", x_in.shape)\n",
    "    print(\"Adjacency shape:\", A_tilde.shape)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "\n",
    "    # If out_dim=1, output is (batch_size, 1, num_nodes, some_time) \n",
    "    # or just 1 time step, depending on your setup.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base off this implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 5, 10, 12])\n",
      "Adjacency shape: torch.Size([10, 10])\n",
      "Output shape: torch.Size([4, 5, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric_temporal.nn.attention.mtgnn import MTGNN\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "    # ---------------------------------------------\n",
    "    # 1. Configuration & Hyperparameters\n",
    "    # ---------------------------------------------\n",
    "    num_nodes = 10\n",
    "    seq_length = 12\n",
    "    in_dim = 5            # Number of input sectors\n",
    "    out_dim = 5           # Number of output sectors\n",
    "    batch_size = 4\n",
    "    learning_rate = 0.001\n",
    "    epochs = 10\n",
    "    \n",
    "    # We'll use the smaller kernel_set and fewer layers to avoid dimension issues:\n",
    "    model = MTGNN(\n",
    "        gcn_true=True,\n",
    "        build_adj=False,    # We will provide our adjacency, do not learn a new one\n",
    "        gcn_depth=2,\n",
    "        num_nodes=num_nodes,\n",
    "        kernel_set=[2],     # minimal kernel for demonstration\n",
    "        kernel_size=2,\n",
    "        dropout=0.3,\n",
    "        subgraph_size=5,\n",
    "        node_dim=16,\n",
    "        dilation_exponential=1,\n",
    "        conv_channels=16,\n",
    "        residual_channels=16,\n",
    "        skip_channels=32,\n",
    "        end_channels=64,\n",
    "        seq_length=seq_length,\n",
    "        in_dim=in_dim,\n",
    "        out_dim=out_dim,    # same dimension as input (5 sectors)\n",
    "        layers=1,\n",
    "        propalpha=0.05,\n",
    "        tanhalpha=3.0,\n",
    "        layer_norm_affline=True,\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # 2. Define or Load Adjacency Matrix\n",
    "    # ---------------------------------------------\n",
    "    # Suppose you already have an N x N matrix of trade scores.\n",
    "    # Here we create a dummy adjacency for illustration:\n",
    "    A_tilde = torch.rand(num_nodes, num_nodes)\n",
    "    A_tilde = A_tilde / A_tilde.sum(dim=1, keepdim=True).clamp(min=1e-9)\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # 3. Create Dummy Input Data\n",
    "    # ---------------------------------------------\n",
    "    # Shape is (batch_size, in_dim=5, num_nodes, seq_length).\n",
    "    # \"in_dim=5\" means each country has 5 sector features per time step.\n",
    "    x_in = torch.randn(batch_size, in_dim, num_nodes, seq_length)\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # 4. Forward Pass\n",
    "    # ---------------------------------------------\n",
    "    output = model(x_in, A_tilde=A_tilde)\n",
    "\n",
    "    print(\"Input shape:\", x_in.shape)\n",
    "    print(\"Adjacency shape:\", A_tilde.shape)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.6872e+00],\n",
      "         [ 2.8977e+00],\n",
      "         [ 1.5462e-03],\n",
      "         [ 9.6436e-01],\n",
      "         [-1.5651e+00]],\n",
      "\n",
      "        [[ 1.4357e+00],\n",
      "         [ 3.8232e+00],\n",
      "         [ 1.1662e-01],\n",
      "         [ 2.6538e-01],\n",
      "         [-2.5016e+00]],\n",
      "\n",
      "        [[ 7.2784e-01],\n",
      "         [ 2.9344e+00],\n",
      "         [ 1.4065e-01],\n",
      "         [ 4.6304e-01],\n",
      "         [-1.0732e+00]],\n",
      "\n",
      "        [[ 9.1411e-01],\n",
      "         [ 2.6709e+00],\n",
      "         [-1.9015e-01],\n",
      "         [ 5.8581e-01],\n",
      "         [-1.5652e+00]]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric_temporal.nn.attention.mtgnn import MTGNN\n",
    "\n",
    "num_countries = 10\n",
    "num_sectors = 5\n",
    "seq_length = 12\n",
    "batch_size = 4\n",
    "\n",
    "#Adjacency matrix (N x N) for trade relationships between countries\n",
    "A = torch.rand(num_countries, num_countries)\n",
    "A = A / A.sum(dim=1, keepdim=True).clamp(min=1e-9)\n",
    "\n",
    "# Build the model to forecast 'num_sectors' (out_dim=5)\n",
    "model = MTGNN(\n",
    "    gcn_true=True,\n",
    "    build_adj=False,          # We'll supply adjacency A\n",
    "    gcn_depth=2,\n",
    "    num_nodes=num_countries,\n",
    "    kernel_set=[2],\n",
    "    kernel_size=2,\n",
    "    dropout=0.3,\n",
    "    subgraph_size=5,\n",
    "    node_dim=16,\n",
    "    dilation_exponential=1,\n",
    "    conv_channels=16,\n",
    "    residual_channels=16,\n",
    "    skip_channels=32,\n",
    "    end_channels=64,\n",
    "    seq_length=seq_length,\n",
    "    in_dim=num_sectors,       # input dimension (5 sectors)\n",
    "    out_dim=num_sectors,      # want 5 predicted sector volumes\n",
    "    layers=1,\n",
    "    propalpha=0.05,\n",
    "    tanhalpha=3.0,\n",
    "    layer_norm_affline=True,\n",
    ")\n",
    "\n",
    "# Example input: (batch_size, in_dim=5, num_countries=10, seq_length=12)\n",
    "X_in = torch.randn(batch_size, num_sectors, num_countries, seq_length)\n",
    "\n",
    "# Forward pass through the model\n",
    "output = model(X_in, A_tilde=A)  # shape: (batch_size, 5, 10, 1)\n",
    "\n",
    "# Get predictions only for the target country, e.g. index 0\n",
    "predictions_for_target = output[..., 0, :]  # shape: (batch_size, 5, 1)\n",
    "\n",
    "print(predictions_for_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Loss: 2.3408\n",
      "Epoch [2/10] - Loss: 1.1429\n",
      "Epoch [3/10] - Loss: 1.0414\n",
      "Epoch [4/10] - Loss: 1.0214\n",
      "Epoch [5/10] - Loss: 1.0069\n",
      "Epoch [6/10] - Loss: 0.9836\n",
      "Epoch [7/10] - Loss: 0.9694\n",
      "Epoch [8/10] - Loss: 0.9592\n",
      "Epoch [9/10] - Loss: 0.9438\n",
      "Epoch [10/10] - Loss: 0.9317\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_model():\n",
    "    # ------------------------------------------------\n",
    "    # 1. Define Hyperparameters\n",
    "    # ------------------------------------------------\n",
    "    num_nodes = 10\n",
    "    seq_length = 12\n",
    "    in_dim = 5            # Number of input sectors\n",
    "    out_dim = 5           # Number of output sectors\n",
    "    batch_size = 4\n",
    "    learning_rate = 0.001\n",
    "    epochs = 10\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 2. Initialize the MTGNN Model\n",
    "    # ------------------------------------------------\n",
    "    model = MTGNN(\n",
    "        gcn_true=True,\n",
    "        build_adj=False,        # We'll provide the adjacency ourselves\n",
    "        gcn_depth=2,\n",
    "        num_nodes=num_nodes,\n",
    "        kernel_set=[2],         # Minimal kernel set for demonstration\n",
    "        kernel_size=2,\n",
    "        dropout=0.3,\n",
    "        subgraph_size=5,\n",
    "        node_dim=16,\n",
    "        dilation_exponential=1,\n",
    "        conv_channels=16,\n",
    "        residual_channels=16,\n",
    "        skip_channels=32,\n",
    "        end_channels=64,\n",
    "        seq_length=seq_length,\n",
    "        in_dim=in_dim,          # 5 input sectors\n",
    "        out_dim=out_dim,        # 5 output sectors\n",
    "        layers=1,\n",
    "        propalpha=0.05,\n",
    "        tanhalpha=3.0,\n",
    "        layer_norm_affline=True,\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 3. Define or Load the Adjacency Matrix\n",
    "    # ------------------------------------------------\n",
    "    # Suppose you have a trade-based adjacency of shape (num_nodes, num_nodes).\n",
    "    # For demonstration, we create a random adjacency and row-normalize it:\n",
    "    A_tilde = torch.rand(num_nodes, num_nodes)\n",
    "    A_tilde = A_tilde / A_tilde.sum(dim=1, keepdim=True).clamp(min=1e-9)\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 4. Create a Synthetic Dataset (Replace with Real Data)\n",
    "    # ------------------------------------------------\n",
    "    # We'll assume we have 100 samples. Each sample:\n",
    "    #   - X: shape (in_dim=5, num_nodes=10, seq_length=12)\n",
    "    #   - y: shape (out_dim=5, num_nodes=10, 1 time step)\n",
    "    X_data = torch.randn(100, in_dim, num_nodes, seq_length)\n",
    "    y_data = torch.randn(100, out_dim, num_nodes, 1)\n",
    "\n",
    "    # Wrap them in a TensorDataset and DataLoader for easy batching\n",
    "    dataset = torch.utils.data.TensorDataset(X_data, y_data)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 5. Set Up Loss and Optimizer\n",
    "    # ------------------------------------------------\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 6. Training Loop\n",
    "    # ------------------------------------------------\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for i, (x_batch, y_batch) in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass through MTGNN\n",
    "            y_pred = model(x_batch, A_tilde=A_tilde)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "\n",
    "            # Backprop and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / (i + 1)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UPDATE (START HERE)\n",
    "as per discussed, sentiment score becomes one of the features to put in, will put in 1 other for now, lets call it bilateral trade index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric_temporal.nn.attention.mtgnn import MTGNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "Assume the data is already cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try batch size=4/7 for 25 years of historical data; for a seq length of 5(5/3 batches per epoch)\n",
    "#input features will be input sectors (10) + 3 additional features for now\n",
    "#seq_length will be every 5 years\n",
    "#assume data will be read from csv \n",
    "import pandas as pd\n",
    "\n",
    "class TradeDataset:\n",
    "    def __init__ (self, csv_file, seq_length=5, transform=None):\n",
    "        df=pd.read_csv(csv_file)\n",
    "\n",
    "        # Suppose you have 13 input features (10 \"input sectors\" + 3 additional features)\n",
    "        # and 1 target column. Adjust indexing to match your real CSV.\n",
    "        data = df.values  # shape = (num_rows, total_columns)\n",
    "\n",
    "        self.seq_length = seq_length\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        \n",
    "        # Build sequences of length 'seq_length'\n",
    "        # For each index i, we take rows[i : i+seq_length] as inputs \n",
    "        # and row[i+seq_length] (or some slice) as the target.\n",
    "        for i in range(len(data) - seq_length):\n",
    "            # For example, let's say columns [0:13] are features, column 13 is target\n",
    "            x_seq = data[i : i + seq_length, :13] \n",
    "            y_val = data[i + seq_length, 13]\n",
    "\n",
    "            self.X.append(x_seq)\n",
    "            self.y.append(y_val)\n",
    "\n",
    "        # Convert to tensors\n",
    "        self.X = torch.tensor(self.X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(self.y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country Dictionary\n",
    "\n",
    "0. Singapore\n",
    "1. China\n",
    "2. Malaysia\n",
    "3. United States\n",
    "4. Hong Kong, China\n",
    "5. Indonesia\n",
    "6. Korea, Rep.\n",
    "7. Japan\n",
    "8. Thailand\n",
    "9. Australia\n",
    "10. Vietnam\n",
    "11. India\n",
    "12. United Arab Emirates\n",
    "13. Philippines\n",
    "14. Germany\n",
    "15. France\n",
    "16. Switzerland\n",
    "17. Netherlands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_countries=18            #based on the excel \n",
    "num_country_pair=num_countries*(num_countries-1)\n",
    "num_sectors=10              # for now; wait for ee zhen then index and split it\n",
    "seq_length = 5              # Each sample is a 5-year window\n",
    "batch_size = 4             # can be 7 as well\n",
    "csv_path=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset and data loader\n",
    "dataset = TradeDataset(csv_path, seq_length=seq_length)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Loss: 1.4750\n",
      "Epoch [2/10] - Loss: 1.1267\n",
      "Epoch [3/10] - Loss: 1.0524\n",
      "Epoch [4/10] - Loss: 1.0134\n",
      "Epoch [5/10] - Loss: 0.9940\n",
      "Epoch [6/10] - Loss: 0.9701\n",
      "Epoch [7/10] - Loss: 0.9491\n",
      "Epoch [8/10] - Loss: 0.9402\n",
      "Epoch [9/10] - Loss: 0.9223\n",
      "Epoch [10/10] - Loss: 0.9035\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# define model for training\n",
    "model = MTGNN(\n",
    "    gcn_true=True,\n",
    "    build_adj=True,        # auto adjacency for training; for model to learn based on node embedding features\n",
    "    gcn_depth=2,\n",
    "    num_nodes=num_country_pair,\n",
    "    kernel_set=[2],         # Minimal kernel set for demonstration\n",
    "    kernel_size=2,\n",
    "    dropout=0.3,\n",
    "    subgraph_size=5,\n",
    "    node_dim=16,\n",
    "    dilation_exponential=1,\n",
    "    conv_channels=16,\n",
    "    residual_channels=16,\n",
    "    skip_channels=32,\n",
    "    end_channels=64,\n",
    "    seq_length=seq_length,\n",
    "    in_dim=num_sectors+2,          \n",
    "    out_dim=num_sectors,         \n",
    "    layers=1,\n",
    "    propalpha=0.05,\n",
    "    tanhalpha=3.0,\n",
    "    layer_norm_affline=True,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# loss function and optimiser\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "epochs = 10 #set to 10 first\n",
    "\n",
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for i, (x_batch, y_batch) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through MTGNN (learn through data)\n",
    "        y_pred = model(x_batch, A_tilde=None, idx=None, FE=None)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        # Backprop and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / (i + 1)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"mtgnn_sector_forecast.pt\")\n",
    "print(\"Model saved to mtgnn_sector_forecast.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape: torch.Size([2, 5, 6, 1])\n",
      "Forecasted sectoral trade volumes (sample):\n",
      "tensor([[[[ 0.2133],\n",
      "          [-0.0894],\n",
      "          [-0.5410],\n",
      "          [-0.0796],\n",
      "          [ 0.0178],\n",
      "          [-0.1630]],\n",
      "\n",
      "         [[ 0.1771],\n",
      "          [ 0.0513],\n",
      "          [-0.3636],\n",
      "          [ 0.4902],\n",
      "          [-0.2471],\n",
      "          [-0.2570]],\n",
      "\n",
      "         [[ 0.2128],\n",
      "          [ 0.0664],\n",
      "          [-0.2309],\n",
      "          [ 0.7080],\n",
      "          [ 0.0675],\n",
      "          [ 0.4353]],\n",
      "\n",
      "         [[-0.4976],\n",
      "          [-0.4523],\n",
      "          [-0.2808],\n",
      "          [-0.4529],\n",
      "          [-0.3936],\n",
      "          [-0.7220]],\n",
      "\n",
      "         [[ 0.5685],\n",
      "          [ 0.0531],\n",
      "          [-0.8483],\n",
      "          [ 0.4036],\n",
      "          [-0.0140],\n",
      "          [-0.5388]]],\n",
      "\n",
      "\n",
      "        [[[-0.4324],\n",
      "          [-0.1338],\n",
      "          [ 0.2895],\n",
      "          [ 0.1366],\n",
      "          [ 0.0425],\n",
      "          [-0.9602]],\n",
      "\n",
      "         [[-0.8531],\n",
      "          [ 0.3688],\n",
      "          [ 0.4448],\n",
      "          [-0.0305],\n",
      "          [ 0.3498],\n",
      "          [-0.3390]],\n",
      "\n",
      "         [[-0.0736],\n",
      "          [ 0.4925],\n",
      "          [-0.4530],\n",
      "          [ 0.2940],\n",
      "          [ 0.0281],\n",
      "          [-0.0400]],\n",
      "\n",
      "         [[-0.0138],\n",
      "          [-0.4859],\n",
      "          [-0.4056],\n",
      "          [ 0.2599],\n",
      "          [-0.1629],\n",
      "          [-0.3241]],\n",
      "\n",
      "         [[-0.0247],\n",
      "          [-0.1194],\n",
      "          [-0.4415],\n",
      "          [-0.0643],\n",
      "          [ 0.4033],\n",
      "          [ 0.1112]]]])\n"
     ]
    }
   ],
   "source": [
    "model_loaded=MTGNN(\n",
    "    gcn_true=True,\n",
    "    build_adj=True,        # auto adjacency for training; for model to learn based on node embedding features\n",
    "    gcn_depth=2,\n",
    "    num_nodes=num_country_pair,\n",
    "    kernel_set=[2],         # Minimal kernel set for demonstration\n",
    "    kernel_size=2,\n",
    "    dropout=0.3,\n",
    "    subgraph_size=5,\n",
    "    node_dim=16,\n",
    "    dilation_exponential=1,\n",
    "    conv_channels=16,\n",
    "    residual_channels=16,\n",
    "    skip_channels=32,\n",
    "    end_channels=64,\n",
    "    seq_length=seq_length,\n",
    "    in_dim=num_sectors+2,          # 5 input sectors + 2 additional features\n",
    "    out_dim=num_sectors,        # 5 output sectors\n",
    "    layers=1,\n",
    "    propalpha=0.05,\n",
    "    tanhalpha=3.0,\n",
    "    layer_norm_affline=True,\n",
    ")\n",
    "\n",
    "model_loaded.load_state_dict(torch.load(\"mtgnn_sector_forecast.pt\", map_location=torch.device('cpu')))\n",
    "model_loaded.eval()\n",
    "\n",
    "#test data for prediction\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # shape: [batch_size=2, in_dim=7, num_nodes=6, seq_len=10] \n",
    "    X_test = torch.randn(2, num_sectors + 2, num_country_pair, seq_length)\n",
    "    \n",
    "    y_pred = model_loaded(X_test, A_tilde=None, idx=None, FE=None)\n",
    "    \n",
    "    print(\"Prediction shape:\", y_pred.shape)\n",
    "    \n",
    "    # For out_dim=5: y_pred shape is [2, 5, 6, 1] (for each country pair, 5 sectors)\n",
    "    print(\"Forecasted sectoral trade volumes (sample):\")\n",
    "    print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
